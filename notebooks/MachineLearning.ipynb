{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "# Plots imports \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px  \n",
    "\n",
    "\n",
    "# Feature Selection & Engneering imports\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Split imports \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Machine Learning models imports\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Cost functions imports\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Pipeline and Grid Search imports\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Save Models\n",
    "import joblib\n",
    "\n",
    "# Some notebook configrations imports \n",
    "import warnings;   warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"notebook_connected\"\n",
    "%matplotlib inline\n",
    "import ast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_id</th>\n",
       "      <th>Area</th>\n",
       "      <th>RegistrationTime</th>\n",
       "      <th>CloseTime</th>\n",
       "      <th>CarBrand</th>\n",
       "      <th>CarModel</th>\n",
       "      <th>ManufactureYear</th>\n",
       "      <th>CarColor</th>\n",
       "      <th>AssessmentCost</th>\n",
       "      <th>SparePartCost</th>\n",
       "      <th>TotalCost</th>\n",
       "      <th>PaymentType</th>\n",
       "      <th>DurationTime</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>WeekDay</th>\n",
       "      <th>PartsList</th>\n",
       "      <th>PositionList</th>\n",
       "      <th>PartStateList</th>\n",
       "      <th>CarMade</th>\n",
       "      <th>CarClass</th>\n",
       "      <th>CarType</th>\n",
       "      <th>SparePart_Differace%</th>\n",
       "      <th>AssessmentEvaluation</th>\n",
       "      <th>PartsNumber</th>\n",
       "      <th>TimeEvaluation</th>\n",
       "      <th>PartOfDay</th>\n",
       "      <th>TotalCostEvaluation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51</td>\n",
       "      <td>Truck Center</td>\n",
       "      <td>2018-01-01 09:13:36.437000</td>\n",
       "      <td>2018-01-01 09:29:00</td>\n",
       "      <td>Volvo</td>\n",
       "      <td>head</td>\n",
       "      <td>2002</td>\n",
       "      <td>red</td>\n",
       "      <td>2455</td>\n",
       "      <td>1255</td>\n",
       "      <td>3710</td>\n",
       "      <td>POS</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Monday</td>\n",
       "      <td>['Decoration', 'Fender', 'Other', 'Taillight']</td>\n",
       "      <td>['front left', 'left', 'rear left']</td>\n",
       "      <td>['New']</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Luxury</td>\n",
       "      <td>Multi</td>\n",
       "      <td>95.617530</td>\n",
       "      <td>unacceptable</td>\n",
       "      <td>4</td>\n",
       "      <td>Acceptable</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54</td>\n",
       "      <td>Truck Center</td>\n",
       "      <td>2018-01-01 08:37:46.137000</td>\n",
       "      <td>2018-01-01 08:51:00</td>\n",
       "      <td>Volvo</td>\n",
       "      <td>head</td>\n",
       "      <td>2008</td>\n",
       "      <td>red</td>\n",
       "      <td>6510</td>\n",
       "      <td>5310</td>\n",
       "      <td>11820</td>\n",
       "      <td>POS</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Monday</td>\n",
       "      <td>['Bumper', 'Decoration', 'Other', 'Taillight']</td>\n",
       "      <td>['front right', 'right']</td>\n",
       "      <td>['New']</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Luxury</td>\n",
       "      <td>Multi</td>\n",
       "      <td>22.598870</td>\n",
       "      <td>Acceptable</td>\n",
       "      <td>4</td>\n",
       "      <td>Acceptable</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Acceptable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94</td>\n",
       "      <td>Orouba</td>\n",
       "      <td>2018-01-01 10:17:57.727000</td>\n",
       "      <td>2018-01-01 10:25:00</td>\n",
       "      <td>BMW</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>2012</td>\n",
       "      <td>white</td>\n",
       "      <td>5778</td>\n",
       "      <td>4778</td>\n",
       "      <td>10556</td>\n",
       "      <td>Insurance Company</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Monday</td>\n",
       "      <td>['Bumper']</td>\n",
       "      <td>['rear']</td>\n",
       "      <td>['New']</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Luxury</td>\n",
       "      <td>Car</td>\n",
       "      <td>20.929259</td>\n",
       "      <td>Acceptable</td>\n",
       "      <td>1</td>\n",
       "      <td>Fast</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Acceptable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99</td>\n",
       "      <td>Orouba</td>\n",
       "      <td>2018-01-01 10:25:36.453000</td>\n",
       "      <td>2018-01-01 10:52:00</td>\n",
       "      <td>Hyundai</td>\n",
       "      <td>Genesis</td>\n",
       "      <td>2011</td>\n",
       "      <td>silver</td>\n",
       "      <td>1043</td>\n",
       "      <td>343</td>\n",
       "      <td>1386</td>\n",
       "      <td>POS</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Monday</td>\n",
       "      <td>['Sensor']</td>\n",
       "      <td>['undefined']</td>\n",
       "      <td>['New']</td>\n",
       "      <td>Korea</td>\n",
       "      <td>Luxury</td>\n",
       "      <td>Multi</td>\n",
       "      <td>204.081633</td>\n",
       "      <td>unacceptable</td>\n",
       "      <td>1</td>\n",
       "      <td>Delay</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>103</td>\n",
       "      <td>New Industrial</td>\n",
       "      <td>2018-01-01 10:42:32.120000</td>\n",
       "      <td>2018-01-01 10:56:00</td>\n",
       "      <td>Lexus</td>\n",
       "      <td>IS</td>\n",
       "      <td>2007</td>\n",
       "      <td>brouwn</td>\n",
       "      <td>1609</td>\n",
       "      <td>409</td>\n",
       "      <td>2019</td>\n",
       "      <td>Insurance Company</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Monday</td>\n",
       "      <td>['Bumper', 'Sensor']</td>\n",
       "      <td>['front', 'front right']</td>\n",
       "      <td>['New']</td>\n",
       "      <td>Japan</td>\n",
       "      <td>Luxury</td>\n",
       "      <td>Car</td>\n",
       "      <td>293.398533</td>\n",
       "      <td>unacceptable</td>\n",
       "      <td>2</td>\n",
       "      <td>Acceptable</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251468</th>\n",
       "      <td>253390</td>\n",
       "      <td>New Industrial</td>\n",
       "      <td>2018-12-18 14:25:26.810000</td>\n",
       "      <td>2018-12-18 15:57:00</td>\n",
       "      <td>Isuzu</td>\n",
       "      <td>Two</td>\n",
       "      <td>2016</td>\n",
       "      <td>white</td>\n",
       "      <td>2540</td>\n",
       "      <td>1040</td>\n",
       "      <td>3580</td>\n",
       "      <td>Insurance Company</td>\n",
       "      <td>91</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>['Other', 'Rims']</td>\n",
       "      <td>['rear right']</td>\n",
       "      <td>['New']</td>\n",
       "      <td>Japan</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Multi</td>\n",
       "      <td>144.230769</td>\n",
       "      <td>unacceptable</td>\n",
       "      <td>2</td>\n",
       "      <td>Delay</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>Acceptable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251469</th>\n",
       "      <td>253391</td>\n",
       "      <td>Capital Industrial</td>\n",
       "      <td>2018-12-19 15:39:27.750000</td>\n",
       "      <td>2018-12-19 16:00:00</td>\n",
       "      <td>Hyundai</td>\n",
       "      <td>Elantra</td>\n",
       "      <td>2016</td>\n",
       "      <td>white</td>\n",
       "      <td>6655</td>\n",
       "      <td>5355</td>\n",
       "      <td>12011</td>\n",
       "      <td>Insurance Company</td>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>['Bumper', 'Decoration', 'Fender', 'Headlight'...</td>\n",
       "      <td>['front', 'front right', 'right', 'undefined']</td>\n",
       "      <td>['New']</td>\n",
       "      <td>Korea</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Multi</td>\n",
       "      <td>24.276377</td>\n",
       "      <td>Acceptable</td>\n",
       "      <td>5</td>\n",
       "      <td>Acceptable</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251470</th>\n",
       "      <td>253392</td>\n",
       "      <td>Remmal Industrial</td>\n",
       "      <td>2018-12-19 17:22:22.537000</td>\n",
       "      <td>2018-12-19 17:36:00</td>\n",
       "      <td>Chevrolet</td>\n",
       "      <td>Malibu</td>\n",
       "      <td>2011</td>\n",
       "      <td>silver</td>\n",
       "      <td>2600</td>\n",
       "      <td>600</td>\n",
       "      <td>3200</td>\n",
       "      <td>Insurance Company</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>['Dash insulator']</td>\n",
       "      <td>['front left', 'rear left']</td>\n",
       "      <td>['New']</td>\n",
       "      <td>US</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Multi</td>\n",
       "      <td>333.333333</td>\n",
       "      <td>unacceptable</td>\n",
       "      <td>1</td>\n",
       "      <td>Acceptable</td>\n",
       "      <td>Evening</td>\n",
       "      <td>Acceptable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251471</th>\n",
       "      <td>253393</td>\n",
       "      <td>New Industrial</td>\n",
       "      <td>2018-12-19 15:41:18.967000</td>\n",
       "      <td>2018-12-19 15:56:00</td>\n",
       "      <td>Hyundai</td>\n",
       "      <td>Elantra</td>\n",
       "      <td>2016</td>\n",
       "      <td>white</td>\n",
       "      <td>1673</td>\n",
       "      <td>273</td>\n",
       "      <td>1947</td>\n",
       "      <td>POS</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>['Mudguard', 'Splash shield']</td>\n",
       "      <td>['rear left']</td>\n",
       "      <td>['New']</td>\n",
       "      <td>Korea</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Multi</td>\n",
       "      <td>512.820513</td>\n",
       "      <td>unacceptable</td>\n",
       "      <td>2</td>\n",
       "      <td>Acceptable</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251472</th>\n",
       "      <td>253395</td>\n",
       "      <td>Capital Industrial</td>\n",
       "      <td>2018-12-19 15:32:21.193000</td>\n",
       "      <td>2018-12-19 15:54:00</td>\n",
       "      <td>Hyundai</td>\n",
       "      <td>Sonata</td>\n",
       "      <td>2014</td>\n",
       "      <td>silver</td>\n",
       "      <td>5191</td>\n",
       "      <td>2991</td>\n",
       "      <td>8182</td>\n",
       "      <td>Insurance Company</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>['Door']</td>\n",
       "      <td>['front left']</td>\n",
       "      <td>['New']</td>\n",
       "      <td>Korea</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Multi</td>\n",
       "      <td>73.553995</td>\n",
       "      <td>Very High</td>\n",
       "      <td>1</td>\n",
       "      <td>Acceptable</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>Acceptable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>251473 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          c_id                Area            RegistrationTime  \\\n",
       "0           51        Truck Center  2018-01-01 09:13:36.437000   \n",
       "1           54        Truck Center  2018-01-01 08:37:46.137000   \n",
       "2           94              Orouba  2018-01-01 10:17:57.727000   \n",
       "3           99              Orouba  2018-01-01 10:25:36.453000   \n",
       "4          103      New Industrial  2018-01-01 10:42:32.120000   \n",
       "...        ...                 ...                         ...   \n",
       "251468  253390      New Industrial  2018-12-18 14:25:26.810000   \n",
       "251469  253391  Capital Industrial  2018-12-19 15:39:27.750000   \n",
       "251470  253392   Remmal Industrial  2018-12-19 17:22:22.537000   \n",
       "251471  253393      New Industrial  2018-12-19 15:41:18.967000   \n",
       "251472  253395  Capital Industrial  2018-12-19 15:32:21.193000   \n",
       "\n",
       "                  CloseTime   CarBrand CarModel  ManufactureYear CarColor  \\\n",
       "0       2018-01-01 09:29:00      Volvo     head             2002      red   \n",
       "1       2018-01-01 08:51:00      Volvo     head             2008      red   \n",
       "2       2018-01-01 10:25:00        BMW    Sedan             2012    white   \n",
       "3       2018-01-01 10:52:00    Hyundai  Genesis             2011   silver   \n",
       "4       2018-01-01 10:56:00      Lexus       IS             2007   brouwn   \n",
       "...                     ...        ...      ...              ...      ...   \n",
       "251468  2018-12-18 15:57:00      Isuzu      Two             2016    white   \n",
       "251469  2018-12-19 16:00:00    Hyundai  Elantra             2016    white   \n",
       "251470  2018-12-19 17:36:00  Chevrolet   Malibu             2011   silver   \n",
       "251471  2018-12-19 15:56:00    Hyundai  Elantra             2016    white   \n",
       "251472  2018-12-19 15:54:00    Hyundai   Sonata             2014   silver   \n",
       "\n",
       "        AssessmentCost  SparePartCost  TotalCost        PaymentType  \\\n",
       "0                 2455           1255       3710                POS   \n",
       "1                 6510           5310      11820                POS   \n",
       "2                 5778           4778      10556  Insurance Company   \n",
       "3                 1043            343       1386                POS   \n",
       "4                 1609            409       2019  Insurance Company   \n",
       "...                ...            ...        ...                ...   \n",
       "251468            2540           1040       3580  Insurance Company   \n",
       "251469            6655           5355      12011  Insurance Company   \n",
       "251470            2600            600       3200  Insurance Company   \n",
       "251471            1673            273       1947                POS   \n",
       "251472            5191           2991       8182  Insurance Company   \n",
       "\n",
       "        DurationTime  Hour  Month  Day    WeekDay  \\\n",
       "0                 15     9      1    1     Monday   \n",
       "1                 13     8      1    1     Monday   \n",
       "2                  7    10      1    1     Monday   \n",
       "3                 26    10      1    1     Monday   \n",
       "4                 13    10      1    1     Monday   \n",
       "...              ...   ...    ...  ...        ...   \n",
       "251468            91    14     12   18    Tuesday   \n",
       "251469            20    15     12   19  Wednesday   \n",
       "251470            13    17     12   19  Wednesday   \n",
       "251471            14    15     12   19  Wednesday   \n",
       "251472            21    15     12   19  Wednesday   \n",
       "\n",
       "                                                PartsList  \\\n",
       "0          ['Decoration', 'Fender', 'Other', 'Taillight']   \n",
       "1          ['Bumper', 'Decoration', 'Other', 'Taillight']   \n",
       "2                                              ['Bumper']   \n",
       "3                                              ['Sensor']   \n",
       "4                                    ['Bumper', 'Sensor']   \n",
       "...                                                   ...   \n",
       "251468                                  ['Other', 'Rims']   \n",
       "251469  ['Bumper', 'Decoration', 'Fender', 'Headlight'...   \n",
       "251470                                 ['Dash insulator']   \n",
       "251471                      ['Mudguard', 'Splash shield']   \n",
       "251472                                           ['Door']   \n",
       "\n",
       "                                          PositionList PartStateList  CarMade  \\\n",
       "0                  ['front left', 'left', 'rear left']       ['New']   Sweden   \n",
       "1                             ['front right', 'right']       ['New']   Sweden   \n",
       "2                                             ['rear']       ['New']  Germany   \n",
       "3                                        ['undefined']       ['New']    Korea   \n",
       "4                             ['front', 'front right']       ['New']    Japan   \n",
       "...                                                ...           ...      ...   \n",
       "251468                                  ['rear right']       ['New']    Japan   \n",
       "251469  ['front', 'front right', 'right', 'undefined']       ['New']    Korea   \n",
       "251470                     ['front left', 'rear left']       ['New']       US   \n",
       "251471                                   ['rear left']       ['New']    Korea   \n",
       "251472                                  ['front left']       ['New']    Korea   \n",
       "\n",
       "       CarClass CarType  SparePart_Differace% AssessmentEvaluation  \\\n",
       "0        Luxury   Multi             95.617530         unacceptable   \n",
       "1        Luxury   Multi             22.598870           Acceptable   \n",
       "2        Luxury     Car             20.929259           Acceptable   \n",
       "3        Luxury   Multi            204.081633         unacceptable   \n",
       "4        Luxury     Car            293.398533         unacceptable   \n",
       "...         ...     ...                   ...                  ...   \n",
       "251468   Normal   Multi            144.230769         unacceptable   \n",
       "251469   Normal   Multi             24.276377           Acceptable   \n",
       "251470   Normal   Multi            333.333333         unacceptable   \n",
       "251471   Normal   Multi            512.820513         unacceptable   \n",
       "251472   Normal   Multi             73.553995            Very High   \n",
       "\n",
       "        PartsNumber TimeEvaluation  PartOfDay TotalCostEvaluation  \n",
       "0                 4     Acceptable    Morning                 Low  \n",
       "1                 4     Acceptable    Morning          Acceptable  \n",
       "2                 1           Fast    Morning          Acceptable  \n",
       "3                 1          Delay    Morning                 Low  \n",
       "4                 2     Acceptable    Morning                 Low  \n",
       "...             ...            ...        ...                 ...  \n",
       "251468            2          Delay  Afternoon          Acceptable  \n",
       "251469            5     Acceptable  Afternoon                High  \n",
       "251470            1     Acceptable    Evening          Acceptable  \n",
       "251471            2     Acceptable  Afternoon                 Low  \n",
       "251472            1     Acceptable  Afternoon          Acceptable  \n",
       "\n",
       "[251473 rows x 29 columns]"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('Dataframes/en_ML_df.csv')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To convert string to list \n",
    "df['PartsList'] = df['PartsList'].apply(lambda x : ast.literal_eval(x))\n",
    "df['PositionList'] = df['PositionList'].apply(lambda x : ast.literal_eval(x))\n",
    "df['PartStateList'] = df['PartStateList'].apply(lambda x : ast.literal_eval(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bumper', 'Decoration', 'Other', 'Taillight']"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[1,'PartsList']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_id</th>\n",
       "      <th>Area</th>\n",
       "      <th>RegistrationTime</th>\n",
       "      <th>CloseTime</th>\n",
       "      <th>CarBrand</th>\n",
       "      <th>CarModel</th>\n",
       "      <th>ManufactureYear</th>\n",
       "      <th>CarColor</th>\n",
       "      <th>AssessmentCost</th>\n",
       "      <th>SparePartCost</th>\n",
       "      <th>TotalCost</th>\n",
       "      <th>PaymentType</th>\n",
       "      <th>DurationTime</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>WeekDay</th>\n",
       "      <th>PartsList</th>\n",
       "      <th>PositionList</th>\n",
       "      <th>PartStateList</th>\n",
       "      <th>CarMade</th>\n",
       "      <th>CarClass</th>\n",
       "      <th>CarType</th>\n",
       "      <th>SparePart_Differace%</th>\n",
       "      <th>AssessmentEvaluation</th>\n",
       "      <th>PartsNumber</th>\n",
       "      <th>TimeEvaluation</th>\n",
       "      <th>PartOfDay</th>\n",
       "      <th>TotalCostEvaluation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51</td>\n",
       "      <td>Truck Center</td>\n",
       "      <td>2018-01-01 09:13:36.437000</td>\n",
       "      <td>2018-01-01 09:29:00</td>\n",
       "      <td>Volvo</td>\n",
       "      <td>head</td>\n",
       "      <td>2002</td>\n",
       "      <td>red</td>\n",
       "      <td>2455</td>\n",
       "      <td>1255</td>\n",
       "      <td>3710</td>\n",
       "      <td>POS</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Monday</td>\n",
       "      <td>[Decoration, Fender, Other, Taillight]</td>\n",
       "      <td>[front left, left, rear left]</td>\n",
       "      <td>[New]</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Luxury</td>\n",
       "      <td>Multi</td>\n",
       "      <td>95.617530</td>\n",
       "      <td>unacceptable</td>\n",
       "      <td>4</td>\n",
       "      <td>Acceptable</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54</td>\n",
       "      <td>Truck Center</td>\n",
       "      <td>2018-01-01 08:37:46.137000</td>\n",
       "      <td>2018-01-01 08:51:00</td>\n",
       "      <td>Volvo</td>\n",
       "      <td>head</td>\n",
       "      <td>2008</td>\n",
       "      <td>red</td>\n",
       "      <td>6510</td>\n",
       "      <td>5310</td>\n",
       "      <td>11820</td>\n",
       "      <td>POS</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Monday</td>\n",
       "      <td>[Bumper, Decoration, Other, Taillight]</td>\n",
       "      <td>[front right, right]</td>\n",
       "      <td>[New]</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Luxury</td>\n",
       "      <td>Multi</td>\n",
       "      <td>22.598870</td>\n",
       "      <td>Acceptable</td>\n",
       "      <td>4</td>\n",
       "      <td>Acceptable</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Acceptable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94</td>\n",
       "      <td>Orouba</td>\n",
       "      <td>2018-01-01 10:17:57.727000</td>\n",
       "      <td>2018-01-01 10:25:00</td>\n",
       "      <td>BMW</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>2012</td>\n",
       "      <td>white</td>\n",
       "      <td>5778</td>\n",
       "      <td>4778</td>\n",
       "      <td>10556</td>\n",
       "      <td>Insurance Company</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Monday</td>\n",
       "      <td>[Bumper]</td>\n",
       "      <td>[rear]</td>\n",
       "      <td>[New]</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Luxury</td>\n",
       "      <td>Car</td>\n",
       "      <td>20.929259</td>\n",
       "      <td>Acceptable</td>\n",
       "      <td>1</td>\n",
       "      <td>Fast</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Acceptable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99</td>\n",
       "      <td>Orouba</td>\n",
       "      <td>2018-01-01 10:25:36.453000</td>\n",
       "      <td>2018-01-01 10:52:00</td>\n",
       "      <td>Hyundai</td>\n",
       "      <td>Genesis</td>\n",
       "      <td>2011</td>\n",
       "      <td>silver</td>\n",
       "      <td>1043</td>\n",
       "      <td>343</td>\n",
       "      <td>1386</td>\n",
       "      <td>POS</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Monday</td>\n",
       "      <td>[Sensor]</td>\n",
       "      <td>[undefined]</td>\n",
       "      <td>[New]</td>\n",
       "      <td>Korea</td>\n",
       "      <td>Luxury</td>\n",
       "      <td>Multi</td>\n",
       "      <td>204.081633</td>\n",
       "      <td>unacceptable</td>\n",
       "      <td>1</td>\n",
       "      <td>Delay</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>103</td>\n",
       "      <td>New Industrial</td>\n",
       "      <td>2018-01-01 10:42:32.120000</td>\n",
       "      <td>2018-01-01 10:56:00</td>\n",
       "      <td>Lexus</td>\n",
       "      <td>IS</td>\n",
       "      <td>2007</td>\n",
       "      <td>brouwn</td>\n",
       "      <td>1609</td>\n",
       "      <td>409</td>\n",
       "      <td>2019</td>\n",
       "      <td>Insurance Company</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Monday</td>\n",
       "      <td>[Bumper, Sensor]</td>\n",
       "      <td>[front, front right]</td>\n",
       "      <td>[New]</td>\n",
       "      <td>Japan</td>\n",
       "      <td>Luxury</td>\n",
       "      <td>Car</td>\n",
       "      <td>293.398533</td>\n",
       "      <td>unacceptable</td>\n",
       "      <td>2</td>\n",
       "      <td>Acceptable</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   c_id            Area            RegistrationTime            CloseTime  \\\n",
       "0    51    Truck Center  2018-01-01 09:13:36.437000  2018-01-01 09:29:00   \n",
       "1    54    Truck Center  2018-01-01 08:37:46.137000  2018-01-01 08:51:00   \n",
       "2    94          Orouba  2018-01-01 10:17:57.727000  2018-01-01 10:25:00   \n",
       "3    99          Orouba  2018-01-01 10:25:36.453000  2018-01-01 10:52:00   \n",
       "4   103  New Industrial  2018-01-01 10:42:32.120000  2018-01-01 10:56:00   \n",
       "\n",
       "  CarBrand CarModel  ManufactureYear CarColor  AssessmentCost  SparePartCost  \\\n",
       "0    Volvo     head             2002      red            2455           1255   \n",
       "1    Volvo     head             2008      red            6510           5310   \n",
       "2      BMW    Sedan             2012    white            5778           4778   \n",
       "3  Hyundai  Genesis             2011   silver            1043            343   \n",
       "4    Lexus       IS             2007   brouwn            1609            409   \n",
       "\n",
       "   TotalCost        PaymentType  DurationTime  Hour  Month  Day WeekDay  \\\n",
       "0       3710                POS            15     9      1    1  Monday   \n",
       "1      11820                POS            13     8      1    1  Monday   \n",
       "2      10556  Insurance Company             7    10      1    1  Monday   \n",
       "3       1386                POS            26    10      1    1  Monday   \n",
       "4       2019  Insurance Company            13    10      1    1  Monday   \n",
       "\n",
       "                                PartsList                   PositionList  \\\n",
       "0  [Decoration, Fender, Other, Taillight]  [front left, left, rear left]   \n",
       "1  [Bumper, Decoration, Other, Taillight]           [front right, right]   \n",
       "2                                [Bumper]                         [rear]   \n",
       "3                                [Sensor]                    [undefined]   \n",
       "4                        [Bumper, Sensor]           [front, front right]   \n",
       "\n",
       "  PartStateList  CarMade CarClass CarType  SparePart_Differace%  \\\n",
       "0         [New]   Sweden   Luxury   Multi             95.617530   \n",
       "1         [New]   Sweden   Luxury   Multi             22.598870   \n",
       "2         [New]  Germany   Luxury     Car             20.929259   \n",
       "3         [New]    Korea   Luxury   Multi            204.081633   \n",
       "4         [New]    Japan   Luxury     Car            293.398533   \n",
       "\n",
       "  AssessmentEvaluation  PartsNumber TimeEvaluation PartOfDay  \\\n",
       "0         unacceptable            4     Acceptable   Morning   \n",
       "1           Acceptable            4     Acceptable   Morning   \n",
       "2           Acceptable            1           Fast   Morning   \n",
       "3         unacceptable            1          Delay   Morning   \n",
       "4         unacceptable            2     Acceptable   Morning   \n",
       "\n",
       "  TotalCostEvaluation  \n",
       "0                 Low  \n",
       "1          Acceptable  \n",
       "2          Acceptable  \n",
       "3                 Low  \n",
       "4                 Low  "
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id='ML_Reg'></a>\n",
    "# ML Regression Section \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function to calculate the cost function for models and the base line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function to calculate the model cost and get the baseline of regressoin models \n",
    "# It's take the actual label and predicted label the calculate the cost functions and if the user pass only the actual label and make the baseline parameter Ture then \n",
    "# the function will take the mean of the label and apply the cost function\n",
    "def calc_cost_regrs(y_true, y_predict=None, baseline=False):\n",
    "\n",
    "    # Check if user make the base line true if yes then i will make the y_predict as mean of the actual label \n",
    "    if baseline:\n",
    "        y_predict = [y_true.mean() for x in range(len(y_true))]\n",
    "    \n",
    "    # To Save all results of cost fucnitons here \n",
    "    result_dict = {}\n",
    "    \n",
    "    # Cost Functions \n",
    "    mse = mean_squared_error(y_true, y_predict)\n",
    "    mae = mean_absolute_error(y_true, y_predict)\n",
    "    rmse = mean_squared_error(y_true, y_predict, squared=False)\n",
    "    r2=r2_score(y_true, y_predict)\n",
    "    \n",
    "    ls = [mse, mae, rmse, r2]\n",
    "    ls2 = [\"MSE\", \"MAE\", \"RMSE\", \"R2\"]\n",
    "    \n",
    "    # Add the cost functions on the decleared variable \n",
    "    for x in range(len(ls)):\n",
    "        print(f\"{ls2[x]}: {ls[x]}\")\n",
    "        result_dict[ls2[x]] = ls[x]\n",
    "    \n",
    "    return result_dict\n",
    "\n",
    "# Function just to print the model accuracy \n",
    "def getAccuracy(X_test, y_test, model, X_train=None,y_train=None, title='of the model'):\n",
    "    try:\n",
    "            train_score = model.score(X_train, y_train)*100\n",
    "            test_score = model.score(X_test, y_test)*100\n",
    "            print(f'| Training Accuracy | Testing Accuracy |\\n|     {round(train_score,2)}         |    {round(test_score,2)}         |')\n",
    "\n",
    "            # Subtract the train score and test score then round it to 2 decimal\n",
    "            diff  = round(train_score-test_score,2)\n",
    "\n",
    "            # Print the differance\n",
    "            print(f'The differance betewen the train accuracy and test accuracy is: {diff}%')\n",
    "\n",
    "            # If the differance greater thean 25% maybe there is an overfiting and if greater thean 10 this is good model and if greater than 0 or equal then this great model else will be an underfitting\n",
    "            if diff >=20:\n",
    "                print('So maybe there is an (Overfiting)')\n",
    "            elif diff>10:\n",
    "                print('The model in general is (Good)')\n",
    "            elif diff>=0:\n",
    "                print('The model is (Great)')\n",
    "            else:\n",
    "                print('So maybe there is an (Underfiting)')\n",
    "    except:\n",
    "        print(f'The Accuracy {title} is : ({model.score(X_test, y_test)*100})\\n')\n",
    "\n",
    "\n",
    "\n",
    "# Functions to get the differance between two paased dictonries of cost functions and if normlaize is ture then will print the differance in percentage\n",
    "def cost_diff_reg(res1, res2, normalize=False):\n",
    "    diff_res={}\n",
    "    for k, v in res1.items():\n",
    "        diff_res[k] = (res1[k] - res2[k])\n",
    "        if normalize:\n",
    "            diff_res[k] = round((diff_res[k]/res1[k])*100, 3)  \n",
    "\n",
    "    # If the erros with negitave sign then the error is increesing  by the precentage else is decreesing \n",
    "    print(f'The Erros is decreesing by:')\n",
    "    for k, v in diff_res.items():\n",
    "        if not normalize:\n",
    "            print(f\"{k}: {v}\")\n",
    "        else:\n",
    "            print(f\"{k}: {v} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take copy from original dataframe to apply the regression model\n",
    "reg_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dummies for parts regression dataframe \n",
    "reg_df = reg_df.join(reg_df['PartsList'].str.join('|').str.get_dummies().add_prefix('part_'))\n",
    "reg_df = reg_df.join(reg_df['PositionList'].str.join('|').str.get_dummies().add_prefix('pos_'))\n",
    "reg_df = reg_df.join(reg_df['PartStateList'].str.join('|').str.get_dummies().add_prefix('state_'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_id</th>\n",
       "      <th>Area</th>\n",
       "      <th>RegistrationTime</th>\n",
       "      <th>CloseTime</th>\n",
       "      <th>CarBrand</th>\n",
       "      <th>CarModel</th>\n",
       "      <th>ManufactureYear</th>\n",
       "      <th>CarColor</th>\n",
       "      <th>AssessmentCost</th>\n",
       "      <th>SparePartCost</th>\n",
       "      <th>TotalCost</th>\n",
       "      <th>PaymentType</th>\n",
       "      <th>DurationTime</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>WeekDay</th>\n",
       "      <th>PartsList</th>\n",
       "      <th>PositionList</th>\n",
       "      <th>PartStateList</th>\n",
       "      <th>CarMade</th>\n",
       "      <th>CarClass</th>\n",
       "      <th>CarType</th>\n",
       "      <th>SparePart_Differace%</th>\n",
       "      <th>AssessmentEvaluation</th>\n",
       "      <th>PartsNumber</th>\n",
       "      <th>TimeEvaluation</th>\n",
       "      <th>PartOfDay</th>\n",
       "      <th>TotalCostEvaluation</th>\n",
       "      <th>part_Bridge</th>\n",
       "      <th>part_Bumper</th>\n",
       "      <th>part_Coilover</th>\n",
       "      <th>part_Control Arms</th>\n",
       "      <th>part_Dash insulator</th>\n",
       "      <th>part_Decoration</th>\n",
       "      <th>part_Door</th>\n",
       "      <th>part_Fender</th>\n",
       "      <th>part_Fiber</th>\n",
       "      <th>part_Grill</th>\n",
       "      <th>part_Handle</th>\n",
       "      <th>part_Headlight</th>\n",
       "      <th>part_Hinges</th>\n",
       "      <th>part_Hood</th>\n",
       "      <th>part_Injection</th>\n",
       "      <th>part_Mirror</th>\n",
       "      <th>part_Mudguard</th>\n",
       "      <th>part_Muffler</th>\n",
       "      <th>part_Other</th>\n",
       "      <th>part_Power Window</th>\n",
       "      <th>part_Radiator</th>\n",
       "      <th>part_Rims</th>\n",
       "      <th>part_Rotor</th>\n",
       "      <th>part_Sensor</th>\n",
       "      <th>part_Shock absorber</th>\n",
       "      <th>part_Splash shield</th>\n",
       "      <th>part_Stabilizer link</th>\n",
       "      <th>part_Taillight</th>\n",
       "      <th>part_Tie rod</th>\n",
       "      <th>part_Tire</th>\n",
       "      <th>part_Windshild</th>\n",
       "      <th>pos_front</th>\n",
       "      <th>pos_front left</th>\n",
       "      <th>pos_front right</th>\n",
       "      <th>pos_left</th>\n",
       "      <th>pos_rear</th>\n",
       "      <th>pos_rear left</th>\n",
       "      <th>pos_rear right</th>\n",
       "      <th>pos_right</th>\n",
       "      <th>pos_undefined</th>\n",
       "      <th>state_New</th>\n",
       "      <th>state_Used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51</td>\n",
       "      <td>Truck Center</td>\n",
       "      <td>2018-01-01 09:13:36.437000</td>\n",
       "      <td>2018-01-01 09:29:00</td>\n",
       "      <td>Volvo</td>\n",
       "      <td>head</td>\n",
       "      <td>2002</td>\n",
       "      <td>red</td>\n",
       "      <td>2455</td>\n",
       "      <td>1255</td>\n",
       "      <td>3710</td>\n",
       "      <td>POS</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Monday</td>\n",
       "      <td>[Decoration, Fender, Other, Taillight]</td>\n",
       "      <td>[front left, left, rear left]</td>\n",
       "      <td>[New]</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Luxury</td>\n",
       "      <td>Multi</td>\n",
       "      <td>95.61753</td>\n",
       "      <td>unacceptable</td>\n",
       "      <td>4</td>\n",
       "      <td>Acceptable</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   c_id          Area            RegistrationTime            CloseTime  \\\n",
       "0    51  Truck Center  2018-01-01 09:13:36.437000  2018-01-01 09:29:00   \n",
       "\n",
       "  CarBrand CarModel  ManufactureYear CarColor  AssessmentCost  SparePartCost  \\\n",
       "0    Volvo     head             2002      red            2455           1255   \n",
       "\n",
       "   TotalCost PaymentType  DurationTime  Hour  Month  Day WeekDay  \\\n",
       "0       3710         POS            15     9      1    1  Monday   \n",
       "\n",
       "                                PartsList                   PositionList  \\\n",
       "0  [Decoration, Fender, Other, Taillight]  [front left, left, rear left]   \n",
       "\n",
       "  PartStateList CarMade CarClass CarType  SparePart_Differace%  \\\n",
       "0         [New]  Sweden   Luxury   Multi              95.61753   \n",
       "\n",
       "  AssessmentEvaluation  PartsNumber TimeEvaluation PartOfDay  \\\n",
       "0         unacceptable            4     Acceptable   Morning   \n",
       "\n",
       "  TotalCostEvaluation  part_Bridge  part_Bumper  part_Coilover  \\\n",
       "0                 Low            0            0              0   \n",
       "\n",
       "   part_Control Arms  part_Dash insulator  part_Decoration  part_Door  \\\n",
       "0                  0                    0                1          0   \n",
       "\n",
       "   part_Fender  part_Fiber  part_Grill  part_Handle  part_Headlight  \\\n",
       "0            1           0           0            0               0   \n",
       "\n",
       "   part_Hinges  part_Hood  part_Injection  part_Mirror  part_Mudguard  \\\n",
       "0            0          0               0            0              0   \n",
       "\n",
       "   part_Muffler  part_Other  part_Power Window  part_Radiator  part_Rims  \\\n",
       "0             0           1                  0              0          0   \n",
       "\n",
       "   part_Rotor  part_Sensor  part_Shock absorber  part_Splash shield  \\\n",
       "0           0            0                    0                   0   \n",
       "\n",
       "   part_Stabilizer link  part_Taillight  part_Tie rod  part_Tire  \\\n",
       "0                     0               1             0          0   \n",
       "\n",
       "   part_Windshild   pos_front  pos_front left  pos_front right  pos_left  \\\n",
       "0                0          0               1                0         1   \n",
       "\n",
       "   pos_rear  pos_rear left  pos_rear right  pos_right  pos_undefined  \\\n",
       "0         0              1               0          0              0   \n",
       "\n",
       "   state_New  state_Used  \n",
       "0          1           0  "
      ]
     },
     "execution_count": 598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unwanted columns from Regression Training\n",
    "unwanted_cols = ['c_id','RegistrationTime', 'CloseTime', 'Hour','Month', 'Day', 'WeekDay', 'PartsList', 'PositionList', 'PartStateList']\n",
    "unwanted_cols.append('AssessmentCost')\n",
    "unwanted_cols.append('SparePartCost')\n",
    "unwanted_cols.append('SparePart_Differace%')\n",
    "unwanted_cols.append('AssessmentEvaluation')\n",
    "unwanted_cols.append('TotalCostEvaluation')\n",
    "\n",
    "unwanted_cols.append('TimeEvaluation')\n",
    "unwanted_cols.append('DurationTime')\n",
    "\n",
    "unwanted_cols.append('CarColor')\n",
    "unwanted_cols.append('CarClass')\n",
    "# unwanted_cols.append('PartsNumber')\n",
    "\n",
    "\n",
    "\n",
    "target = 'TotalCost'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_df.drop(unwanted_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>CarBrand</th>\n",
       "      <th>CarModel</th>\n",
       "      <th>ManufactureYear</th>\n",
       "      <th>TotalCost</th>\n",
       "      <th>PaymentType</th>\n",
       "      <th>CarMade</th>\n",
       "      <th>CarType</th>\n",
       "      <th>PartsNumber</th>\n",
       "      <th>PartOfDay</th>\n",
       "      <th>part_Bridge</th>\n",
       "      <th>part_Bumper</th>\n",
       "      <th>part_Coilover</th>\n",
       "      <th>part_Control Arms</th>\n",
       "      <th>part_Dash insulator</th>\n",
       "      <th>part_Decoration</th>\n",
       "      <th>part_Door</th>\n",
       "      <th>part_Fender</th>\n",
       "      <th>part_Fiber</th>\n",
       "      <th>part_Grill</th>\n",
       "      <th>part_Handle</th>\n",
       "      <th>part_Headlight</th>\n",
       "      <th>part_Hinges</th>\n",
       "      <th>part_Hood</th>\n",
       "      <th>part_Injection</th>\n",
       "      <th>part_Mirror</th>\n",
       "      <th>part_Mudguard</th>\n",
       "      <th>part_Muffler</th>\n",
       "      <th>part_Other</th>\n",
       "      <th>part_Power Window</th>\n",
       "      <th>part_Radiator</th>\n",
       "      <th>part_Rims</th>\n",
       "      <th>part_Rotor</th>\n",
       "      <th>part_Sensor</th>\n",
       "      <th>part_Shock absorber</th>\n",
       "      <th>part_Splash shield</th>\n",
       "      <th>part_Stabilizer link</th>\n",
       "      <th>part_Taillight</th>\n",
       "      <th>part_Tie rod</th>\n",
       "      <th>part_Tire</th>\n",
       "      <th>part_Windshild</th>\n",
       "      <th>pos_front</th>\n",
       "      <th>pos_front left</th>\n",
       "      <th>pos_front right</th>\n",
       "      <th>pos_left</th>\n",
       "      <th>pos_rear</th>\n",
       "      <th>pos_rear left</th>\n",
       "      <th>pos_rear right</th>\n",
       "      <th>pos_right</th>\n",
       "      <th>pos_undefined</th>\n",
       "      <th>state_New</th>\n",
       "      <th>state_Used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Truck Center</td>\n",
       "      <td>Volvo</td>\n",
       "      <td>head</td>\n",
       "      <td>2002</td>\n",
       "      <td>3710</td>\n",
       "      <td>POS</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Multi</td>\n",
       "      <td>4</td>\n",
       "      <td>Morning</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Area CarBrand CarModel  ManufactureYear  TotalCost PaymentType  \\\n",
       "0  Truck Center    Volvo     head             2002       3710         POS   \n",
       "\n",
       "  CarMade CarType  PartsNumber PartOfDay  part_Bridge  part_Bumper  \\\n",
       "0  Sweden   Multi            4   Morning            0            0   \n",
       "\n",
       "   part_Coilover  part_Control Arms  part_Dash insulator  part_Decoration  \\\n",
       "0              0                  0                    0                1   \n",
       "\n",
       "   part_Door  part_Fender  part_Fiber  part_Grill  part_Handle  \\\n",
       "0          0            1           0           0            0   \n",
       "\n",
       "   part_Headlight  part_Hinges  part_Hood  part_Injection  part_Mirror  \\\n",
       "0               0            0          0               0            0   \n",
       "\n",
       "   part_Mudguard  part_Muffler  part_Other  part_Power Window  part_Radiator  \\\n",
       "0              0             0           1                  0              0   \n",
       "\n",
       "   part_Rims  part_Rotor  part_Sensor  part_Shock absorber  \\\n",
       "0          0           0            0                    0   \n",
       "\n",
       "   part_Splash shield  part_Stabilizer link  part_Taillight  part_Tie rod  \\\n",
       "0                   0                     0               1             0   \n",
       "\n",
       "   part_Tire  part_Windshild   pos_front  pos_front left  pos_front right  \\\n",
       "0          0                0          0               1                0   \n",
       "\n",
       "   pos_left  pos_rear  pos_rear left  pos_rear right  pos_right  \\\n",
       "0         1         0              1               0          0   \n",
       "\n",
       "   pos_undefined  state_New  state_Used  \n",
       "0              0          1           0  "
      ]
     },
     "execution_count": 601,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>CarBrand</th>\n",
       "      <th>CarModel</th>\n",
       "      <th>ManufactureYear</th>\n",
       "      <th>TotalCost</th>\n",
       "      <th>PaymentType</th>\n",
       "      <th>CarMade</th>\n",
       "      <th>CarType</th>\n",
       "      <th>PartsNumber</th>\n",
       "      <th>PartOfDay</th>\n",
       "      <th>part_Bridge</th>\n",
       "      <th>part_Bumper</th>\n",
       "      <th>part_Coilover</th>\n",
       "      <th>part_Control Arms</th>\n",
       "      <th>part_Dash insulator</th>\n",
       "      <th>part_Decoration</th>\n",
       "      <th>part_Door</th>\n",
       "      <th>part_Fender</th>\n",
       "      <th>part_Fiber</th>\n",
       "      <th>part_Grill</th>\n",
       "      <th>part_Handle</th>\n",
       "      <th>part_Headlight</th>\n",
       "      <th>part_Hinges</th>\n",
       "      <th>part_Hood</th>\n",
       "      <th>part_Injection</th>\n",
       "      <th>part_Mirror</th>\n",
       "      <th>part_Mudguard</th>\n",
       "      <th>part_Muffler</th>\n",
       "      <th>part_Other</th>\n",
       "      <th>part_Power Window</th>\n",
       "      <th>part_Radiator</th>\n",
       "      <th>part_Rims</th>\n",
       "      <th>part_Rotor</th>\n",
       "      <th>part_Sensor</th>\n",
       "      <th>part_Shock absorber</th>\n",
       "      <th>part_Splash shield</th>\n",
       "      <th>part_Stabilizer link</th>\n",
       "      <th>part_Taillight</th>\n",
       "      <th>part_Tie rod</th>\n",
       "      <th>part_Tire</th>\n",
       "      <th>part_Windshild</th>\n",
       "      <th>pos_front</th>\n",
       "      <th>pos_front left</th>\n",
       "      <th>pos_front right</th>\n",
       "      <th>pos_left</th>\n",
       "      <th>pos_rear</th>\n",
       "      <th>pos_rear left</th>\n",
       "      <th>pos_rear right</th>\n",
       "      <th>pos_right</th>\n",
       "      <th>pos_undefined</th>\n",
       "      <th>state_New</th>\n",
       "      <th>state_Used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>96</td>\n",
       "      <td>815</td>\n",
       "      <td>2002</td>\n",
       "      <td>3710</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>96</td>\n",
       "      <td>815</td>\n",
       "      <td>2008</td>\n",
       "      <td>11820</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>655</td>\n",
       "      <td>2012</td>\n",
       "      <td>10556</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>362</td>\n",
       "      <td>2011</td>\n",
       "      <td>1386</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>412</td>\n",
       "      <td>2007</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251468</th>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>740</td>\n",
       "      <td>2016</td>\n",
       "      <td>3580</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251469</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>278</td>\n",
       "      <td>2016</td>\n",
       "      <td>12011</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251470</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>505</td>\n",
       "      <td>2011</td>\n",
       "      <td>3200</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251471</th>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>278</td>\n",
       "      <td>2016</td>\n",
       "      <td>1947</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251472</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>674</td>\n",
       "      <td>2014</td>\n",
       "      <td>8182</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>251473 rows Ã— 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Area  CarBrand  CarModel  ManufactureYear  TotalCost  PaymentType  \\\n",
       "0          4        96       815             2002       3710            1   \n",
       "1          4        96       815             2008      11820            1   \n",
       "2          2         5       655             2012      10556            0   \n",
       "3          2        37       362             2011       1386            1   \n",
       "4          1        50       412             2007       2019            0   \n",
       "...      ...       ...       ...              ...        ...          ...   \n",
       "251468     1        40       740             2016       3580            0   \n",
       "251469     0        37       278             2016      12011            0   \n",
       "251470     3        12       505             2011       3200            0   \n",
       "251471     1        37       278             2016       1947            1   \n",
       "251472     0        37       674             2014       8182            0   \n",
       "\n",
       "        CarMade  CarType  PartsNumber  PartOfDay  part_Bridge  part_Bumper  \\\n",
       "0            13        1            4          2            0            0   \n",
       "1            13        1            4          2            0            1   \n",
       "2             5        0            1          2            0            1   \n",
       "3             9        1            1          2            0            0   \n",
       "4             8        0            2          2            0            1   \n",
       "...         ...      ...          ...        ...          ...          ...   \n",
       "251468        8        1            2          0            0            0   \n",
       "251469        9        1            5          0            0            1   \n",
       "251470       16        1            1          1            0            0   \n",
       "251471        9        1            2          0            0            0   \n",
       "251472        9        1            1          0            0            0   \n",
       "\n",
       "        part_Coilover  part_Control Arms  part_Dash insulator  \\\n",
       "0                   0                  0                    0   \n",
       "1                   0                  0                    0   \n",
       "2                   0                  0                    0   \n",
       "3                   0                  0                    0   \n",
       "4                   0                  0                    0   \n",
       "...               ...                ...                  ...   \n",
       "251468              0                  0                    0   \n",
       "251469              0                  0                    0   \n",
       "251470              0                  0                    1   \n",
       "251471              0                  0                    0   \n",
       "251472              0                  0                    0   \n",
       "\n",
       "        part_Decoration  part_Door  part_Fender  part_Fiber  part_Grill  \\\n",
       "0                     1          0            1           0           0   \n",
       "1                     1          0            0           0           0   \n",
       "2                     0          0            0           0           0   \n",
       "3                     0          0            0           0           0   \n",
       "4                     0          0            0           0           0   \n",
       "...                 ...        ...          ...         ...         ...   \n",
       "251468                0          0            0           0           0   \n",
       "251469                1          0            1           0           0   \n",
       "251470                0          0            0           0           0   \n",
       "251471                0          0            0           0           0   \n",
       "251472                0          1            0           0           0   \n",
       "\n",
       "        part_Handle  part_Headlight  part_Hinges  part_Hood  part_Injection  \\\n",
       "0                 0               0            0          0               0   \n",
       "1                 0               0            0          0               0   \n",
       "2                 0               0            0          0               0   \n",
       "3                 0               0            0          0               0   \n",
       "4                 0               0            0          0               0   \n",
       "...             ...             ...          ...        ...             ...   \n",
       "251468            0               0            0          0               0   \n",
       "251469            0               1            0          0               0   \n",
       "251470            0               0            0          0               0   \n",
       "251471            0               0            0          0               0   \n",
       "251472            0               0            0          0               0   \n",
       "\n",
       "        part_Mirror  part_Mudguard  part_Muffler  part_Other  \\\n",
       "0                 0              0             0           1   \n",
       "1                 0              0             0           1   \n",
       "2                 0              0             0           0   \n",
       "3                 0              0             0           0   \n",
       "4                 0              0             0           0   \n",
       "...             ...            ...           ...         ...   \n",
       "251468            0              0             0           1   \n",
       "251469            0              0             0           0   \n",
       "251470            0              0             0           0   \n",
       "251471            0              1             0           0   \n",
       "251472            0              0             0           0   \n",
       "\n",
       "        part_Power Window  part_Radiator  part_Rims  part_Rotor  part_Sensor  \\\n",
       "0                       0              0          0           0            0   \n",
       "1                       0              0          0           0            0   \n",
       "2                       0              0          0           0            0   \n",
       "3                       0              0          0           0            1   \n",
       "4                       0              0          0           0            1   \n",
       "...                   ...            ...        ...         ...          ...   \n",
       "251468                  0              0          1           0            0   \n",
       "251469                  0              0          0           0            0   \n",
       "251470                  0              0          0           0            0   \n",
       "251471                  0              0          0           0            0   \n",
       "251472                  0              0          0           0            0   \n",
       "\n",
       "        part_Shock absorber  part_Splash shield  part_Stabilizer link  \\\n",
       "0                         0                   0                     0   \n",
       "1                         0                   0                     0   \n",
       "2                         0                   0                     0   \n",
       "3                         0                   0                     0   \n",
       "4                         0                   0                     0   \n",
       "...                     ...                 ...                   ...   \n",
       "251468                    0                   0                     0   \n",
       "251469                    0                   1                     0   \n",
       "251470                    0                   0                     0   \n",
       "251471                    0                   1                     0   \n",
       "251472                    0                   0                     0   \n",
       "\n",
       "        part_Taillight  part_Tie rod  part_Tire  part_Windshild   pos_front  \\\n",
       "0                    1             0          0                0          0   \n",
       "1                    1             0          0                0          0   \n",
       "2                    0             0          0                0          0   \n",
       "3                    0             0          0                0          0   \n",
       "4                    0             0          0                0          1   \n",
       "...                ...           ...        ...              ...        ...   \n",
       "251468               0             0          0                0          0   \n",
       "251469               0             0          0                0          1   \n",
       "251470               0             0          0                0          0   \n",
       "251471               0             0          0                0          0   \n",
       "251472               0             0          0                0          0   \n",
       "\n",
       "        pos_front left  pos_front right  pos_left  pos_rear  pos_rear left  \\\n",
       "0                    1                0         1         0              1   \n",
       "1                    0                1         0         0              0   \n",
       "2                    0                0         0         1              0   \n",
       "3                    0                0         0         0              0   \n",
       "4                    0                1         0         0              0   \n",
       "...                ...              ...       ...       ...            ...   \n",
       "251468               0                0         0         0              0   \n",
       "251469               0                1         0         0              0   \n",
       "251470               1                0         0         0              1   \n",
       "251471               0                0         0         0              1   \n",
       "251472               1                0         0         0              0   \n",
       "\n",
       "        pos_rear right  pos_right  pos_undefined  state_New  state_Used  \n",
       "0                    0          0              0          1           0  \n",
       "1                    0          1              0          1           0  \n",
       "2                    0          0              0          1           0  \n",
       "3                    0          0              1          1           0  \n",
       "4                    0          0              0          1           0  \n",
       "...                ...        ...            ...        ...         ...  \n",
       "251468               1          0              0          1           0  \n",
       "251469               0          1              1          1           0  \n",
       "251470               0          0              0          1           0  \n",
       "251471               0          0              0          1           0  \n",
       "251472               0          0              0          1           0  \n",
       "\n",
       "[251473 rows x 52 columns]"
      ]
     },
     "execution_count": 602,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cols = reg_df.describe(exclude='number').columns\n",
    "num_cols = reg_df.describe().columns\n",
    "\n",
    "reg_df[cat_cols]=reg_df[cat_cols].apply(LabelEncoder().fit_transform)\n",
    "reg_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ab_SFd3Lse5F"
   },
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(reg_df.drop(target, axis=1), reg_df[target],  train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imJBENMvsYFH"
   },
   "source": [
    "## Baseline Model\n",
    "I made the baseline here because i want it after the scaleling to met with result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>>>>>>>>Baseline<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "MSE: 72145653.64093144\n",
      "MAE: 5063.779629443855\n",
      "RMSE: 8493.859761082205\n",
      "R2: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(f'>>>>>>>>>>>>>>>>>>>>>>>Baseline<<<<<<<<<<<<<<<<<<<<<<<<<<')\n",
    "reg_baseline = calc_cost_regrs(reg_df[target],baseline=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFK296zBug7u"
   },
   "source": [
    "### **1st Regression Model (Random Forest Regressor)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6936799071968166"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFR = RandomForestRegressor()\n",
    "RFR.fit(X_train, y_train.values.ravel())\n",
    "RFR.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xvFI9DEtuXvw"
   },
   "source": [
    "### **2nd Regression Model (XG Boost Regressor)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {
    "id": "GAoyDH5-u1PZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7207329614407397"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB_R = XGBRegressor()\n",
    "XGB_R.fit(X_train, y_train.values.ravel())\n",
    "XGB_R.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ke8DFgiHu_WK"
   },
   "source": [
    "### **3rd Regression Model (Linear Regression)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {
    "id": "cicu5WyGvWGy"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3908893076737273"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_r= LinearRegression()\n",
    "LR_r.fit(X_train, y_train.values.ravel())\n",
    "LR_r.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xdLl8k9_wG6v"
   },
   "source": [
    "## Model Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EUP0fJJdvmQj"
   },
   "source": [
    "### **1st Model Evaluation (Random Forest Regressor)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ITE4LHiQvuIh",
    "outputId": "c61542ea-8a48-4d57-bb7b-84b9402908d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>>>>>>>>Testing Set Report<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "The Accuracy of the model is : (69.36799071968166)\n",
      "\n",
      "MSE: 23493719.79986144\n",
      "MAE: 2277.1755973901963\n",
      "RMSE: 4847.032060948373\n",
      "R2: 0.6936799071968166\n"
     ]
    }
   ],
   "source": [
    "# Evaluation on the testing set \n",
    "print(f'>>>>>>>>>>>>>>>>>>>>>>>Testing Set Report<<<<<<<<<<<<<<<<<<<<<<<<<<')\n",
    "getAccuracy(X_test, y_test, RFR)\n",
    "RFR_test_res = calc_cost_regrs(y_test,RFR.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ITE4LHiQvuIh",
    "outputId": "c61542ea-8a48-4d57-bb7b-84b9402908d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>>>>>>>>Training Set Report<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "The Accuracy of the model is : (95.2632305228333)\n",
      "\n",
      "MSE: 3363433.756984185\n",
      "MAE: 882.4896794214737\n",
      "RMSE: 1833.9666728117459\n",
      "R2: 0.952632305228333\n"
     ]
    }
   ],
   "source": [
    "# Evaluation on the training set \n",
    "print(f'>>>>>>>>>>>>>>>>>>>>>>>Training Set Report<<<<<<<<<<<<<<<<<<<<<<<<<<')\n",
    "getAccuracy(X_train, y_train, RFR)\n",
    "RFR_train_res =calc_cost_regrs(y_train,RFR.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>>>>>>>>Differance Between Train & Test Results<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "| Training Accuracy | Testing Accuracy |\n",
      "|     95.26         |    69.37         |\n",
      "The differance betewen the train accuracy and test accuracy is: 25.9%\n",
      "So maybe there is an (Overfiting)\n",
      "The Erros is decreesing by:\n",
      "MSE: -598.504 %\n",
      "MAE: -158.04 %\n",
      "RMSE: -164.292 %\n",
      "R2: 27.183 %\n"
     ]
    }
   ],
   "source": [
    "# The final model evaluation\n",
    "print(f'>>>>>>>>>>>>>>>>>>>>>>>Differance Between Train & Test Results<<<<<<<<<<<<<<<<<<<<<<<<<<')\n",
    "getAccuracy( X_test, y_test,RFR, X_train, y_train)\n",
    "cost_diff_reg(RFR_train_res, RFR_test_res, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the error is increesing by 160% in 'MAE' between the train and test sets then there is an overfiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>>>>>>>>Differance Between Baseline & Test Result<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "The Erros is decreesing by:\n",
      "MSE: 67.436 %\n",
      "MAE: 55.03 %\n",
      "RMSE: 42.935 %\n",
      "R2: -inf %\n"
     ]
    }
   ],
   "source": [
    "# The final model evaluation\n",
    "print(f'>>>>>>>>>>>>>>>>>>>>>>>Differance Between Baseline & Test Result<<<<<<<<<<<<<<<<<<<<<<<<<<')\n",
    "cost_diff_reg(reg_baseline, RFR_test_res, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dadYirzrzGip"
   },
   "source": [
    "### **2nd Model  Evaluation (XG Boost Regressor)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ITE4LHiQvuIh",
    "outputId": "c61542ea-8a48-4d57-bb7b-84b9402908d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>>>>>>>>Testing Set Report<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "The Accuracy of the model is : (72.07329614407398)\n",
      "\n",
      "MSE: 21418841.621545028\n",
      "MAE: 2173.7823838419486\n",
      "RMSE: 4628.049440265848\n",
      "R2: 0.7207329614407397\n"
     ]
    }
   ],
   "source": [
    "# Evaluation on the testing set \n",
    "print(f'>>>>>>>>>>>>>>>>>>>>>>>Testing Set Report<<<<<<<<<<<<<<<<<<<<<<<<<<')\n",
    "getAccuracy(X_test, y_test, XGB_R)\n",
    "XGB_R_test_res = calc_cost_regrs(y_test,XGB_R.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ITE4LHiQvuIh",
    "outputId": "c61542ea-8a48-4d57-bb7b-84b9402908d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>>>>>>>>Training Set Report<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "The Accuracy of the model is : (82.95644110161521)\n",
      "\n",
      "MSE: 12102104.950284492\n",
      "MAE: 2004.306944297153\n",
      "RMSE: 3478.8079783576\n",
      "R2: 0.8295644110161521\n"
     ]
    }
   ],
   "source": [
    "# Evaluation on the training set \n",
    "print(f'>>>>>>>>>>>>>>>>>>>>>>>Training Set Report<<<<<<<<<<<<<<<<<<<<<<<<<<')\n",
    "getAccuracy(X_train, y_train, XGB_R)\n",
    "XGB_R_train_res =calc_cost_regrs(y_train,XGB_R.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>>>>>>>>Differance Between Train & Test Results<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "| Training Accuracy | Testing Accuracy |\n",
      "|     82.96         |    72.07         |\n",
      "The differance betewen the train accuracy and test accuracy is: 10.88%\n",
      "The model in general is (Good)\n",
      "The Erros is decreesing by:\n",
      "MSE: -76.984 %\n",
      "MAE: -8.456 %\n",
      "RMSE: -33.035 %\n",
      "R2: 13.119 %\n"
     ]
    }
   ],
   "source": [
    "# The final model evaluation\n",
    "print(f'>>>>>>>>>>>>>>>>>>>>>>>Differance Between Train & Test Results<<<<<<<<<<<<<<<<<<<<<<<<<<')\n",
    "getAccuracy( X_test, y_test,XGB_R, X_train, y_train)\n",
    "cost_diff_reg(XGB_R_train_res, XGB_R_test_res, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the error is increesing by 103% in 'MAE' between the train and test sets then there is an overfiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>>>>>>>>Differance Between Baseline & Test Result<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "The Erros is decreesing by:\n",
      "MSE: 70.312 %\n",
      "MAE: 57.072 %\n",
      "RMSE: 45.513 %\n",
      "R2: -inf %\n"
     ]
    }
   ],
   "source": [
    "# The final model evaluation\n",
    "print(f'>>>>>>>>>>>>>>>>>>>>>>>Differance Between Baseline & Test Result<<<<<<<<<<<<<<<<<<<<<<<<<<')\n",
    "cost_diff_reg(reg_baseline, XGB_R_test_res, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ke8DFgiHu_WK"
   },
   "source": [
    "### **3rd Model Evaluation (Linear Regression)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ITE4LHiQvuIh",
    "outputId": "c61542ea-8a48-4d57-bb7b-84b9402908d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>>>>>>>>Testing Set Report<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "The Accuracy of the model is : (39.08893076737273)\n",
      "\n",
      "MSE: 46716739.34823365\n",
      "MAE: 3310.6791243847397\n",
      "RMSE: 6834.964473077651\n",
      "R2: 0.3908893076737273\n"
     ]
    }
   ],
   "source": [
    "# Evaluation on the testing set \n",
    "print(f'>>>>>>>>>>>>>>>>>>>>>>>Testing Set Report<<<<<<<<<<<<<<<<<<<<<<<<<<')\n",
    "getAccuracy(X_test, y_test, LR_r)\n",
    "LR_r_test_res = calc_cost_regrs(y_test,LR_r.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ITE4LHiQvuIh",
    "outputId": "c61542ea-8a48-4d57-bb7b-84b9402908d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>>>>>>>>Training Set Report<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "The Accuracy of the model is : (40.5105729310931)\n",
      "\n",
      "MSE: 42241605.413082786\n",
      "MAE: 3292.222498295429\n",
      "RMSE: 6499.3542304665\n",
      "R2: 0.40510572931093103\n"
     ]
    }
   ],
   "source": [
    "# Evaluation on the training set \n",
    "print(f'>>>>>>>>>>>>>>>>>>>>>>>Training Set Report<<<<<<<<<<<<<<<<<<<<<<<<<<')\n",
    "getAccuracy(X_train, y_train, LR_r)\n",
    "LR_r_train_res =calc_cost_regrs(y_train,LR_r.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>>>>>>>>Differance Between Train & Test Results<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "| Training Accuracy | Testing Accuracy |\n",
      "|     40.51         |    39.09         |\n",
      "The differance betewen the train accuracy and test accuracy is: 1.42%\n",
      "The model is (Great)\n",
      "The Erros is decreesing by:\n",
      "MSE: -10.594 %\n",
      "MAE: -0.561 %\n",
      "RMSE: -5.164 %\n",
      "R2: 3.509 %\n"
     ]
    }
   ],
   "source": [
    "# The final model evaluation\n",
    "print(f'>>>>>>>>>>>>>>>>>>>>>>>Differance Between Train & Test Results<<<<<<<<<<<<<<<<<<<<<<<<<<')\n",
    "getAccuracy( X_test, y_test,LR_r, X_train, y_train)\n",
    "cost_diff_reg(LR_r_train_res, LR_r_test_res, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the error is increesing by 3% in 'MAE' between the train and test sets then it is a good model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>>>>>>>>Differance Between Baseline & Test Result<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "The Erros is decreesing by:\n",
      "MSE: 35.247 %\n",
      "MAE: 34.62 %\n",
      "RMSE: 19.531 %\n",
      "R2: -inf %\n"
     ]
    }
   ],
   "source": [
    "# The final model evaluation\n",
    "print(f'>>>>>>>>>>>>>>>>>>>>>>>Differance Between Baseline & Test Result<<<<<<<<<<<<<<<<<<<<<<<<<<')\n",
    "cost_diff_reg(reg_baseline, LR_r_test_res, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fEUrdHRYpLCA"
   },
   "source": [
    "## Invetgiate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFR_imp = XGB_R.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.9.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"4fd17b2d-c246-4ba4-84e0-160e36df043e\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"4fd17b2d-c246-4ba4-84e0-160e36df043e\")) {                    Plotly.newPlot(                        \"4fd17b2d-c246-4ba4-84e0-160e36df043e\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"x=%{x}<br>y=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"textposition\":\"auto\",\"x\":[\"Area\",\"CarBrand\",\"CarModel\",\"ManufactureYear\",\"PaymentType\",\"CarMade\",\"CarType\",\"PartsNumber\",\"PartOfDay\",\"part_Bridge\",\"part_Bumper\",\"part_Coilover\",\"part_Control Arms\",\"part_Dash insulator\",\"part_Decoration\",\"part_Door\",\"part_Fender\",\"part_Fiber\",\"part_Grill\",\"part_Handle\",\"part_Headlight\",\"part_Hinges\",\"part_Hood\",\"part_Injection\",\"part_Mirror\",\"part_Mudguard\",\"part_Muffler\",\"part_Other\",\"part_Power Window\",\"part_Radiator\",\"part_Rims\",\"part_Rotor\",\"part_Sensor\",\"part_Shock absorber\",\"part_Splash shield\",\"part_Stabilizer link\",\"part_Taillight\",\"part_Tie rod\",\"part_Tire\",\"part_Windshild \",\"pos_front\",\"pos_front left\",\"pos_front right\",\"pos_left\",\"pos_rear\",\"pos_rear left\",\"pos_rear right\",\"pos_right\",\"pos_undefined\",\"state_New\",\"state_Used\"],\"xaxis\":\"x\",\"y\":[0.009307214058935642,0.073256716132164,0.0145266093313694,0.02213800884783268,0.010736812837421894,0.08644965291023254,0.06158218905329704,0.17341312766075134,0.009615558199584484,0.006945383735001087,0.009975588880479336,0.003570056287571788,0.006590461824089289,0.013340942561626434,0.020141663029789925,0.06609027832746506,0.015446478500962257,0.0034888803493231535,0.0031960876658558846,0.004934844560921192,0.02005702070891857,0.004047649446874857,0.012590664438903332,0.029466796666383743,0.008585372008383274,0.0034067491069436073,0.00524494145065546,0.006438025273382664,0.002589721931144595,0.00858522579073906,0.023762894794344902,0.005291538778692484,0.03288556635379791,0.00384494848549366,0.01595318131148815,0.006435952614992857,0.007077686954289675,0.007456725463271141,0.008189147338271141,0.004613424185663462,0.010030998848378658,0.016102628782391548,0.012592922896146774,0.007737110368907452,0.011437776498496532,0.019840730354189873,0.023758742958307266,0.010253829881548882,0.01718880422413349,0.020275384187698364,0.019511330872774124],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"x\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"y\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\"},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('4fd17b2d-c246-4ba4-84e0-160e36df043e');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "px.bar(\n",
    "    x = X_train.columns,\n",
    "    y = RFR_imp\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fEUrdHRYpLCA"
   },
   "source": [
    "## Model Optimization - Hyperparameter Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make copy from the original df to prefrome the hyperparametr tuning\n",
    "rg_h_df = df.copy()\n",
    "\n",
    "# Remove unwanted columns from Regression Training\n",
    "unwanted_cols = ['c_id','RegistrationTime', 'CloseTime', 'Hour','Month', 'Day', 'WeekDay', 'PartsList', 'PositionList', 'PartStateList']\n",
    "unwanted_cols.append('AssessmentCost')\n",
    "unwanted_cols.append('SparePartCost')\n",
    "unwanted_cols.append('SparePart_Differace%')\n",
    "unwanted_cols.append('AssessmentEvaluation')\n",
    "unwanted_cols.append('TotalCostEvaluation')\n",
    "\n",
    "unwanted_cols.append('TimeEvaluation')\n",
    "unwanted_cols.append('DurationTime')\n",
    "\n",
    "unwanted_cols.append('CarColor')\n",
    "unwanted_cols.append('CarClass')\n",
    "\n",
    "\n",
    "\n",
    "rg_h_df.drop(unwanted_cols, axis=1, inplace=True)\n",
    "\n",
    "target = 'TotalCost'\n",
    "\n",
    "\n",
    "# Extract the categorical and numircal columns\n",
    "cat_cols = rg_h_df.describe(exclude='number').columns\n",
    "num_cols = rg_h_df.describe().columns\n",
    "\n",
    "rg_h_df[cat_cols]=rg_h_df[cat_cols].apply(LabelEncoder().fit_transform)\n",
    "\n",
    "\n",
    "# Split the data to train and test with 80% for the train set and 20% for test set and make the random state to 42  \n",
    "X_train, X_test, y_train, y_test = train_test_split(rg_h_df.drop(target, axis=1), rg_h_df[target],  train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Now combine all last transfromers to one pipline.\n",
    "cl = Pipeline(\n",
    "    steps=[\n",
    "        ('Model', XGBRegressor())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 721 candidates, totalling 3605 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "             estimator=Pipeline(steps=[('Model',\n",
       "                                        XGBRegressor(base_score=None,\n",
       "                                                     booster=None,\n",
       "                                                     colsample_bylevel=None,\n",
       "                                                     colsample_bynode=None,\n",
       "                                                     colsample_bytree=None,\n",
       "                                                     enable_categorical=False,\n",
       "                                                     gamma=None, gpu_id=None,\n",
       "                                                     importance_type=None,\n",
       "                                                     interaction_constraints=None,\n",
       "                                                     learning_rate=None,\n",
       "                                                     max_delta_step=None,\n",
       "                                                     max_depth=None,\n",
       "                                                     min_child_weight...\n",
       "                                                 interaction_constraints=None,\n",
       "                                                 learning_rate=None,\n",
       "                                                 max_delta_step=None,\n",
       "                                                 max_depth=None,\n",
       "                                                 min_child_weight=None,\n",
       "                                                 missing=nan,\n",
       "                                                 monotone_constraints=None,\n",
       "                                                 n_estimators=100, n_jobs=None,\n",
       "                                                 num_parallel_tree=None,\n",
       "                                                 predictor=None,\n",
       "                                                 random_state=None,\n",
       "                                                 reg_alpha=None,\n",
       "                                                 reg_lambda=None,\n",
       "                                                 scale_pos_weight=None,\n",
       "                                                 subsample=None,\n",
       "                                                 tree_method=None,\n",
       "                                                 validate_parameters=None,\n",
       "                                                 verbosity=None)]}],\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [{\n",
    "    # Speicfy the XG Boost Regressor model and it several parameters \n",
    "    \"Model\":[XGBRegressor()],\n",
    "    \"Model__n_estimators\": [x for x in np.arange(150,301, 50)],\n",
    "    \"Model__max_depth\":[x for x in np.arange(3,12, 1)],\n",
    "    # \"Model__subsample\": [x for x in np.arange(0.75,1.01, 0.05)],\n",
    "    \"Model__eta\":  [0.01,0.15,0.25,0.3],    #[x for x in np.arange(0.01,0.35, 0.02)],\n",
    "    \"Model__gamma\": [1,2,4,6,8] #[x for x in np.arange(0,9, 1)],\n",
    "    \n",
    "},\n",
    "{\n",
    "    # Speicfy the XG Boost Regressor model and it several parameters \n",
    "    \"Model\":[XGBRegressor()],   \n",
    "}]\n",
    "\n",
    "grid_reg = GridSearchCV(cl, \n",
    "                    param_grid=param_grid, \n",
    "                    cv=5, \n",
    "                    verbose=1,  \n",
    "                    n_jobs=-1, \n",
    "                    error_score='raise'\n",
    "                   )\n",
    "\n",
    "grid_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_Model</th>\n",
       "      <th>param_Model__eta</th>\n",
       "      <th>param_Model__gamma</th>\n",
       "      <th>param_Model__max_depth</th>\n",
       "      <th>param_Model__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>34.434943</td>\n",
       "      <td>0.181098</td>\n",
       "      <td>0.063014</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.15</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>250</td>\n",
       "      <td>{'Model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.659173</td>\n",
       "      <td>0.680976</td>\n",
       "      <td>0.671264</td>\n",
       "      <td>0.588097</td>\n",
       "      <td>0.660954</td>\n",
       "      <td>0.652093</td>\n",
       "      <td>0.032942</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>34.506159</td>\n",
       "      <td>0.228222</td>\n",
       "      <td>0.063814</td>\n",
       "      <td>0.002040</td>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>250</td>\n",
       "      <td>{'Model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.659173</td>\n",
       "      <td>0.680976</td>\n",
       "      <td>0.671264</td>\n",
       "      <td>0.588097</td>\n",
       "      <td>0.660954</td>\n",
       "      <td>0.652093</td>\n",
       "      <td>0.032942</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>34.296912</td>\n",
       "      <td>0.226305</td>\n",
       "      <td>0.063014</td>\n",
       "      <td>0.001550</td>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.15</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>250</td>\n",
       "      <td>{'Model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.659173</td>\n",
       "      <td>0.680976</td>\n",
       "      <td>0.671264</td>\n",
       "      <td>0.588097</td>\n",
       "      <td>0.660954</td>\n",
       "      <td>0.652093</td>\n",
       "      <td>0.032942</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>34.396734</td>\n",
       "      <td>0.160434</td>\n",
       "      <td>0.062614</td>\n",
       "      <td>0.002577</td>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>250</td>\n",
       "      <td>{'Model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.659173</td>\n",
       "      <td>0.680976</td>\n",
       "      <td>0.671264</td>\n",
       "      <td>0.588097</td>\n",
       "      <td>0.660954</td>\n",
       "      <td>0.652093</td>\n",
       "      <td>0.032942</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>34.478753</td>\n",
       "      <td>0.112899</td>\n",
       "      <td>0.066415</td>\n",
       "      <td>0.007339</td>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.15</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>250</td>\n",
       "      <td>{'Model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.659173</td>\n",
       "      <td>0.680976</td>\n",
       "      <td>0.671264</td>\n",
       "      <td>0.588097</td>\n",
       "      <td>0.660954</td>\n",
       "      <td>0.652093</td>\n",
       "      <td>0.032942</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "302      34.434943      0.181098         0.063014        0.000895   \n",
       "230      34.506159      0.228222         0.063814        0.002040   \n",
       "338      34.296912      0.226305         0.063014        0.001550   \n",
       "194      34.396734      0.160434         0.062614        0.002577   \n",
       "266      34.478753      0.112899         0.066415        0.007339   \n",
       "\n",
       "      param_Model param_Model__eta param_Model__gamma param_Model__max_depth  \\\n",
       "302  XGBRegressor             0.15                  6                      6   \n",
       "230  XGBRegressor             0.15                  2                      6   \n",
       "338  XGBRegressor             0.15                  8                      6   \n",
       "194  XGBRegressor             0.15                  1                      6   \n",
       "266  XGBRegressor             0.15                  4                      6   \n",
       "\n",
       "    param_Model__n_estimators  \\\n",
       "302                       250   \n",
       "230                       250   \n",
       "338                       250   \n",
       "194                       250   \n",
       "266                       250   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "302  {'Model': XGBRegressor(base_score=None, booste...           0.659173   \n",
       "230  {'Model': XGBRegressor(base_score=None, booste...           0.659173   \n",
       "338  {'Model': XGBRegressor(base_score=None, booste...           0.659173   \n",
       "194  {'Model': XGBRegressor(base_score=None, booste...           0.659173   \n",
       "266  {'Model': XGBRegressor(base_score=None, booste...           0.659173   \n",
       "\n",
       "     split1_test_score  split2_test_score  split3_test_score  \\\n",
       "302           0.680976           0.671264           0.588097   \n",
       "230           0.680976           0.671264           0.588097   \n",
       "338           0.680976           0.671264           0.588097   \n",
       "194           0.680976           0.671264           0.588097   \n",
       "266           0.680976           0.671264           0.588097   \n",
       "\n",
       "     split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "302           0.660954         0.652093        0.032942                1  \n",
       "230           0.660954         0.652093        0.032942                1  \n",
       "338           0.660954         0.652093        0.032942                1  \n",
       "194           0.660954         0.652093        0.032942                1  \n",
       "266           0.660954         0.652093        0.032942                1  "
      ]
     },
     "execution_count": 548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all the grid search result in dataframe\n",
    "grid_reg_df = pd.DataFrame(grid_reg.cv_results_)\n",
    "\n",
    "# To take just the name of the model without any additoinal parameters\n",
    "grid_reg_df['param_Model'] = grid_reg_df['param_Model'].apply(lambda x : str(x).split('(')[0])\n",
    "\n",
    "# Sort the dataframe on the rank test score\n",
    "grid_reg_df= grid_reg_df.sort_values(by = ['rank_test_score'])\n",
    "\n",
    "# Get Five top result\n",
    "grid_reg_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The best result from the grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Model': XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
       "              colsample_bynode=None, colsample_bytree=None,\n",
       "              enable_categorical=False, gamma=None, gpu_id=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_delta_step=None, max_depth=3,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, reg_alpha=None, reg_lambda=None,\n",
       "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
       "              validate_parameters=None, verbosity=None),\n",
       " 'Model__max_depth': 3,\n",
       " 'Model__n_estimators': 100}"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_reg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>>>>>>>>Testing Set Report<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "The Accuracy of the model is : (67.15196683985127)\n",
      "\n",
      "MSE: 25193335.506624367\n",
      "MAE: 2688.281726837575\n",
      "RMSE: 5019.296315881776\n",
      "R2: 0.6715196683985127\n"
     ]
    }
   ],
   "source": [
    "print(f'>>>>>>>>>>>>>>>>>>>>>>>Testing Set Report<<<<<<<<<<<<<<<<<<<<<<<<<<')\n",
    "getAccuracy(X_test, y_test, grid_reg)\n",
    "grid_test_res= calc_cost_regrs(y_test,grid_reg.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>>>>>>>>Training Set Report<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "The Accuracy of the model is : (75.75968777816269)\n",
      "\n",
      "MSE: 17212297.283998616\n",
      "MAE: 2556.6569270543823\n",
      "RMSE: 4148.770575001541\n",
      "R2: 0.7575968777816269\n"
     ]
    }
   ],
   "source": [
    "print(f'>>>>>>>>>>>>>>>>>>>>>>>Training Set Report<<<<<<<<<<<<<<<<<<<<<<<<<<')\n",
    "getAccuracy(X_train, y_train, grid_reg)\n",
    "grid_train_res= calc_cost_regrs(y_train,grid_reg.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>>>>>>>>Differance with train and test sets Report<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "| Training Accuracy | Testing Accuracy |\n",
      "|     75.76         |    67.15         |\n",
      "The differance betewen the train accuracy and test accuracy is: 8.61%\n",
      "The model is (Great)\n",
      "The Erros is decreesing by:\n",
      "MSE: -46.368 %\n",
      "MAE: -5.148 %\n",
      "RMSE: -20.983 %\n",
      "R2: 11.362 %\n"
     ]
    }
   ],
   "source": [
    "print(f'>>>>>>>>>>>>>>>>>>>>>>>Differance with train and test sets Report<<<<<<<<<<<<<<<<<<<<<<<<<<')\n",
    "getAccuracy( X_test, y_test,grid_reg, X_train, y_train)\n",
    "cost_diff_reg(grid_train_res, grid_test_res, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>>>>>>>>Differance with Baseline Report<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "The Erros is decreesing by:\n",
      "MSE: 65.08 %\n",
      "MAE: 46.912 %\n",
      "RMSE: 40.907 %\n",
      "R2: -inf %\n"
     ]
    }
   ],
   "source": [
    "print(f'>>>>>>>>>>>>>>>>>>>>>>>Differance with Baseline Report<<<<<<<<<<<<<<<<<<<<<<<<<<')\n",
    "cost_diff_reg(reg_baseline, grid_test_res, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# ML Classification Section \n",
    "<a id='CLF'></a>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_id</th>\n",
       "      <th>Area</th>\n",
       "      <th>RegistrationTime</th>\n",
       "      <th>CloseTime</th>\n",
       "      <th>CarBrand</th>\n",
       "      <th>CarModel</th>\n",
       "      <th>ManufactureYear</th>\n",
       "      <th>CarColor</th>\n",
       "      <th>AssessmentCost</th>\n",
       "      <th>SparePartCost</th>\n",
       "      <th>TotalCost</th>\n",
       "      <th>PaymentType</th>\n",
       "      <th>DurationTime</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>WeekDay</th>\n",
       "      <th>PartsList</th>\n",
       "      <th>PositionList</th>\n",
       "      <th>PartStateList</th>\n",
       "      <th>CarMade</th>\n",
       "      <th>CarClass</th>\n",
       "      <th>CarType</th>\n",
       "      <th>SparePart_Differace%</th>\n",
       "      <th>AssessmentEvaluation</th>\n",
       "      <th>PartsNumber</th>\n",
       "      <th>TimeEvaluation</th>\n",
       "      <th>PartOfDay</th>\n",
       "      <th>TotalCostEvaluation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51</td>\n",
       "      <td>Truck Center</td>\n",
       "      <td>2018-01-01 09:13:36.437000</td>\n",
       "      <td>2018-01-01 09:29:00</td>\n",
       "      <td>Volvo</td>\n",
       "      <td>head</td>\n",
       "      <td>2002</td>\n",
       "      <td>red</td>\n",
       "      <td>2455</td>\n",
       "      <td>1255</td>\n",
       "      <td>3710</td>\n",
       "      <td>POS</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Monday</td>\n",
       "      <td>[Decoration, Fender, Other, Taillight]</td>\n",
       "      <td>[front left, left, rear left]</td>\n",
       "      <td>[New]</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Luxury</td>\n",
       "      <td>Multi</td>\n",
       "      <td>95.61753</td>\n",
       "      <td>unacceptable</td>\n",
       "      <td>4</td>\n",
       "      <td>Acceptable</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   c_id          Area            RegistrationTime            CloseTime  \\\n",
       "0    51  Truck Center  2018-01-01 09:13:36.437000  2018-01-01 09:29:00   \n",
       "\n",
       "  CarBrand CarModel  ManufactureYear CarColor  AssessmentCost  SparePartCost  \\\n",
       "0    Volvo     head             2002      red            2455           1255   \n",
       "\n",
       "   TotalCost PaymentType  DurationTime  Hour  Month  Day WeekDay  \\\n",
       "0       3710         POS            15     9      1    1  Monday   \n",
       "\n",
       "                                PartsList                   PositionList  \\\n",
       "0  [Decoration, Fender, Other, Taillight]  [front left, left, rear left]   \n",
       "\n",
       "  PartStateList CarMade CarClass CarType  SparePart_Differace%  \\\n",
       "0         [New]  Sweden   Luxury   Multi              95.61753   \n",
       "\n",
       "  AssessmentEvaluation  PartsNumber TimeEvaluation PartOfDay  \\\n",
       "0         unacceptable            4     Acceptable   Morning   \n",
       "\n",
       "  TotalCostEvaluation  \n",
       "0                 Low  "
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>CarBrand</th>\n",
       "      <th>CarModel</th>\n",
       "      <th>ManufactureYear</th>\n",
       "      <th>PaymentType</th>\n",
       "      <th>CarMade</th>\n",
       "      <th>CarClass</th>\n",
       "      <th>CarType</th>\n",
       "      <th>PartsNumber</th>\n",
       "      <th>TotalCostEvaluation</th>\n",
       "      <th>part_Bridge</th>\n",
       "      <th>part_Bumper</th>\n",
       "      <th>part_Coilover</th>\n",
       "      <th>part_Control Arms</th>\n",
       "      <th>part_Dash insulator</th>\n",
       "      <th>part_Decoration</th>\n",
       "      <th>part_Door</th>\n",
       "      <th>part_Fender</th>\n",
       "      <th>part_Fiber</th>\n",
       "      <th>part_Grill</th>\n",
       "      <th>part_Handle</th>\n",
       "      <th>part_Headlight</th>\n",
       "      <th>part_Hinges</th>\n",
       "      <th>part_Hood</th>\n",
       "      <th>part_Injection</th>\n",
       "      <th>part_Mirror</th>\n",
       "      <th>part_Mudguard</th>\n",
       "      <th>part_Muffler</th>\n",
       "      <th>part_Other</th>\n",
       "      <th>part_Power Window</th>\n",
       "      <th>part_Radiator</th>\n",
       "      <th>part_Rims</th>\n",
       "      <th>part_Rotor</th>\n",
       "      <th>part_Sensor</th>\n",
       "      <th>part_Shock absorber</th>\n",
       "      <th>part_Splash shield</th>\n",
       "      <th>part_Stabilizer link</th>\n",
       "      <th>part_Taillight</th>\n",
       "      <th>part_Tie rod</th>\n",
       "      <th>part_Tire</th>\n",
       "      <th>part_Windshild</th>\n",
       "      <th>pos_front</th>\n",
       "      <th>pos_front left</th>\n",
       "      <th>pos_front right</th>\n",
       "      <th>pos_left</th>\n",
       "      <th>pos_rear</th>\n",
       "      <th>pos_rear left</th>\n",
       "      <th>pos_rear right</th>\n",
       "      <th>pos_right</th>\n",
       "      <th>pos_undefined</th>\n",
       "      <th>state_New</th>\n",
       "      <th>state_Used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>96</td>\n",
       "      <td>815</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>96</td>\n",
       "      <td>815</td>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>655</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>362</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>412</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251468</th>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>740</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251469</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>278</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251470</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>505</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251471</th>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>278</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251472</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>674</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>251473 rows Ã— 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Area  CarBrand  CarModel  ManufactureYear  PaymentType  CarMade  \\\n",
       "0          4        96       815             2002            1       13   \n",
       "1          4        96       815             2008            1       13   \n",
       "2          2         5       655             2012            0        5   \n",
       "3          2        37       362             2011            1        9   \n",
       "4          1        50       412             2007            0        8   \n",
       "...      ...       ...       ...              ...          ...      ...   \n",
       "251468     1        40       740             2016            0        8   \n",
       "251469     0        37       278             2016            0        9   \n",
       "251470     3        12       505             2011            0       16   \n",
       "251471     1        37       278             2016            1        9   \n",
       "251472     0        37       674             2014            0        9   \n",
       "\n",
       "        CarClass  CarType  PartsNumber  TotalCostEvaluation  part_Bridge  \\\n",
       "0              0        1            4                    2            0   \n",
       "1              0        1            4                    0            0   \n",
       "2              0        0            1                    0            0   \n",
       "3              0        1            1                    2            0   \n",
       "4              0        0            2                    2            0   \n",
       "...          ...      ...          ...                  ...          ...   \n",
       "251468         1        1            2                    0            0   \n",
       "251469         1        1            5                    1            0   \n",
       "251470         1        1            1                    0            0   \n",
       "251471         1        1            2                    2            0   \n",
       "251472         1        1            1                    0            0   \n",
       "\n",
       "        part_Bumper  part_Coilover  part_Control Arms  part_Dash insulator  \\\n",
       "0                 0              0                  0                    0   \n",
       "1                 1              0                  0                    0   \n",
       "2                 1              0                  0                    0   \n",
       "3                 0              0                  0                    0   \n",
       "4                 1              0                  0                    0   \n",
       "...             ...            ...                ...                  ...   \n",
       "251468            0              0                  0                    0   \n",
       "251469            1              0                  0                    0   \n",
       "251470            0              0                  0                    1   \n",
       "251471            0              0                  0                    0   \n",
       "251472            0              0                  0                    0   \n",
       "\n",
       "        part_Decoration  part_Door  part_Fender  part_Fiber  part_Grill  \\\n",
       "0                     1          0            1           0           0   \n",
       "1                     1          0            0           0           0   \n",
       "2                     0          0            0           0           0   \n",
       "3                     0          0            0           0           0   \n",
       "4                     0          0            0           0           0   \n",
       "...                 ...        ...          ...         ...         ...   \n",
       "251468                0          0            0           0           0   \n",
       "251469                1          0            1           0           0   \n",
       "251470                0          0            0           0           0   \n",
       "251471                0          0            0           0           0   \n",
       "251472                0          1            0           0           0   \n",
       "\n",
       "        part_Handle  part_Headlight  part_Hinges  part_Hood  part_Injection  \\\n",
       "0                 0               0            0          0               0   \n",
       "1                 0               0            0          0               0   \n",
       "2                 0               0            0          0               0   \n",
       "3                 0               0            0          0               0   \n",
       "4                 0               0            0          0               0   \n",
       "...             ...             ...          ...        ...             ...   \n",
       "251468            0               0            0          0               0   \n",
       "251469            0               1            0          0               0   \n",
       "251470            0               0            0          0               0   \n",
       "251471            0               0            0          0               0   \n",
       "251472            0               0            0          0               0   \n",
       "\n",
       "        part_Mirror  part_Mudguard  part_Muffler  part_Other  \\\n",
       "0                 0              0             0           1   \n",
       "1                 0              0             0           1   \n",
       "2                 0              0             0           0   \n",
       "3                 0              0             0           0   \n",
       "4                 0              0             0           0   \n",
       "...             ...            ...           ...         ...   \n",
       "251468            0              0             0           1   \n",
       "251469            0              0             0           0   \n",
       "251470            0              0             0           0   \n",
       "251471            0              1             0           0   \n",
       "251472            0              0             0           0   \n",
       "\n",
       "        part_Power Window  part_Radiator  part_Rims  part_Rotor  part_Sensor  \\\n",
       "0                       0              0          0           0            0   \n",
       "1                       0              0          0           0            0   \n",
       "2                       0              0          0           0            0   \n",
       "3                       0              0          0           0            1   \n",
       "4                       0              0          0           0            1   \n",
       "...                   ...            ...        ...         ...          ...   \n",
       "251468                  0              0          1           0            0   \n",
       "251469                  0              0          0           0            0   \n",
       "251470                  0              0          0           0            0   \n",
       "251471                  0              0          0           0            0   \n",
       "251472                  0              0          0           0            0   \n",
       "\n",
       "        part_Shock absorber  part_Splash shield  part_Stabilizer link  \\\n",
       "0                         0                   0                     0   \n",
       "1                         0                   0                     0   \n",
       "2                         0                   0                     0   \n",
       "3                         0                   0                     0   \n",
       "4                         0                   0                     0   \n",
       "...                     ...                 ...                   ...   \n",
       "251468                    0                   0                     0   \n",
       "251469                    0                   1                     0   \n",
       "251470                    0                   0                     0   \n",
       "251471                    0                   1                     0   \n",
       "251472                    0                   0                     0   \n",
       "\n",
       "        part_Taillight  part_Tie rod  part_Tire  part_Windshild   pos_front  \\\n",
       "0                    1             0          0                0          0   \n",
       "1                    1             0          0                0          0   \n",
       "2                    0             0          0                0          0   \n",
       "3                    0             0          0                0          0   \n",
       "4                    0             0          0                0          1   \n",
       "...                ...           ...        ...              ...        ...   \n",
       "251468               0             0          0                0          0   \n",
       "251469               0             0          0                0          1   \n",
       "251470               0             0          0                0          0   \n",
       "251471               0             0          0                0          0   \n",
       "251472               0             0          0                0          0   \n",
       "\n",
       "        pos_front left  pos_front right  pos_left  pos_rear  pos_rear left  \\\n",
       "0                    1                0         1         0              1   \n",
       "1                    0                1         0         0              0   \n",
       "2                    0                0         0         1              0   \n",
       "3                    0                0         0         0              0   \n",
       "4                    0                1         0         0              0   \n",
       "...                ...              ...       ...       ...            ...   \n",
       "251468               0                0         0         0              0   \n",
       "251469               0                1         0         0              0   \n",
       "251470               1                0         0         0              1   \n",
       "251471               0                0         0         0              1   \n",
       "251472               1                0         0         0              0   \n",
       "\n",
       "        pos_rear right  pos_right  pos_undefined  state_New  state_Used  \n",
       "0                    0          0              0          1           0  \n",
       "1                    0          1              0          1           0  \n",
       "2                    0          0              0          1           0  \n",
       "3                    0          0              1          1           0  \n",
       "4                    0          0              0          1           0  \n",
       "...                ...        ...            ...        ...         ...  \n",
       "251468               1          0              0          1           0  \n",
       "251469               0          1              1          1           0  \n",
       "251470               0          0              0          1           0  \n",
       "251471               0          0              0          1           0  \n",
       "251472               0          0              0          1           0  \n",
       "\n",
       "[251473 rows x 52 columns]"
      ]
     },
     "execution_count": 632,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_df = df.copy()\n",
    "# Get dummies for parts regression dataframe \n",
    "cls_df = cls_df.join(cls_df['PartsList'].str.join('|').str.get_dummies().add_prefix('part_'))\n",
    "cls_df = cls_df.join(cls_df['PositionList'].str.join('|').str.get_dummies().add_prefix('pos_'))\n",
    "cls_df = cls_df.join(cls_df['PartStateList'].str.join('|').str.get_dummies().add_prefix('state_'))\n",
    "\n",
    "\n",
    "cls_df.head(1)\n",
    "# Remove unwanted columns from Regression Training\n",
    "unwanted_cols = ['c_id','RegistrationTime', 'CloseTime', 'Hour','Month', 'Day', 'WeekDay', 'PartsList', 'PositionList', 'PartStateList']\n",
    "\n",
    "unwanted_cols.append('AssessmentCost')\n",
    "unwanted_cols.append('SparePartCost')\n",
    "unwanted_cols.append('TotalCost')\n",
    "unwanted_cols.append('SparePart_Differace%')\n",
    "unwanted_cols.append('AssessmentEvaluation')\n",
    "\n",
    "unwanted_cols.append('TimeEvaluation')\n",
    "unwanted_cols.append('PartOfDay')\n",
    "unwanted_cols.append('DurationTime')\n",
    "\n",
    "unwanted_cols.append('CarColor')\n",
    "# unwanted_cols.append('CarClass')\n",
    "# unwanted_cols.append('CarType')\n",
    "# unwanted_cols.append('ManufactureYear')\n",
    "\n",
    "# unwanted_cols.append('PartsNumber')\n",
    "# unwanted_cols.append('PaymentType')\n",
    "\n",
    "# unwanted_cols.append('PartStateList')\n",
    "\n",
    "target = 'TotalCostEvaluation'\n",
    "\n",
    "cls_df.drop(unwanted_cols, axis=1, inplace=True)\n",
    "\n",
    "cat_cols = cls_df.describe(exclude='number').columns\n",
    "num_cols = cls_df.describe().columns\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "cls_df[cat_cols]=cls_df[cat_cols].apply(le.fit_transform)\n",
    "cls_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imJBENMvsYFH"
   },
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Acceptable    49.179435\n",
       "Low           25.491007\n",
       "High          19.507462\n",
       "Very High      5.822096\n",
       "Name: TotalCostEvaluation, dtype: float64"
      ]
     },
     "execution_count": 610,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[target].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the majority is 'No' with **73.5%** so will be my Baseline of the model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ab_SFd3Lse5F"
   },
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(cls_df.drop(target, axis=1), cls_df[target],  train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qTwkfOrWswkW"
   },
   "source": [
    "## Train Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFK296zBug7u"
   },
   "source": [
    "### **1st Classification Model (Random Forest Classifier)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71698976041356"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFC = RandomForestClassifier()\n",
    "RFC.fit(X_train, y_train.values.ravel())\n",
    "RFC.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xvFI9DEtuXvw"
   },
   "source": [
    "### **2nd Classification Model (XG Boost Classifier)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {
    "id": "GAoyDH5-u1PZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:19:56] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7440898697683667"
      ]
     },
     "execution_count": 612,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB_C = XGBClassifier()\n",
    "XGB_C.fit(X_train, y_train.values.ravel())\n",
    "XGB_C.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ke8DFgiHu_WK"
   },
   "source": [
    "### **3rd Classification Model (Logistic Regression)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {
    "id": "cicu5WyGvWGy"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4899294164429864"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_c= LogisticRegression()\n",
    "LR_c.fit(X_train, y_train.values.ravel())\n",
    "LR_c.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_df = X_test.copy()\n",
    "# result_df['Actual_Option']= y_test\n",
    "# result_df['Preedect_Option']=XGB_C.predict(X_test)\n",
    "# result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xdLl8k9_wG6v"
   },
   "source": [
    "## Model Evaluation\n",
    "\n",
    "#### Note: This should include confusion matrix and classification report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function to evaluate the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function take the x and y sets and the model then will create classification report and confusion matrix and the accuracy and print it in good fromat\n",
    "def calc_cost_class(X_test, y_test, clf, setName='Testing'):\n",
    "\n",
    "    # Get the predict of x set on the passing model \n",
    "    y_pred=clf.predict(X_test)\n",
    "    \n",
    "    print(f'>>>>>>>>>>>>>>>>>>>>>>>{setName} Set Report<<<<<<<<<<<<<<<<<<<<<<<<<<')\n",
    "    print (\"Accuracy : \",\n",
    "    accuracy_score(y_test,y_pred)*100)\n",
    "      \n",
    "    print(\"Classification Report : \\n\",\n",
    "    classification_report(y_test, y_pred))\n",
    "\n",
    "    print(\"Confusion Matrix: \\n\")\n",
    "    plot_confusion_matrix(clf, X_test, y_test);\n",
    "\n",
    "    return (accuracy_score(y_test,y_pred)*100)\n",
    "\n",
    "\n",
    "# This function prints the evaluation of the model based on the difference between the accuracy of training and testing\n",
    "def cost_diff_class(train_score, test_score):\n",
    "\n",
    "    print(f'| Training Accuracy | Testing Accuracy |\\n|     {round(train_score,2)}         |    {round(test_score,2)}         |')\n",
    "\n",
    "    # Subtract the train score and test score then round it to 2 decimal\n",
    "    diff  = round(train_score-test_score,2)\n",
    "\n",
    "    # Print the differance\n",
    "    print(f'The differance betewen the train accuracy and test accuracy is: {diff}%')\n",
    "\n",
    "    # If the differance greater thean 25% maybe there is an overfiting and if greater thean 10 this is good model and if greater than 0 or equal then this great model else will be an underfitting\n",
    "    if diff >=20:\n",
    "        print('So maybe there is an (Overfiting)')\n",
    "    elif diff>10:\n",
    "        print('The model in general is (Good)')\n",
    "    elif diff>=0:\n",
    "        print('The model is (Great)')\n",
    "    else:\n",
    "        print('So maybe there is an (Underfiting)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EUP0fJJdvmQj"
   },
   "source": [
    "### **1st Model  Evaluation (Random Forest Classifier)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ITE4LHiQvuIh",
    "outputId": "c61542ea-8a48-4d57-bb7b-84b9402908d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>>>>>>>>Testing Set Report<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Accuracy :  71.698976041356\n",
      "Classification Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.80      0.76     24731\n",
      "           1       0.64      0.59      0.62      9846\n",
      "           2       0.74      0.71      0.73     12710\n",
      "           3       0.72      0.48      0.57      3008\n",
      "\n",
      "    accuracy                           0.72     50295\n",
      "   macro avg       0.71      0.65      0.67     50295\n",
      "weighted avg       0.72      0.72      0.71     50295\n",
      "\n",
      "Confusion Matrix: \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUUAAAEGCAYAAADyuIefAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA3dklEQVR4nO3dd3hUZfbA8e/JpAcChCAEEnpRsKAgAiIWLOiua1fsa1nUtevP3nFZ1752xY69r6iAooiVXqQjoSYkEEKAUFJnzu+Pe5NMIGUSMpmU83me+zDz3nYmIWfecu99RVUxxhjjCAt1AMYY05BYUjTGGD+WFI0xxo8lRWOM8WNJ0Rhj/ISHOgB/iQke7ZoSEeow6tzKFa1DHULQqKeJfq/uzg91BEGRzy4KtUD25RgnHRunW3K8AW07d2HBt6o6cl/OV98aVFLsmhLBrG9TQh1GnfvLsNNDHULQeBNahDqEoNA5i0MdQlDM1B/2+RjZOV5mfpsc0LYRSasS9/mE9axBJUVjTGOgeNUX6iCCxpKiMaZGFPDRdG/6sKRojKkxH1ZTNMYYABSlyJrPxhjjUMBrzWdjjCljfYrGGONSwNuEn65lSdEYU2NNt0fRkqIxpoYUtT5FY4wpoQpFTTcnWlI0xtSU4GWfbp9u0CwpGmNqRAGf1RSNMaaM1RSNMcblXLxtSdEYYwAnKRZpE32OJpYUjTE1pAjeJvzQfkuKxpga86k1n40xBrA+RWOM2YPgbcJ9ik33kxljgsJ58nZYQEt1ROQNEckSkcV+ZR+JyAJ3WSsiC9zyriKS57fuZb99BojIIhFJFZFnRUTc8ij3eKkiMlNEulYXk9UUjTE1oioUqqeuDvcW8Dwwvuz4el7JaxF5Etjut/0qVe1fwXFeAkYDM4CJwEhgEnAFsFVVe4rIKOBR4LwK9i/VaJNi1oYIHr+xM1uzIpAw5ZSLtnDGldn7dMwpH7fh/Wc6AHDBjRs54dyt5da/cE8nvvsogS9TF+3TeWrixrvmM2joRrZtjeLaS44DoFvP7Vz7f38QE1PMpo2xPP7QAPJ2R3DMCWmcdUFq6b5de+Ry4+XHsDq1FT37bOPmu+cRGeVjzvT9eOWZgyCE/UIREV6eeGQKERFePB7ll9868+4HB9OiRQF33/4r7ffbxaasOP796DB27oqiZcsC7r3jF3r32sKUqd158ZXDS4/Vs8cWbr1xOlFRXmbP6cRLrw4I6WerSly8l5ufSKPr/vmowlO3pDDgmB2cfMEWtuc4f45vPpLE7KnxIY60ar46+vmq6s+V1d7c2t65wHFVHUNEkoB4VZ3uvh8PnI6TFE8DHnQ3/RR4XkREtfJnnwU1KYrISOAZwAO8pqr/qatje8KV0fdn0OvgPHbvDOO6kb05bPgOuvQuqHbf287qya3/XU+HlMLSstytHt59qgPPTfoTEbhuZG8Gn5hLy9bO/LZ//hHDrtw6+3YM2PcTU/j6s27ccu+80rIb7ljA6y/0Y/GCRE74yzrOuiCVd187gGlTUpg2xZkitkv3XO7/z0xWp7YC4J+3/sFzj/Vn+ZI2PPTEDAYMzmLujPb1/nlKFBWFcce9I8jPj8Dj8fHkf75jzryOHDlkPQv+6MDHn/Xj3LOWcO7ZS3nj7UMpLPQw/r2D6dJlG127bC93rOuvmc2zLxzBshWJPPzAjww8LIM58zqF6JNV7ZoxG5gzrSX/Gt2V8AgfUTHKgGN28MWr7fj05f1CHV5AnIGWeul5OwrYpKor/cq6ich8IBe4V1V/AToB6X7bpLtluP+mAahqsYhsB9oCldaggvbJRMQDvACcDPQFzheRvnV1/Lbti+l1cB4AsS18pPQsIDszgoy1kdx9QXeuPak3t5zek/UrowI63txpLTls+A7i23hp2drLYcN3MOfHlgB4vfDqwx254t6Mugo/YEv+SGRHbmS5suTOO1m8oC0A82fvx5FH7x3X0cen89P3zv+LNm3ziY0rZvmSBECYOjmFIUdlBj32qgn5+REAhHt8hIf7UIUhg9L5fmp3AL6f2p2hR6QBUFAQzpJl+1FUWP6LKaFNHrGxRSxb0Q4QfvixO0MHp9MQxbbwctDgXUx+PwGA4qKwkHzR7jtnoCWQBUgUkTl+y+ganOh84AO/95lAZ1U9FLgFeF9E4qm4WVBSE6xqXYWCWVMcBKSq6moAEfkQpyq7tK5PtDEtklWLY9j/sN2MuaIbN/wnjU7dC1k+L5bn707msU9WVXuM7I0RtOtYVPo+MamI7I3OH+2ENxMZcmIubdsX13XotbJudUsGD9vIjF+TGHbsBhLb5+21zfARG3j4ziMAaJuYx5bN0aXrsrNiaJuYX2/xViYszMdzT02mY9IOvprYmxV/JtK6dT45W2MAyNkaQ6vWVdf827bdTXZ2bOn7zdmxtG27O6hx11aHLoVs3+Lh1qfT6N4vj5ULY3npvo4AnHpZNiPO3srKhTGMe6gjO7c33J6tkoGWAGWr6sCankNEwoEzgQGl51UtAArc13NFZBXQG6dmmOy3ezJQUlNIB1KAdPeYrYCcqs4dzJ98abXVlQ4cUdcnydsVxsNXduXqMRsIC4Olc+L41+hupeuLCp0vim8/TOB/r7UDIGNtJPdd1J3wCKVD5wIeeGNthd8dIrBlYzi/fNWaxz9L3XuDEPnvI4dy1U2LOP+yFcz4tQPFReX/g/bpm0NBvod1a5x+Kangu7IhPOTE5wvj2ptOIS6ukPvv+pkunbfV+BgVVgMa6IXFHo/S86A8Xri3Eyvmx3H1mA2cd10WE95M5P2n26MKl96+kdEPZPDULZ1DHW6VvMH/GR8PLFfV0mq/iLQDclTVKyLdgV7AalXNEZEdIjIYmAlcAjzn7jYBuBSYDpwNTK2qPxGCmxQDqra61enRAJ071Syc4iJ4+MquHHfmVoadsp1dO8JoEe/lpe9X7LXtSaNyOGmU8wVRUZ9iYlIRC6e3KH2fnRnBwUN2kro4loy1UVw21Gn5F+SF8fehB/DW78tqFGtdSl/fkvtuGQpAx5SdHD5kU7n1w0ds4Kfvy744szfH0LZdWc0wcb88crKjaSh27Ypk4eL9GHhYBtu2RZPQJo+crTEktMlj+7aquz+yt8SSmFhWM2yXuJucnJhgh1wr2ZkRbM6MYMX8OAB+/boV516XxbbsiNJtJr3XljHj14QqxIAoQpHWTeoQkQ+AY3Ca2enAA6r6OjCK8k1ngOHAGBEpBrzA1apaUuu7BmckOwZngGWSW/468I6IpOLUEEdVF1Mwe0tLqq0l/Ku0pVR1nKoOVNWB7doG3r+iCk/d2pmUXgWcddVmAOJa+mifUsjPX7Uq3WbVksD++Accs4O5P7VkxzYPO7Z5mPtTSwYcs4Mjjs/lwz+WMH7WUsbPWkpUjC+kCREobVKKKKMuXcGkL7uWrhNRhh2bwc8/lA00bN0STd7ucPr0ywGU40amMeOXpHqOurxW8fnExTlfSpGRxRx6yEbS0uOZMSuZ449bDcDxx61m+qzkqg5DztYY8vLC2b9PNqCMOHY102dWvU+obN0cQXZGJMk9nC+o/kftZP3KaBL2K+u2GXrydtauaDhfWBUpGWgJZKn2WKrnq2qSqkaoarKbEFHVv6vqy3ts+5mq9lPVQ1T1MFX9ym/dHFU9UFV7qOp1JbVBVc1X1XNUtaeqDirpzqtKMGuKs4FeItIN2ICToS+oq4MvmRXHD58m0O2APK45vg8Al92VwZ0vrOPZO5N5/5kOeIuEo0/bSo9+1fefxbfxcuFNm7j+lN4AXHjzJuLbeOsq3Fq7/cE5HNQ/m/jWhbz9+be89/r+RMcW89czndrE7z8lMeWbsqbWgf23kL05ho0ZceWO88ITB3PzPfOJivIyZ0Z75swI7UhnQkIet940HU+YIqL8/GsXZs1JZtmKdtx9+y+cdMIqsjbHMvbRo0r3efvV/xEbW0R4uI8hR6RxzwMjWJ/WiudeGsStN04nMtLLnHkdmT23Ywg/WdVeuLcTdzy/nvAIZeP6SJ68OYVrHs6gR788VGFTeiTP3t4wk3oJReqj+RwyUk3zet8OLnIK8F+cS3LeUNWxVW0/8JBonfVtSlWbNEp/GXZ6qEMIGm9Ci+o3aoR0zuLqN2qEZuoP5GrOPmW0bge10Ac/Pzigbf/ee/rc2gy0hFJQh7hUdSLO1eXGmCZClSZ973PDHfc3xjRIzkBLY7y+MjCWFI0xNWYPmTXGGJci9pBZY4zxZzVFY4xxOfM+W1I0xhiX2HQExhhTwpni1EafjTEGcB64Yc1nY4zxYxdvG2OMy3meovUpGmOMq2lPcWpJ0RhTI84lOVZTNMYYwO59NsaYvdRgjpZGx5KiMaZGnEeHWfPZGGNKNeU+xaZbBzbGBIXzlJywgJbqiMgbIpIlIov9yh4UkQ0issBdTvFbd5eIpIrIChE5ya98gIgsctc9K+LMYSkiUSLykVs+U0S6VheTJUVjTI04t/mFBbQE4C1gZAXlT6tqf3eZCCAifXHmeurn7vOiiJSM+LyEMytoL3cpOeYVwFZV7Qk8DTxaXUCWFI0xNVR3NUVV/ZlqJqf3cxrwoaoWqOoaIBUYJCJJQLyqTndn8RsPnO63z9vu60+BESW1yMpYUjTG1JgPCWjBmc95jt8yOsBTXCciC93mdRu3rBOQ5rdNulvWyX29Z3m5fVS1GNgOtK3qxDbQYoypkRqOPmfXYja/l4CHcVrqDwNPApdDhfcWahXlVLOuQg0qKf65qi0nnnVpqMOoc9uPjA11CEHT+t0ZoQ4hKMKiG/aE9LUl+XUzahzMp+So6qaS1yLyKvC1+zYd8J8DORnIcMuTKyj33yddRMKBVlTTXLfmszGmRkrmaAlkqQ23j7DEGUDJyPQEYJQ7otwNZ0BllqpmAjtEZLDbX3gJ8KXfPiU1rbOBqVrNZPcNqqZojGn4FCiuo5qiiHwAHIPT95gOPAAcIyL93VOtBa4CUNUlIvIxsBQoBq5VVa97qGtwRrJjgEnuAvA68I6IpOLUEEdVF5MlRWNMjdVV81lVz6+g+PUqth8LjK2gfA5wYAXl+cA5NYnJkqIxpmb2oWncGFhSNMbUiD1k1hhj9mA1RWOMcdlDZo0xxo8iFPua7tV8lhSNMTVmfYrGGFNCrflsjDGlrE/RGGP2YEnRGGNciuC1gRZjjCljAy3GGONSG2gxxpjy1JKiMcaUsAdCGGNMOVZTNMYYlyp4fZYUjTGmlI0+G2OMS7HmszHG+GnaAy1N97J0Y0zQqAa2VMed7D5LRBb7lT0uIstFZKGIfCEird3yriKSJyIL3OVlv30GiMgiEUkVkWfdWf1wZ/77yC2fKSJdq4upydQUIyK8PPnwZCIifHg8Pn6Z3oV3PurPpaPmM2RQGuoTtm2P5vHnjyRna9k8zO0Sd/LafyfwzseH8OmEfgCMvfd7Etrk4fH4WLy0Pc+/NghfCG9r+uKOd9ldEIlPndur/v7cWfRKyubOM38mMtyL1xfGY18MY2l6e5La5PLhrR+xfnNrABavb8+jXwwvd7zHL51Ep4RcLnj6vBB8mord8uR6jjg+l23Z4Vw1Yn8ALrolk5MvyGF7jgeAN//TkdlT40v3adexkFenLefdJzvw6Sv7hSTuQIWFKc9+uZjsTZE8eGUfuu2/i+v/tZboOC9Z6VE8dnMPdu8MZ79OBYyb8gfpq2MAWL6gBc/f2y3E0e+tDpvPbwHPA+P9yqYAd6lqsYg8CtwF3OGuW6Wq/Ss4zkvAaGAGMBEYiTOj3xXAVlXtKSKjgEeBKv/jBy0pisgbwF+BLFXda5atulZUFMbtD55Ifn4EHo+Pp/81mdnzOvHJl/14+8NDATj9lGVcdM5Cnh03uHS/qy+bw+z5ncoda+yTw9mdFwko9932E8OHrGPab6H9j/nPcaeyfXdM6fvrT5nBa98PZPqKzgzts47rTpnBP8edBsCGLfFc/EzFE5gd0281eQUR9RJzTXz3cQIT3kzktmfWlyv/4tV2lSa8qx/cwOwfW9ZHePvstMs2sn5VDLEtnBk5b/rPGl77d2cWzYrnxHOyOOsfmbzztDPPe+a6aK7760GhDLdKzuhznc3m9/OetTdV/c7v7Qyc+Zor5c4THa+q093344HTcZLiacCD7qafAs+LiFQ193Mwqz9v4WTreiLk5zt/7OEeH55wH4Cb3BzRUcX4/ySGDlrPxk0tWJfWqtyRSvbxeJSIcF9AzYD6pkBcVCEALaILyc6Nq3afmMgiLjhqIW9OPSzI0dXc4pkt2LHNE/D2Q07aRub6SNatiA5iVHUjsUMBg47dxrcftSstS+6Wx6JZTkKf92srho3MCVV4tVKD5nOiiMzxW0bX8FSXUzaHM0A3EZkvIj+JyFFuWScg3W+bdLesZF2aE7MWA9uBtlWdMGg1xYq+AYItLMzHC499Q8cOO5gwuQ/LVzr/Cf9+wXxOOHoVu3ZHctsDJwIQHVXEuacv5s4xJ3DO35bsdax/3zeFPj23MHt+R36Z0aU+P0YFhGev/AYUvpjZl//N6svTXx3JM1d8ww1/mY6I8o8XzyjdumPCDsbf8Am7CiJ55dtBLFibBMBVJ87ivV8OIb+o8fSanHrZZkacncPKhbGMG9ORndvDiYrxcu61Wdw1qgdnX50V6hCrddV963j9P52JifOWlq39M5bBx29lxvcJHHVKDolJhaXrOqQU8PxXi9i908PbTyWzZHZ8RYcNqRo0n7NVdWBtziEi9+BMev+eW5QJdFbVLSIyAPifiPSDCq8PKqnKVLWuQiEfaBGR0SXfIkVFu/bpWD5fGNf836lcMPps+vTKpmvKVgDeev9QLrzqbKb+3I2/nbwcgIvP+4PPv+5bWrvc090Pn8CoK88hIsJH/wM37lNc++ofL57Opc+ezU1v/IWzhyyhf7cMzhy8hP9+NZS/PXIx//16KPecPQ2A7Nw4/vbIRVzy7Dk88/VQxpz/PXFRhfRKyia5bS4/LWl4/VOV+Xp8IpcN7cs/T+xDTlYEo+/PAOCS/9vIF6+2I3934DXLUBl03Fa2bYkgdXH5mvzTd3Tn1Is38eyXi4iJ81Jc5Pwpbt0cwSXD+nPdqQcxbmwX7nh6FbEtikMReqUUQTWwpbZE5FKc7rcLS5q6qlqgqlvc13OBVUBvnJphst/uyUCG+zodSHGPGQ60Aqqsloe8yqCq44BxAPEtOtVJQ3XX7kgWLu7AwEMzWJvWprR86q/d+NfdU3nno/7s3yubo4as48qL59IirhCfTygs8jBh0v6l2xcVeZgxO4Uhg9KYt7BjXYRWK9k7nD+orbtimLakK/1SsvjLgD95asKRAPywsAf3nPWTE7PXQ5GbLJZvaEf6lnhSErfRN2Uz+ydv5os73iXco7SJy+PF0V+W9kM2RNuyy76wJr2XwJi31wCw/6G7GfaXbVxxTwYt4r2oTygsECa81a6yQ4VM3wE7GDxiK4cfs42IKCW2hZfbnkrl8Vt6cs+lBwDQqVseg47dBkBRYRhFhU6CTF0cR+b6KDp1y2flohah+ggVCmaPkoiMxBlYOVpVd/uVtwNyVNUrIt2BXsBqVc0RkR0iMhiYCVwCPOfuNgG4FJiO0zc5tar+RGgASbGutIrPp7g4jF27I4mMLObQgzP5+H8H0jEpl4xMp/kxZGAaaRuc17feV9bdefG5C8jLj2DCpP2Jji4iNrqInG2xhIX5OPywdBYvax+SzwQQHVFEmCi7CyOJjijiiN7pvP79ADbnxnJY9wzmre7EwB4bSMt2+kVbx+WRuzsKn4bRMSGXlMTtZOTEs3zDfnw+wxldT2qTy5N/n9SgEyJAwn5F5GQ5iXHoydtZ6/Yf3npmr9JtLrolk/xdngaZEAHeerwzbz3eGYCDjsjlrH9k8vgtPWnVtojtWyIQUUZdm8HE953BpFYJRezYFo7PJ3RIyadj13wy1zewflMFraPb/ETkA+AYnL7HdOABnNHmKGCKe2XNDFW9GhgOjBGRYsALXK2qJbW+a3DGMWJw+iBL+iFfB94RkVScGuKo6mJqMkkxoU0et133K2EeJUzgp9+7MHNuMvfdNo2Ujrn4FLI2t+CZVwZXeZzoqGIeuutHIiK8hIUpCxZ14Otve9fTp9hbQss8Hrv4WwA8Hh/fzu/JjD8788hnEdxy6m94wpSCYg+PfH40AId2y2T0ibPxesPwqvDoF8PJzWtgf1QVuPOFtRw8ZCetEop5d84S3nmiAwcP3UmPvnmowqb0SJ69IyXUYdaZY07dwl8v3gTA79+24btPnKR+4KAdXHxTOl6v4PPC8/d2Y+f2hvdnWleX5Kjq+RUUv17Jtp8Bn1Wybg6w11UuqpoPVHwpRiWkmppkrfl/AwCbgAdUtcIPWyK+RScddMg1QYknlLb3jK1+o0aq9bszQh1CUIRFRYU6hKCYkT+R7b4t+5TRont00uRHAvs7XXXefXNrO9ASKpV+BYnIc1TRdaCqN1R14Eq+AYwxjVxzvvd5Tr1FYYxpPBRojklRVd/2fy8icaq6b9fMGGOahIZ4Q0NdqfY6RREZIiJLgWXu+0NE5MWgR2aMaaAE9QW2NEaBXLz9X+AkoOSiyT9whsaNMc2VBrg0QgGN9atqmnu9UAlvZdsaY5o4bb4DLSXSRGQooCISCdyA25Q2xjRTjbQWGIhAms9XA9fiPG1iA9DffW+MabYkwKXxqbamqKrZwIX1EIsxprHwhTqA4Alk9Lm7iHwlIpvdx4Z/6d6MbYxpjkquUwxkaYQCaT6/D3wMJAEdgU+AD4IZlDGmYaurOVoaokCSoqjqO6pa7C7v0qS7WY0x1WqOl+SISIL78kcRuRP4EOdjngd8Uw+xGWMaqkbaNA5EVQMtc3GSYMmnv8pvnQIPBysoY0zDJo20FhiIqu59bjzPrTfG1B8VaKS38AUioDtaRORAoC9Q+rRSVR1f+R7GmCatOdYUS4jIAzgPi+2LM8n0ycCvlJ+82hjTnDThpBjI6PPZwAhgo6peBhyCM3+CMaa5qqPRZxF5w73+ebFfWYKITBGRle6/bfzW3SUiqSKyQkRO8isfICKL3HXPivuwBhGJEpGP3PKZgUy7HEhSzFNVH1AsIvFAFmAXbxvTXNXtxdtvASP3KLsT+EFVewE/uO8Rkb44E0/1c/d5UURK5rl9CRiNM8NfL79jXgFsVdWewNPAo9UFFEhSnCMirYFXcUak5wGzAtjPGNNEiQa2VEdVf2bveZhPA0oecv02cLpf+Yfu/M9rgFRgkIgkAfGqOt2dvnT8HvuUHOtTYERJLbIygdz7/E/35csiMtk9+cLq9jPGNGGB9ykmioj/1Cbj3Lneq9JeVTMBVDVTRPZzyzsB/jOlpbtlRe7rPctL9klzj1UsItuBtkB2ZSev6uLtw6pap6rzKltvjGnaanCdYnYdzuZXUQ1Pqyivap9KVVVTfLKKdQocV9WBa0VAPU3v+qfW70wPdQhBs+bfQ0IdQlB0u7tp/s7qbErj4N7RsklEktxaYhLOOAY4NUD/yb+TgQy3PLmCcv990kUkHGjF3s31cqq6ePvYmnwKY0wzEfz7micAlwL/cf/90q/8fRF5CufhNL2AWarqFZEdIjIYmAlcAjy3x7Gm41xJM1Wr+WYI6OJtY4wpp46Sooh8gHMddKKIpAMP4CTDj0XkCmA9cA6Aqi4RkY+BpUAxcK2qlkyNcg3OSHYMMMldAF4H3hGRVJwa4qjqYrKkaIypMamjh8yq6vmVrBpRyfZjgbEVlM8BDqygPB83qQbKkqIxpuaa8x0t4rhIRO5333cWkUHBD80Y0xAFeo1iY32STiAXb78IDAFKqrk7gBeCFpExpuFrwtMRBNJ8PkJVDxOR+QCqutWd6tQY01w10lpgIAJJikXu/YUKICLtaNJzeRljqtNYm8aBCCQpPgt8AewnImNxrvW5N6hRGWMaLq270eeGKJB7n98Tkbk4Q+QCnK6qy4IemTGm4WrONUUR6QzsBr7yL1PV9cEMzBjTgDXnpIgzc1/JTdfRQDdgBc4zzYwxzVCz7lNU1YP837tPz7mqks2NMaZRq/EdLao6T0QOD0YwxphGojnXFEXkFr+3YcBhwOagRWSMadia++gz0NLvdTFOH+NnwQnHGNMoNNeaonvRdgtVva2e4jHGNHBCMx1oEZFwd06DSqclMMY0U80xKeLM2HcYsEBEJgCfALtKVqrq50GOzRjTEDXiJ+AEIpA+xQRgC86cLCXXKypgSdGY5qqZDrTs5448L2bvGbOa8PeEMaY6zbWm6AFaUIspAo0xTVwTzgBVJcVMVR1Tb5Hso4gIL089NImIcB8ej49fZnRl/Cf9uficBZwy4k+250YD8MYHhzFrfjLHDVvNuX9bXLp/t85b+ecdp7JqXQL/vnsKCa3z8Hh8LF7enudeOwKfBvI83voXFqY8N/lPtmRGcP+l3bn75bUk9ygAIC7ey65cD/88oU+Io6zYJQcs5NzeyxDg45UH8PbSg2kVmc9/j5lCpxY72LCzJTdOO5HcwijCxcvYI3+ib9tswsXH/1b15pVF5ccAXzpuEiktc/nrl+eF5gPVUFy8l5ufSKPr/vmowlO3pLBsblyow6peHc3mJyJ9gI/8iroD9wOtgX9Qdj303ao60d3nLuAKwAvcoKrfuuUDKJu4aiJwY3Wz9lWmqqS4T4/NFZEUYDzQAacHYpyqPrMvx6xKUVEYtz10EvkFEXg8Pp4eM4nZCzoB8Nk3ffn0q/Jz2kz9tTtTf+0OQNeUrYy5fSqr1iUA8K+nj2Z3XiSg3H/rNIYPWce037sFK/R9cvqV2aStjCa2hTOp2b+v7lq6bvT9Geza0TCTea/WOZzbexlnf30mRT4Pr5/wDdPSOnNu72VMz0xm3KJDGX3QfEYfNJ8n5g5mZNfVRHq8nPrluUR7iph4xkd8vaYnG3bGA3Bi59XsLo4I8aeqmWvGbGDOtJb8a3RXwiN8RMU0nupXXTSfVXUF0B9KL//bgPOYwsuAp1X1iXLnFOmLMxtfP5wpTr8Xkd7ujH4vAaOBGThJcSRlM/rVSFV/MRXOplUDxcCtqnoAMBi41v1QQSLkFzh/FOEeH+EeH4F+Txw3bA0//laW9JyECB6PEh4e+HHqW2JSIYNG5DLp/YQK1irD/7aNH//Xpt7jCkSPVlv5Y3N78r0ReDWMWRs7ckKXNYzovJYvUnsD8EVqb47vvAZwKiYx4cV4xEd0uJcir4edhc7vKTa8iMv6LeTFPxrP1WOxLbwcNHgXk93fXXFRGLtyPSGOqgY0wCVwI4BVqrquim1OAz5U1QJVXQOkAoNEJAmIV9Xpbu1wPHB6jc7up9KkqKo5tT2ou3+mqs5zX+8AlgGd9uWY1QkTHy8/NoFPXvuIeYs6sjy1HQCnnbScVx6fwK3X/EaLuIK99jt6SPmkCPDI3VP45NWPyMuL4JcZXYIZdq1d/VAGr/0rCfXtXak/8IhdbN0cTsaaqBBEVr2V2xIY2D6T1lH5RHuKODp5PUlxu0iMyWNzntOE3JwXR9voPAC+XdudvOJwfjtvPNPOfpc3lhzC9kKnS+TGQ2fxxpJDyPc2nskpO3QpZPsWD7c+ncYL363gpifSiIrxVr9jAyG+wBac+Zzn+C2jKznkKOADv/fXichCEXlDREq+2TsBaX7bpLtlndzXe5bXSr20rUSkK3AoMLOCdaNLfmCFRbv22rcmfBrG1bf/jfOvPoc+PbLpmrKVr77rw6XXn8nVt59KztYYrrpkTrl99u+5mYLCcNamla9R3fXvEzjvqnOJiPDS/8CN+xRXMBxxfC7bssNJXRRb4fpjT9/GtP+1rt+gamDV9ja8urg/b574Na+fMJHlW9tSXEFyL3Fwuyy8PmHYRxdz3GcXclm/P0hpkcsBCdl0ic9lyvqG2b1RGY9H6XlQHl+Pb8u1J/Yhf3cY512XFeqwAhNoLdGpKWar6kC/Zdyeh3PnfPobzrXQ4DSFe+A0rTOBJ0s2rSSaOh0MDnpSFJEWOPdK36SquXuuV9VxJT+wyIi66WTetTuSP5a2Z2D/DWzbHoNPw1AVJv7Qmz49sstte8yRe9cSSxQVeZg+J4Whhze85+n2PXwXg0/M5e2ZS7nrpXUcMmwntz/ntDzCPMqRp2znpwmtQxtkNT5deQBnfHU2F04+je0FUazLbUV2XgztYpwvx3Yxu9iSHwPAqd1S+WVDZ4rVQ05+DPOyOnBgYhb9222iX9vNTD37XT44+Uu6xm/nnZFfhvJjBSQ7M4LNmRGsmO/8n//161b0PCgvxFEFRmqwBOhkYJ6qbgJQ1U2q6lVVH/AqUDKlcjqQ4rdfMpDhlidXUF4rQU2KIhKBkxDfC/YdMK1a5hMXWwhAZEQxhx2USdqGViS03l26zZGD1rE2rbVffMrwwevKJcXoqKLSfcLCfAw6dANpG1oFM/RaefORJC4a2JdLj+jLI9d04Y9fW/DY9U4z/7CjdpCWGkV2ZsOedDHBbRonxe3gxC5r+HpNL6amdeWMnn8CcEbPP/lhfVcAMna1YHDSBkCJCS+if7ssVm9vwwcr+nHUx5dw3KcXcf6k01ib24qLJ58Wok8UuK2bI8jOiCS5Rz4A/Y/ayfqV0SGOqgbqtk/xfPyazm4fYYkzcK6VBpgAjBKRKBHpBvQCZqlqJrBDRAaLiACXALX+ZgxaJ4wb3OvAMlV9KljnKZHQZje3X/sbYWGKiPLz9K7MnJfCHdf9Qo+uOagKmzbH8d9xQ0r3OeiATWRviWVjVtmDgKKjixlz+1QiInyEhflYsDiJr6Y0zEtaKnP0aQ276Vzi+WO/pXVUAcW+MB6aMYzcwijGLTqUZ46ewtm9lpG5syU3TDsBgPeWH8gjw37km9M+RgQ+W9mHFVvbhvgT7JsX7u3EHc+vJzxC2bg+kidvTql+pwairi7eFpFY4ATKP7j6MRHpj5NW15asU9UlIvIxsBRnIPdad+QZ4BrKLsmZRC1HngGklpfyVH9gkWHAL8Aiym4KKr3eqCLxLTvp4Yf+MyjxhFLYrwtCHULQrPn3kOo3aoS63T091CEExUz9gVzN2afL7WLbp2ivUbdUvyGw8Nlb5qrqwH05X30LWk1RVX9lH691NMY0QPaQWWOM2UMDvXa3LlhSNMbUWHN9IIQxxlTMkqIxxpSxmqIxxpRQmu1DZo0xZi/NduIqY4yplCVFY4wpIw31eXp1wJKiMaZm6ujJ2w2VJUVjTI1Zn6Ixxvix2/yMMcaf1RSNMcal1nw2xpjyLCkaY4zDLt42xpg9iK/pZkVLisaYmmni1ynWyxSnxpimpQbzPld9HJG1IrJIRBaIyBy3LEFEpojISvffNn7b3yUiqSKyQkRO8isf4B4nVUSedeeIqhVLisaYmqvb2fyOVdX+fnO53An8oKq9gB/c94hIX2AU0A8YCbwoIh53n5eA0Tgz/PVy19eKJUVjTI2JBrbU0mnA2+7rt4HT/co/VNUCVV0DpAKD3ClR41V1ujoz8Y3326fGLCkaY2pGAdXAlsCO9p2IzBWR0W5Ze3cuZ9x/93PLOwFpfvumu2Wd3Nd7ltdKwxpo2ZWHZ8bi6rdrZMLa71f9Ro1UU50KNDypQ6hDCArZXDd/8jW4zS+xpK/QNU5Vx/m9P1JVM0RkP2CKiCyv6rQVlGkV5bXSsJKiMabBq+F1itlVzfusqhnuv1ki8gUwCNgkIkmqmuk2jbPczdOBFL/dk4EMtzy5gvJaseazMaZmAm06V9N8FpE4EWlZ8ho4EVgMTAAudTe7FPjSfT0BGCUiUSLSDWdAZZbbxN4hIoPdUedL/PapMaspGmNqrI7uaGkPfOFePRMOvK+qk0VkNvCxiFwBrAfOAVDVJSLyMbAUKAauVVWve6xrgLeAGGCSu9SKJUVjTM3VQVJU1dXAIRWUbwFGVLLPWGBsBeVzgAP3PSpLisaYWrB7n40xpoQC3qabFS0pGmNqzGqKxhjjz2bzM8aYMlZTNMaYEk380WGWFI0xNSKA2ECLMcaUEetTNMYYlzWfjTHGX8CPBWuULCkaY2rMRp+NMcaf1RSNMcalNvpsjDHlNd2caEnRGFNzdkmOMcb4s6RojDEuBQKfuKrRsaRojKkRQa353NgkJhVy29NraNOuGFWY+H4iX77Rnu59d3P9v9cTGeXD6xWev6czf/4Rx6FH5XL5nRsIj/BRXBTGa2M78cfv8aH+GADc9MASBg3fzLacSP55zlAALr/pT44YvpniojAy02N4+oF+7NoZUbpPuw55vPzZdN57uTufv9OVmNhiHntjdun6xP0K+HFiEuOe6FPvn6cmwsKU5yb/yZbMCO6/tDtX3pfB4BNyKSoUMtdF8uTNndmV6wl1mHu58f7FDDrK+Z1de96R5dadefEarrjpT84fcSy52yLp3W8b19+z1FkpyvvjejL9x/bO7+y1WaX7tW2fz48Tk3j1yQPq86NUztd0q4pBS4oiEg38DES55/lUVR8I1vn8+bzCq/9KIXVxLDFxXp77Zhnzf4nnirvTee+/ScyZ1orDj93OlXenc/t5fcjNCeeBy3uQsymSLr3zGPvuSi4adHB9hFqt77/qyFcfpXDrw2XzYc+f0Za3nuuJzxvGZTes5NzL1/Lms71K14/+vz+Z81vb0vd5u8O5ftSQ0vfPvDeD36c2/LmoT78ym7SV0cS2cOYmmvdzS974dxI+r3DFPRmMun4Tr4/tGOIo9/b9Vx35+uPO3PLQonLlie3z6H/EFrIyo0vL1q1qyY0XD8bnDaNNYgHPf/A7M39u5/zOLhhaut0z707n96nt6+0zVKmOms8ikgKMBzq4Rxynqs+IyIPAP4DN7qZ3q+pEd5+7gCsAL3CDqn7rlg+gbOKqicCNqrWrzgZzitMC4DhVPQToD4wUkcFBPF+pnKwIUhfHApC3y0NaajRtOxSBCrEtnT+wuJZetmxyalerlsSSsykSgHV/RhMZ5SMismF8Ey6e14Yd2yPKlc2f0Raf1/nVLV/UisT2+aXrhhyTRWZ6DOtXtajweB0776J1QiGL57UOWsx1ITGpkEEjcpn0fkJp2byfWuLzOvOeL5sbR2JSUajCq9KS+Ql7/c4A/nHLCt58pne5MYqCfE/p7zIy0lvh+EXHlF20alPIkvltghVyjYlqQEs1ioFbVfUAYDBwrYj0ddc9rar93aUkIfYFRgH9gJHAiyJS0lR4CRiNM+1pL3d9rQQtKapjp/s2wl3qvSOifXIBPfrtZsX8OF5+KJkr707nnRkLufLedN58tNNe2w87ZRurlsRSVNg4psQ+8bQNzPktEYCoaC9nX7aW91/pXun2R4/cyM/fdcB5AFTDdfVDGbz2ryTUV3GcJ52fw+ypDaOLIxBHDM9iy+Yo1qzcO+Y+B27jxY9/5YWPfueFR/qWJskSR4/M5JcpDex3VgfzPqtqpqrOc1/vAJYBe/9RljkN+FBVC1R1DZAKDBKRJCBeVae7tcPxwOm1/WhB/csXEY+ILACygCmqOjOY59tTdKyXe19ZzSsPpbB7p4e/XryZV8akcPHgg3llTDI3P76u3PZdeudx+V3pPHtXl/oMs9bOu2I1Xq/w48QOAFx0zSr+925n8vMq7xU5+qRN/DS5Q32FWCtHHJ/LtuxwUhfFVrj+/Bs24S2GqZ+3rt/Aaikq2st5V6zm3Zd7Vrh+xeLW/PPcYdx88WDO+ftqIiK95dYPP3FjA/udBZgQnaSYKCJz/JbRFR1RRLoChwIlOeI6EVkoIm+ISEkVuROQ5rdbulvWyX29Z3mtBHWgxZ2our+ItMaZ9PpAVV3sv437QxoNEE3FfwS14QlX7ntlNT9+kcBvk52f6fFnbeGlB1IA+OXrNtz0aFlSTOxQyH3jVvHEzd3IXBdVZ3EEy4hTMxg0PJu7rxpASQ2iz4HbGXb8Ji6/aSVxLYtRHxQWhvH1R50B6NZ7Bx6PkrqsYdew+h6+i8En5nL4iKVERimxLb3c/tw6Hru+C8efk8Og43O587weNKiaUxU6JO+mfcc8nv/gd8AZ6Hrmvenccslgtm4p+7+WtrYFBfkeuvTYSeqyVgB065Xr/M6WtwpJ7BWq2Wx+2ao6sKoNRKQF8Blwk6rmishLwMPumR4GngQup+JfuFZRXiv1MvqsqttEZBpOO3/xHuvGAeMA4sMS6qh5rdz8+FrWp0bz+WtlndNbNkVy8OCdLJzRkv5H7iBjrdPhHRdfzJi3Unnz0U4snVNxX1xDMmBoNuf8fS23XzmQgvyy0dfbrzi89PWFV60ib7enNCGC03Se1qBqHBV785Ek3nwkCYCDh+zk7KuzeOz6Lgw8Jpdzr83itjN7UpDXOLo3ANaltuTCE44tff/GVz9x08VDyN0WSfuOu9m8KRqfN4x2HfLo1GU3WZkxpdsePXIjP32bFIqwq1RXl+SISAROQnxPVT8HUNVNfutfBb5236YDKX67JwMZbnlyBeW1EszR53ZAkZsQY4DjgUeDdT5//Q7fxfFn5bBmWQwvTHIud3jrsU48c2cXrn4wDY9HKSwQnrnTSRh/u3QzHbsWcMENmVxwQyYAd1/Ui+1b9u4sr2+3P7KQgwdsJb51EeMn/8y7L/fg3MvWEBHpY+xLcwFYsagVz4/tW82R4KgTNvHA9YcGO+SguXbsBiKilEc+WgXA8rlxPHtncjV71b/bx/7BQQNziG9dxNsTp/HeKz357suK4+zbfxvn/H013uIwfAov/ucAcrdFlq4/6viNPHDjYfUVeuDqICmKiACvA8tU9Sm/8iRVzXTfnkFZRWoC8L6IPAV0xBlQmaWqXhHZ4Q7kzgQuAZ6rdVy1HLWu/sAiBwNvAx6cvsuPVXVMVfvEhyXo4PCTghJPKIW1Tah+o0bKuykr1CEERXhSw69R18bvmz9ie2HWPvU7tIpO0qFdLg1o28l/Pjq3suaziAwDfgEWUXaRz93A+ThXrCiwFriqJEmKyD04TelinOb2JLd8IGWX5EwCrq/tJTlBqymq6kKcjlNjTJNSN0/eVtVfqbg/cGIV+4wFxlZQPgc4cJ+Doone0WKMCTK7zc8YY1wKeBvGzQ3BYEnRGFNDCmpJ0Rhjyljz2RhjXAr4LCkaY0wZqykaY4wfS4rGGONSBa+3+u0aKUuKxpias5qiMcb4saRojDEl1EafjTGmlILaxdvGGOPHbvMzxhiXqk1xaowx5dhAizHGlFGrKRpjTIm6echsQ2VJ0RhTM/ZACGOMKaOA2m1+xhjjUnvIrDHGlKPWfDbGGD9NuKYYtHmfa0NENgPr6ul0iUB2PZ2rPtnnanzq87N1UdV2+3IAEZmME3MgslV15L6cr741qKRYn0RkTmWTdDdm9rkan6b82RqjsFAHYIwxDYklRWOM8dOck+K4UAcQJPa5Gp+m/NkanWbbp2iMMRVpzjVFY4zZiyVFY4zx0+ySooiMFJEVIpIqIneGOp66IiJviEiWiCwOdSx1SURSRORHEVkmIktE5MZQx1QXRCRaRGaJyB/u53oo1DEZR7PqUxQRD/AncAKQDswGzlfVpSENrA6IyHBgJzBeVQ8MdTx1RUSSgCRVnSciLYG5wOmN/XcmIgLEqepOEYkAfgVuVNUZIQ6t2WtuNcVBQKqqrlbVQuBD4LQQx1QnVPVnICfUcdQ1Vc1U1Xnu6x3AMqBTaKPad+rY6b6NcJfmU0NpwJpbUuwEpPm9T6cJ/IE1FyLSFTgUmBniUOqEiHhEZAGQBUxR1SbxuRq75pYUpYIy+3ZuBESkBfAZcJOq5oY6nrqgql5V7Q8kA4NEpMl0ezRmzS0ppgMpfu+TgYwQxWIC5Pa5fQa8p6qfhzqeuqaq24BpQKN6cEJT1dyS4mygl4h0E5FIYBQwIcQxmSq4AxKvA8tU9alQx1NXRKSdiLR2X8cAxwPLQxqUAZpZUlTVYuA64FucDvuPVXVJaKOqGyLyATAd6CMi6SJyRahjqiNHAhcDx4nIAnc5JdRB1YEk4EcRWYjzZT1FVb8OcUyGZnZJjjHGVKdZ1RSNMaY6lhSNMcaPJUVjjPFjSdEYY/xYUjTGGD+WFBsREfG6l6QsFpFPRCR2H471loic7b5+TUT6VrHtMSIytBbnWCsie836Vln5HtvsrGp9Bds/KCL/V9MYjdmTJcXGJU9V+7tPwSkErvZf6T4FqMZU9cpqnjpzDFDjpGhMY2RJsfH6Bejp1uJ+FJH3gUXuQwYeF5HZIrJQRK4C584QEXleRJaKyDfAfiUHEpFpIjLQfT1SROa5z/n7wX0Iw9XAzW4t9Sj3bozP3HPMFpEj3X3bish3IjJfRF6h4nvNyxGR/4nIXPeZgqP3WPekG8sPItLOLeshIpPdfX4Rkf3r5KdpjCs81AGYmhORcOBkYLJbNAg4UFXXuIllu6oeLiJRwG8i8h3O02X6AAcB7YGlwBt7HLcd8Cow3D1WgqrmiMjLwE5VfcLd7n3gaVX9VUQ649whdADwAPCrqo4Rkb8A5ZJcJS53zxEDzBaRz1R1CxAHzFPVW0XkfvfY1+FM8nS1qq4UkSOAF4HjavFjNKZClhQblxj3UVPg1BRfx2nWzlLVNW75icDBJf2FQCugFzAc+EBVvUCGiEyt4PiDgZ9LjqWqlT2f8Xigr3NbMgDx7gNghwNnuvt+IyJbA/hMN4jIGe7rFDfWLYAP+Mgtfxf43H1SzlDgE79zRwVwDmMCZkmxcclzHzVVyk0Ou/yLgOtV9ds9tjuF6h+TJgFsA063yxBVzasgloDvGxWRY3AS7BBV3S0i04DoSjZX97zb9vwZGFOXrE+x6fkWuMZ93BYi0ltE4oCfgVFun2MScGwF+04HjhaRbu6+CW75DqCl33bf4TRlcbfr7778GbjQLTsZaFNNrK2ArW5C3B+nploiDCip7V6A0yzPBdaIyDnuOUREDqnmHMbUiCXFpuc1nP7CeeJMYvUKTovgC2AlsAh4Cfhpzx1VdTNOP+DnIvIHZc3Xr4AzSgZagBuAge5AzlLKRsEfAoaLyDycZvz6amKdDIS7T4p5GPCfn2QX0E9E5uL0GY5xyy8ErnDjW0ITmU7CNBz2lBxjjPFjNUVjjPFjSdEYY/xYUjTGGD+WFI0xxo8lRWOM8WNJ0Rhj/FhSNMYYP/8PreVRQUVHx4kAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluation on the testing set \n",
    "RFC_test_score= calc_cost_class(X_test, y_test, RFC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ITE4LHiQvuIh",
    "outputId": "c61542ea-8a48-4d57-bb7b-84b9402908d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>>>>>>>>Training Set Report<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Accuracy :  96.73075584805495\n",
      "Classification Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97     98942\n",
      "           1       0.99      0.98      0.99     39210\n",
      "           2       0.94      0.95      0.95     51393\n",
      "           3       1.00      0.99      0.99     11633\n",
      "\n",
      "    accuracy                           0.97    201178\n",
      "   macro avg       0.97      0.97      0.97    201178\n",
      "weighted avg       0.97      0.97      0.97    201178\n",
      "\n",
      "Confusion Matrix: \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUUAAAEGCAYAAADyuIefAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAxOUlEQVR4nO3dd3xUZfb48c9J74EklBA6RBQRWUUB26qgout+RX8WrKyry1qxrmtZu9hW3bVh751VVFxFVFBRFlEBBemhhdBCSEiDtJnz++PeJBMgyQxkMinn/XrdV2aeueXclJOn3PtcUVWMMcY4wkIdgDHGtCSWFI0xxoclRWOM8WFJ0RhjfFhSNMYYHxGhDsBXWkq49u4RGeowmtyKhXGhDiFoJKxt/l9VrzfUIQRFGaVUaLnsyz5OOi5et+V7/Fp33sLy6ao6el+O19xaVFLs3SOSH6f3CHUYTe6kbkNCHULQhMW2zYTv3bEj1CEExVydsc/7yMv3MHd6d7/WjUxflbbPB2xmLSopGmNaA8WjbbMmDZYUjTEBUsBL273pw5KiMSZgXqymaIwxAChKpTWfjTHGoYDHms/GGFPL+hSNMcalgKcNz65lSdEYE7C226NoSdEYEyBFrU/RGGOqqUJl282JlhSNMYESPOzT7dMtmiVFY0xAFPBaTdEYY2pZTdEYY1zOxduWFI0xBnCSYqW2zXk0wZKiMSZAiuBpw5P2W1I0xgTMq9Z8NsYYwPoUjTFmF4LH+hSNMcbhzLxtSdEYYwBQFSo0PNRhBE2rToofvpjGtLdSUYWTz8/njL9s5Y1HujLt7RSSU5xHMF58y0YOH1nMzCkd+c+kzjXbrlkaw9PTV9Bv0E5uPa8v+bmReKpg0LBSrro/h/BwWPRDPM/ekcHqpbHc+sxajj61MFSnCkCnbhX87fFsOnauQr3w2ZupfPRSJ259di3d+5UDEJ/kobQonCtOGABAnwN2MuGhHOITPXi9wtWnZFJZHvr/8mnp5dz4zyw6plWiCtPe7cLHr6XTZ/9Srr53NTFxHnI3xPDw9f3ZURLB747czsV/yyYi0ktVZRgvPdiLX39IBiAi0ssVd67hoGFFqBdee6wns6enhvgMGzfmkq2cfH4+Isq0t1L58MVOoQ7Jb17rU9w7IjIaeBwIB15U1Qebat9rl8Uw7a1Unvh0BZFRyq3n9WPYSCdpnf6XrZx1+dY66x9/RgHHn1EAOAnxrov70G/QTgBue24t8YleVOHev/Tmu086cOyY7XTKqOSGf2fz/rOdaQk8VcLz93Qja1EcsfEenvp8BfNnJXL/Zb1r1hl/x0ZKi52kFxau3PRkNv+c0JPVS2JJ7FiFp7Jl/DJ7qoQXHujFqsUJxMZ7eOKjhSyYncy196/ixQd7sejHZE48M5f/d+lG3vh3T4oKIrlr/P7k50bRK3MH972yhAuPGgrA2Cs2sH1bJH854XeIKIkdqkJ8do3rNWAnJ5+fz4Q/ZFJZIdz/9mrmzkhi45roUIfWKGegJfT/WIMlaGcmIuHA08DJwEDgXBEZ2FT7z14ZzQGH7CAmTgmPgMEjSpg9rYNf2379UUeOHVNQ8z4+0ZkdzlMFVRVC9T/Brj0q6DuwjJbyvPf83EiyFjnPWd5ZGs76rBjS0it91lCO+b/tfP1RRwAO/X0xa5bGsHpJLADFBRF4vS0jKRZsjWLV4gTAPZdVsaR2qaB73zIW/ZgEwPzZyRw1Oh+AVUviyc+NAmDdyliiopXIKOfnduKZubz3bAbgNO2KCiKb+3QC1jOznKXz4yjfGYbXIyyck8CRJ4e2JeI/Z6DFn6U1CmbUhwNZqrpaVSuAd4HTmmrnvfcvY9HceIrywynbIfw0M4mtG50/hk9e6cRlIwfw6HU9KN6+e9/HrKkdOG7M9jplt57bl3MGDyI2wcvRp27fbZuWpkv3CvoN2smy+bUPox80rJSCrRE1tY3ufctRFSa+vYqnpq/grCtyQxVugzpnlNFvYCnLf01g7YpYho9y/mEdffI20rqW77b+UaPzWbUknsqKMOITnVrhRdet58mPF3Lrk8vpkFrRrPHvjbXLYjhoWAmJHauIjvVy2PFFdOrW8uOG2oEWf5bWKJhRZwDrfd7nuGVNomdmOWdfkcstY/tx2/n96DNwJ+ERyqnj8nhlzhImfbmclC6VPH93tzrbLZsfR3Ssl977l9Upv/+d1byzYDGVFcIv3yc0VZhBERPn4fYX1/LsHd3YUVKb9I8bs51vPupQ8z48Qhl0eCkPXdWLG8b054jRhQw5qjgEEdcvJs7DP55ewXP39WZHSQT/urk/f7xgM098tJDYeA9VlXV/RXtm7uDPN63jydv7As45dkqvYMm8RK4+bTBLFyRy6S3rQnEqAVmfFcPkSZ154N3VTHxrNWuWxOKpahm1eH94VPxaWqNgJsU9fUd2m3BIRMaLyM8i8vPWbZ6ADjD6vHye/mIFj36YRWIHDxl9yunYqYrwcAgLcwZflv8SV2ebbz7uUKfp7CsqRhlxYiFzpicHFEdzCo9Qbn9xLTOndKzTXRAWrhx5SiHfTq0t27opkoVz4inKj6B8Zxg/zUyi/0E7mz/oeoRHePnH08v5emoa//vCGRjJWR3LbX8ayIQxg/n2kzQ2Zdf2saV1Lef2Sct55Mb+bMqOAaCoIIKyHWH874sUAL6blkr/A0ub/2T2wvR3UrnqpP248Yz+FG8PZ0Mr6E8E5za/So3wa2mNgpkUc4AePu+7Axt3XUlVn1fVoao6tFNqYMP82/Ocb3puTiSzP0vm2DHb2bal9gfxv2nJ9B5QWyP0euG7/3bg2NO215TtLA2r2cZTBT/OSKJH/92bbC2Dcv2j61m/MoYpz9cdqTzk6GLWZ0WTtymqpmzeN4n0GVhGdKyXsHBl8IgSslfENHfQ9VCufWAV67Ni+fDl2tp8corTRyqijL0yh8/e6QpAfGIVd7+wjFcf6cmS+Uk++xHmzuzI4GFFAAwZUUh2VmyzncW+SE51zrVTRgVHnlJYp5bfklUPtPiztEbBTOU/AZki0gfYAIwFzmvKA9xzaW+KCyIIj1Suuj+HxA4eHr66J6sWxyLi9LtNeLi2Bb/ohwTS0itJ71Xbd1O2I4y7/tSXygrB44EhR5Zw6kV5ACz/JZZ7LulD8fZwfvgyidcf6coL3yxvylMIyIGHlzLqrAJWL4lh0pdOHK88kM5PM5P4/Wnbd/ujKimMYMpznXjysxWoCj/OTOTHGUl72HPzO/DQYkadnseaZXE8NfVXAF57tCfdepdx6gWbAfjfFyl88b6T/P944Wa69Srj3CtzOPfKHABu+9NACvMjefnhXtz4yEr++o+1FOZH8Njf+4fmpAJ0x4vraq4IeOrWDEoKW0fNSmm9TWN/iAbxUYUicgrwb5xLcl5W1YkNrT/04Bj9cXqPhlZplU7qNiTUIQRNWFxc4yu1Qt4dO0IdQlDM1RkUaf4+ZbQ+ByXoXVMG+7Xun/abM09Vh+7L8ZpbUP81qepnwGfBPIYxpnmp0movt/FH2z0zY0xQOAMt4X4tjRGR60RksYj8JiLviEiMiKSIyJcistL92tFn/VtEJEtElovIST7lh4rIIvezJ0RE3PJoEXnPLZ8rIr0bi8mSojEmYE0x0CIiGcAEYKiqDsLpZhsL3AzMUNVMYIb7Hvfmj7HAgcBoYJJ7kwjAM8B4INNdRrvllwAFqtof+BfwUGPnZknRGBMQRfCqf4sfIoBYEYkA4nCuUDkNeM39/DVgjPv6NOBdVS1X1TVAFnC4iKQDSao6R51Bktd32aZ6X+8DI6trkfWxpGiMCVgANcW06uuQ3WV89T5UdQPwCJANbAIKVfULoIuqbnLX2QRUTz5Q3w0hGe7rXcvrbKOqVUAh0OBsIa3jGgBjTIvhPPfZ7/pUXn2jz25f4WlAH2A78B8RuaCBfdV3Q0hDN4r4dROJL6spGmMCJHj8XBoxClijqltVtRKYAhwBbHGbxLhfq2/ar++GkBz39a7ldbZxm+jJQH5DQVlSNMYExHnEaZOMPmcDw0Ukzu3nGwksBaYC49x1xgEfu6+nAmPdEeU+OAMqP7pN7GIRGe7u56Jdtqne15nATG3k4mxrPhtjAqIqgTSfG9iPzhWR94H5QBWwAHgeSAAmi8glOInzLHf9xSIyGVjirn+lqlZPmHA58CoQC0xzF4CXgDdEJAunhji2sbgsKRpjAtZUF2+r6p3AnbsUl+PUGve0/kRgtzvjVPVnYNAeystwk6q/LCkaYwLizKfYdu99tqRojAmQPeLUGGNqOJfkWE3RGGOA2nuf2ypLisaYgLXW56/4w5KiMSYgztRh1nw2xpga1qdojDEuZ5Ycaz4bYwxQfZufJUVjjHFZTdEYY+qwO1qMMcZlo8/NaMXCOE7K+F2ow2hyG/4+ItQhBE3GQ/8LdQgmBKz5bIwxrupntLRVlhSNMQFRoMpqisYYU8uaz8YYU83/x5e2SpYUjTEBsUlmjTFmF1ZTNMYYl00ya4wxPhShymsDLcYYU8P6FI0xpppa89kYY2pYn6IxxuzCkqIxxrgUwWMDLcYYU8sGWowxxqU20GKMMXWpJUVjjKlmE0IYY0wdVlM0xhiXKni8lhSNMaaGjT4bY4xLseazMcb4sIEWY4ypQzXUEQRPm02K8UlVXPfIenoPKEMVHruhJ2nplVx4/WZ6ZJYx4Q/7sXJhHAARkV6ueSiHzME7UIVn7shg4ZzEkMUeFV7Fa2d+TFS4h/AwL19m9eXpHw5nQFoedxz/LdERHjzeMO79+mh+29KlZruuicVMveBdJs09jFfnDyEusoLXz/qo5vMuCaX8d1kmD806itMOWMYNR80htzQegHd+HcQHiwc296nWa8wlWzn5/HxElGlvpfLhi5244IbNnHzeNgrznV/bVx5I56eZSSGO1H+dulXwt8ez6di5CvXCZ2+m8tFLnTj61O1ceMNmemSWM+GUzJrfy5asqZrPItIBeBEYhNMy/zOwHHgP6A2sBc5W1QJ3/VuASwAPMEFVp7vlhwKvArHAZ8A1qqoiEg28DhwKbAPOUdW1DcUUtKQoIi8DpwK5qjooWMepz+X3bODnr5O4b3wfIiK9RMd6KSkM556/9GbCg+vrrHvyedsAuGzU/iSnVjLxzdVcfcp+Ies3qfCE8+cp/8fOykgiwjy8ftZHfLe2J1cN/4ln5g7l+3W9OLr3Om446gcu/uC0mu3+fsxsvlvXs+b9jsooznz77Jr37439D19l9a15//nK/tz/zdHNc1IB6DVgJyefn8+EP2RSWSHc//Zq5s5wkt+HL3Ti/Wc7hzjCveOpEp6/pxtZi+KIjffw1OcrmD8rkbXLYrjn0t5MeCgn1CH6xRl9brJ7nx8HPlfVM0UkCogDbgVmqOqDInIzcDPwdxEZCIwFDgS6AV+JyH6q6gGeAcYDP+AkxdHANJwEWqCq/UVkLPAQcE5DAQXzru5X3cCaXVyCh4OGlfL5OykAVFWGUVoUwfqsGHJWxey2fs/9ylnwfQIAhdsiKSkKZ7+DdzRrzHUJOysjAYgI8xIR5kVVUISEqEoAEqIqyC2trVEc33cNOYVJrNqWssc99uywndS4nczbmB788PdRz8xyls6Po3xnGF6PsHBOAkeeXBjqsPZZfm4kWYucn9nO0nDWZ8WQll5Z7+9lS6bq39IQEUkCjgFecvapFaq6HTgNeM1d7TVgjPv6NOBdVS1X1TVAFnC4iKQDSao6R1UVp2bou031vt4HRopIg7WdoCVFVZ0F5Adr/w3p2qucwm0R3PCvbJ6evpxr/5lNdKyn3vVXL4lhxEmFhIUrXXqUk3nQDjp1q2zGiHcXJl7eP28ys/7yKnOyu7NoSxce+vZIbjh6Dl/9+XVuPHoO/549HIDYiEr+PHQBk+YeVu/+Ttkvi89X9AefSylO6L+aKee/x2OnTKdrQkmwT8lva5fFcNCwEhI7VhEd6+Ww44vo1K0CgD9enMczXy3n+seySUiuCnGke69L9wr6DdrJsvktv6m8J6ri19KIvsBW4BURWSAiL4pIPNBFVTc5x9FNQHXTIAPwbebluGUZ7utdy+tso6pVQCGQ2lBQIZ//R0TGi8jPIvJzJeVNss/wcOh/0A7++3oaV540gLIdYZxzVW69609/N5W8TVE8NW05l9+9gSU/x+OpCu3omlfDOPPtsxn50kUc1CWX/qnbOGfwYh6adQSjXr6Ih2cdwT2jvgbgyuE/8caCwTW1yz05eb8sPluRWfP+mzW9OfGVCzjjrXP4YX13Jp44I+jn5K/1WTFMntSZB95dzcS3VrNmSSyeKuG/r6Vy8YgDuOKE/cjfEsn4OzeGOtS9EhPn4fYX1/LsHd3YURIe6nACpviXEN2kmFb99+0u4312FQEcAjyjqr8DSnGayvXZ0x+lNlDe0Db1CvlAi6o+DzwPkCQpTTKmlbcpkq2bIlm+wBlE+P7TDpzdQFL0eoTn7sqoef+vj1ewYU10U4Syz4orovlpQzeO6rWe/ztgOQ98eyQA01f24+6R3wBwUNctnJC5muuP+oHE6HJUhfKqcN5ZeBAAA9LyCA/zsiS3U81+C8tqm2vv/3YA1x35Q3Odkl+mv5PK9Hecf+gX37yJrZsi2Z5Xm/SnvZXKPa+vCVV4ey08Qrn9xbXMnNKR2dM6hDqcvRbAH2qeqg6t57McIEdV57rv38dJiltEJF1VN7lN41yf9Xv4bN8d2OiWd99Due82OSISASTTSAs25DXFYCjYGknexii69ysDYMhRxWSvqD/JRcd4a5rXhxxdjKdKyF4Zuj6ejrE7SYxyas3R4VUM75HDmoIObC2N47AM52c9rMcG1m1PBmDc+6dz0isXcNIrF/DmgsG88NMhNQkR4OQBWUxb0b/OMdLiSmteH9d3LavzOwT5rAKTnOp0X3TKqODIUwr55qMOpHSu7dI44uRC1i5vXf1woFz/6HrWr4xhyvOdGl+9pVJQr/i1NLgb1c3AehEZ4BaNBJYAU4Fxbtk44GP39VRgrIhEi0gfIBP40W1iF4vIcLe/8KJdtqne15nATLffsV4hrykGy9O3Z/D3J9cREalszo7i0et7csTo7Vxx3waSU6q49/XVrFocy23n96NDWiUT316NemHb5kgentArpLF3it/BxBNmEh7mRVCmr+zPt2t6U1Qezc3HfE9EmFLuCefumcf6tb+TMrO44uM/1Cm7YMgiju27Fo83jMKyaP7x5fFBOJO9d8eL60jsWIWnUnjq1gxKCiP42xPZ9DtwJ6qwJSeKJ27q3viOWpADDy9l1FkFrF4Sw6QvlwPOZUWRUer8XqZWce8ba1i1OIbbzusX4mgb1oRXZlwNvOWOPK8GLsaprE0WkUuAbOAs55i6WEQm4yTOKuBKd+QZ4HJqL8mZ5i7gDOK8ISJZODXEsY0FJI0kzb0mIu8AxwJpwBbgTlV9qaFtkiRFh4WNCko8obThphGhDiFoMh76X6hDMAGYqzMo0vx9ymgx/TK0+wOX+7XuqnNun9dA87lFqremKCJP0kDXgapOaGjHqnruPsRljGmh2vO9zz83WxTGmNZDgfaYFFX1Nd/3IhKvqqX1rW+MaT/a8r3PjY4+i8gIEVkCLHXfHywik4IemTGmhfJv5Lmx0eeWyp9Lcv4NnIRzMzWq+ivOrTnGmPZK/VxaIb8uyVHV9bvcLlj/PXPGmLZN2+9AS7X1InIEoO61RBNwm9LGmHaqldYC/eFP8/ky4EqcG6s3AEPc98aYdkv8XFqfRmuKqpoHnN8MsRhjWgtvqAMIHn9Gn/uKyCcislVEckXkYxHp29h2xpg2qvo6RX+WVsif5vPbwGQgHWe22/8A7wQzKGNMy9YUk8y2VP4kRVHVN1S1yl3epE13sxpjGtUeL8kRkep57b92n5PwLs5pngN82gyxGWNaqlbaNPZHQwMt86g7q+1ffT5T4N5gBWWMadmkldYC/dHQvc99mjMQY0wroQKt9BY+f/h1R4uIDAIGAjVTHavq68EKyhjTwrXHmmI1EbkTZ7LYgTjPUz0Z+B7nMYLGmPaoDSdFf0afz8R5dsJmVb0YOBhoGU91MsaERnscffaxU1W9IlLlPrw6F+d5rcaY9qi9TjLr42cR6QC8gDMiXQL8GMygjDEtW7scfa6mqle4L58Vkc+BJFVdGNywjDEtWntMiiJySEOfqer84IRkjGnp2mtN8dEGPlOgyR8ULCKERbe9MZy2/BjQlY8PD3UIQZF5zQ+hDqFla499iqp6XHMGYoxpJVrxyLI//Lp42xhj6rCkaIwxtaQNTzJrSdEYE7g2XFP0Z+ZtEZELROQO931PETk8+KEZY1oiUf+X1sif2/wmASOAc933xcDTQYvIGNPyteHHEfjTfB6mqoeIyAIAVS1wH3VqjGmvWmkt0B/+JMVKEQnH/TaISCfa9LO8jDGNaa1NY3/4kxSfAD4EOovIRJxZc/4R1KiMMS2XtvPRZ1V9S0Tm4UwfJsAYVV0a9MiMMS1Xe64pikhPYAfwiW+ZqmYHMzBjTAvWnpMizpP7qh9gFQP0AZYDBwYxLmNMC9au+xRV9SDf9+7sOX+tZ3VjjGnVAr6jRVXni8hhwQjGGNNKtOeaoohc7/M2DDgE2Bq0iIwxLVsTjz67l/z9DGxQ1VNFJAV4D+gNrAXOVtUCd91bgEsADzBBVae75YcCrwKxOA/Yu0ZVVUSicR6ydyiwDThHVdc2FI8/d7Qk+izROH2Mp/l9xsaYtqdpH1x1DeB7RcvNwAxVzQRmuO8RkYHAWJzxjNHAJDehAjwDjAcy3WW0W34JUKCq/YF/AQ81FkyDNUX3gAmq+je/Ts0Y0+YJTTfQIiLdgT8AE4HqVulpOI9VBngN+Ab4u1v+rqqWA2tEJAs4XETW4jwmZY67z9eBMcA0d5u73H29DzwlIqKq9Z5BvTVFEYlQVQ9Oc9kYY2r5X1NME5GffZbxu+zp38BN1L1LrouqbgJwv3Z2yzOA9T7r5bhlGe7rXcvrbKOqVUAhkNrQqTVUU/wRJyH+IiJTgf8ApdUfquqUhnZsjGmjApsBJ09Vh+7pAxE5FchV1Xkicqwf+9rTDBPaQHlD29TLn9HnFJwOyuN9AlDAkqIx7VXTDLQcCfyfiJyCcw10koi8CWwRkXRV3SQi6TjPmgenBtjDZ/vuwEa3vPseyn23yRGRCCAZyG8oqIYGWjq7I8+/AYvcr4vdr781crLGmDasKeZTVNVbVLW7qvbGGUCZqaoXAFOBce5q44CP3ddTgbEiEi0ifXAGVH50m9jFIjJcRAS4aJdtqvd1pnuMva4phgMJ7EX10xjTxgU3AzwITBaRS4Bs4CwAVV0sIpOBJUAVcKU77gFwObWX5ExzF4CXgDfcQZl8nOTboIaS4iZVvSfg0wmRtPRybnxkFR07VaJeYdq7nfn41a6cf00Oo8/JpTA/EoDXHunBT990AODsyzdw0llb8XqFZ+7uxfzvnPKH3l5CSudKysucivRt4/ancFtkKE6rXpHRXh6dkkVklBIeoXz3aQfeeKQriR2quPXZdXTpXsGWnCgm/rUXJYUt7KkTXqXHI4vwJEex8a/7E5VTSufJawir8qJhQu5ZfSjvlQAeL13eWU10TiniVYoO60TBCU7/ecaTi4koqkQjnZ/RhssPwJNY+zNK+GUb6a+sJPuGQZT3TAjJafojLEx58vMVbNsUyR3j+oY6HP8E4Wl+qvoNzigzqroNZwKaPa03EWeketfyn4FBeygvw02q/mror2Wfps0VkR44F012xemBeF5VH9+XfTbEUyW8cH8vVi2OJzbewxNTf2PB90kAfPRyOh+8mF5n/Z79d/D7U/O5bPRgUjpX8MAby7h05MF4vc5pP3xdP1Yuarl/TJXlwk1n9aNsRzjhEcpjH2Xx08xEjjylkAXfJzD5qS6cfdUWzrkql5cmdgt1uHV0+HYzlV1iCStz/smnTc0mf3QGOwZ2JG5xAWlT17Hh6gNJXJCPVCnZNx+MVHjo9cCvFB+SSlVqDACbL+y/x4QnZR46zNrMzl4t9+dXbcyleaxfGUNcgqfxlVuQtnzvc0N9invM1AGoAm5Q1QOA4cCV7sWXQVGwNYpVi+MB2FkazvqsGFK7Vta7/vATCvj2vylUVoSxJSeGjeti2O/gkmCFFwRC2Q7nutWISCU8UlGFEScV8dXkFAC+mpzCiNFFoQxyNxHby4lfXEDhiM61hUJNggwr8+BJciZ2VwGp8IBHkUovGh6GN6bxWm/qZ+spOL4bGtmyp8NPS6/g8JFFTHs7JdShBK5pL95uUer9DVPVBkdoGuN2flZfa1QsIktxrhlasi/79UfnjHL6HbiD5b/EM/DQYv540WZGnrGVlYsSeGFiT0qKIkjtUsmyBbU1ibzNUaR1rah5f93Dq/F6hNmfp/DOU93Yx4pzUISFKU9NX0G33hV88moqyxfE0zGtkvxcpxmZnxtJh9SqEEdZV9qUdeSd1rMmCQJsPb03Gc8sJe3jbESV9dc6raCSISkkLCqgz+3zCKv0svX0Xnjja39lu7y9CsKEkoNTyD8xA0SIziklsqCCvEEd6fD1xt2O35JcdvdGXrwvnbiE1jdja1ueZNaf2/z2mYj0Bn4HzN3DZ+OrL+ysoHyfjxUT5+Efk1bw3L292FESwadvdeHPxw7hyj8cRH5uJH+5Lds97u7/xlSrm879ueLkwfztnIEMOqyIkafn7XNcweD1ClecMIDzDx3IgCE76DVgZ6hDalD8bwV4EiIp71G3Wdth9hbyTu/F2rsPYevpvenyzioAYtaVomGw5t5DWHvH7+j49SYi8soA2HxhJtk3H8z6CQcSs6qYxJ/ywKukfbiWrWN6Nvu5BWrYqCK250WQtSgu1KEEzt9aYiutKQY9KYpIAvABcK2q7taWU9XnVXWoqg6NInqfjhUe4eUfk1by9dQ0/jfdaZJsz4vE6xVUncGX/QY7TeS8zVF06labhNO6VrBti1PD2rbFab7tLA3n66lp7HdwKS1ZaVE4v85J4LDjiinIiySls9NtkNK5ku3bWs4gS8yaYuJ/K6D33fPp+loWsSuL6PJ6Fok/bqXkYOfnVTIkheh1zvc7cV4eOw7oAOFheBIj2dknkZj1zmeeDm4TOyac4kNTickuIazcQ/SmnXR/agm9755PzNoSur2wnOjsltctMvCwUoafWMRrc5dwyzPrOPioEm56cl2ow/KLBLC0RkFNiiISiZMQ3wr+HTDKtQ+uYf2qWD58qXZQpWOn2ibxESfls25FLAA/fNWR35+aT2SUly7dy+jWu4wVvyYQFq4kdXSSSniEl2HHF9Rs05Ikp1QRn+Q0QaNivBxydAnrs2L44YskRp3t9HyMOjufOdOTQhlmHdv+2JO19xzC2jsPYfO4/uzMTGLLRf3xJEcSm+X8v4xdUURlJ2cgpapjFHErikAVKfcQs7aEis4x4FHCStz+Yo+X+MXbqegahzc2gtX3D2Xtnc4xynonsPEvA1rk6PMrD6RzwdCBjBs2kAcu78Wv3yfw8NW9Qh2W/9pwTTFo1Qj3IsqXgKWq+liwjlPtwKEljDojjzXLYnnqv4sA5/Kb3/8xj74Dd4DClpxonritDwDZK+P47tMUnpu+EI9HmHRnb7xeITrWw32vLiMiUgkLgwWzk/j83c4NHTokUrpUcuPj2YSFQVgYzPokmblfJbFkXhy3PbuO0WPzyd3gXJLT0m05py+dpqxDvIpGCrljnZ/R9qO70uXtVfR8cCEoFA3rREVGPFLuIeOZZYhHQZUd+yVTeETL+xm1ZW159Fkaubh773cschTwHc7dMNXdsreq6mf1bZMclqrDY04JSjyh5C0rC3UIQbPy8eGhDiEoMq/5IdQhBMVcnUGR5u9TyzauSw/NHHt94ysCC5+4fl599z63VEGrKarq97TebgVjTH3a+yNOjTFmN224+WxJ0RgTsLbcp2hJ0RgTOEuKxhhTy2qKxhhTTWmqSWZbJEuKxpiANOWDq1oiS4rGmMBZUjTGmFoSpJs+WgJLisaYwLTi+5r9YUnRGBMw61M0xhgfdpufMcb4spqiMca4/Himc2tmSdEYEzhLisYY47CLt40xZhfibbtZ0ZKiMSYwdp2iMcbUZZfkGGOML6spGmNMLRtoMcaYagrYhBDNQ1Xb9ONA26K2+ijQ8AMyQx1CUMjq75tmP9anaIwxDrtO0RhjfKla89kYY3xZTdEYY3xZUjTGmFptuaYYFuoAjDGtjAIe9W9pgIj0EJGvRWSpiCwWkWvc8hQR+VJEVrpfO/psc4uIZInIchE5yaf8UBFZ5H72hIiIWx4tIu+55XNFpHdjp2dJ0RgTMFH/lkZUATeo6gHAcOBKERkI3AzMUNVMYIb7HvezscCBwGhgkoiEu/t6BhgPZLrLaLf8EqBAVfsD/wIeaiwoS4rGmMBVj0A3tjS4C92kqvPd18XAUiADOA14zV3tNWCM+/o04F1VLVfVNUAWcLiIpANJqjpHVRV4fZdtqvf1PjCyuhZZH0uKxpiABVBTTBORn32W8Xvcn9Os/R0wF+iiqpvASZxAZ3e1DGC9z2Y5blmG+3rX8jrbqGoVUAikNnRuNtBijAlMYFOH5anq0IZWEJEE4APgWlUtaqAit6cPtIHyhrapl9UUjTEBEUA86tfS6L5EInES4luqOsUt3uI2iXG/5rrlOUAPn827Axvd8u57KK+zjYhEAMlAfkMxWVI0xgRMVP1aGtyHUyV8CViqqo/5fDQVGOe+Hgd87FM+1h1R7oMzoPKj28QuFpHh7j4v2mWb6n2dCcx0+x3rZc1nY0xgmm7m7SOBC4FFIvKLW3Yr8CAwWUQuAbKBswBUdbGITAaW4IxcX6mqHne7y4FXgVhgmruAk3TfEJEsnBri2MaCsqRojAlQ09z7rKrfs+c+P4CR9WwzEZi4h/KfgUF7KC/DTar+sqRojAlYW76jxZKiMSZwNkuOMca4FL9GllsrS4rGmMC13ZxoSdEYE7jGLrdpzSwpGmMCZ0nRGGNcCtiDq4wxxiE0frdKa9bmk2JktJdHp2QRGaWERyjffdqBNx7pSt+BO7n6wRxi471syYnioSt7sqMkvPEdtjBhYcqTn69g26ZI7hjXl0tv38jwE4qorBA2rYvi0et6UlrUus7r+seyGTaqmO15Efz1+AEAHH3qdi68YTM9MsuZcEomKxfGhTjKuq698WcOH76J7dujueLSEwE46pgczh+3hB49i7juyuNZuSIFgM5dSnnulenkrE8EYPnSVJ769yF19nfHvbPpml5as69BB21l/JW/0qdvIQ/eN4zZs7oTUt62W1UM2r3PIhIjIj+KyK/urLp3B+tYDaksF246qx+XnzCAy08YwNBji9n/kFKufWQ9L9+fzmUjBzB7WhJnXp7b+M5aoDGX5rF+ZUzN+/mzEhl/3AAuHzWADaujGXv1lhBGt3e+eC+F287vU6ds7bIY7rm0N4t+iA9RVA37anovbr/lqDpl69Ymcd+dI/htYdpu62/amMDVfz2Bq/96wm4J8YijNlC2s259JTc3jsceHso3M3oQctXNZ3+WViiYE0KUA8er6sHAEGC0iAwP4vHqIZTtcGpKEZFKeKSiCt37ldf8gS2YlchRfyhs/tD2UVp6BYePLGLa2yk1ZfO/TcTrce6cWjovnrT0ylCFt9d+m5tAcUHdpLA+K4acVTH1bBF6vy3qRHFRVJ2y9dlJbMhJDGg/MTFVnH7mCt5564A65blb4lm7ugNebXB+1GbTFBNCtFRBS4rqKHHfRrpLSL5LYWHKpC+X897CxSyYlcDyBfGsWx7DiJOKADj61EI6dWt9yeOyuzfy4n3pqHfPfygnnZvPTzOTmjkq44+uXUt58tmveOixbzjwoK015Rde/BtT/rMf5WUtvMujCWbebqmCOnWYiIS7s1/kAl+q6txgHq8+Xq9wxQkDOP/QgQwYsoNeA3by2PU9+OOf8njq8xXEJnioqmgZ/4H9NWxUEdvzIshatOe+tXMnbMFTBTOndGjewEyj8vNjGHfeKVx92SheeOZgbrr1R2LjKunbbzvdMkqZMzuj8Z2ElJ8JsZUmxaAOtLjT+gwRkQ7AhyIySFV/813HnZ58PEAMwe08Ly0K59c5CRx2XDHvP9uZW8/tB0BG33KGjSwK6rGb2sDDShl+YhGHjVxCVLQSl+jhpifX8fDVvRh1Vj6Hjyri5nP6Uf8kJCZUqirDKa50aoJZKzuyaWM83bsXkzmggP6ZBbzy1meEhyvJHcp48NFvuPmGY0Mb8K6qn+bXRjXL6LOqbheRb3CesPXbLp89DzwPkCQpTf6dTk6poqpKKC0KJyrGyyFHlzD56c4kp1ZSuC0SEeW8a7bw3zcafGxDi/PKA+m88kA6AINHlHDmZbk8fHUvhh5bxNlX5vK3M/pTvtPmEG6JkpLLKSmOwusVuqaX0K17CZs2JbByRQqffeL8o+7cpZS7Js5ueQnR1Vr7C/0RtKQoIp2ASjchxgKj8OPxgk0tpUslNz6eTVgYhIXBrE+SmftVEmMu2cof/5QHwOxpyXzxbkoje2odrpy4gcho5YH3VgGwbF48T9wc4ss3AnTzpHUMHlFCckoVb/68hDce7UJxQQRX3LeB5NQq7n1jDasWx3Dbef1CHWqNm26by+CDt5KUXM7r737Km68NpLgoisuv/oXk5HLuun82q7M6cPvNR3PQ4K1c8KcleDyC1ys89e9DKCmOanD/mQPyuf3uOSQkVDBsxCYuGLeEyy85sZnObg/acFKURmbm3vsdiwzGebRgOE7f5WRVvaehbZIkRYfJHueWNKZZhR+QGeoQgmLO6lco3Llpn/pUkmPS9Yhe4xpfEfh8xUPzGntwVUsTtJqiqi7EeWShMaZNab2DKP5o83e0GGOCwJKiMca4FPC00ttV/GBJ0RgTIAW1pGiMMbWs+WyMMS4FvJYUjTGmltUUjTHGhyVFY4xxqYLHE+oogsaSojEmcFZTNMYYH5YUjTGmmtroszHG1FBQu3jbGGN82G1+xhjjUm3Tjzi1pGiMCZwNtBhjTC21mqIxxlSzSWaNMaaWTQhhjDG1FFC7zc8YY1xqk8waY0wdas1nY4zx0YZrikF77vPeEJGtwLpmOlwakNdMx2pOdl6tT3OeWy9V7bQvOxCRz3Fi9keeqo7el+M1txaVFJuTiPzc2h7S7Q87r9anLZ9baxQW6gCMMaYlsaRojDE+2nNSfD7UAQSJnVfr05bPrdVpt32KxhizJ+25pmiMMbuxpGiMMT7aXVIUkdEislxEskTk5lDH01RE5GURyRWR30IdS1MSkR4i8rWILBWRxSJyTahjagoiEiMiP4rIr+553R3qmIyjXfUpikg4sAI4AcgBfgLOVdUlIQ2sCYjIMUAJ8LqqDgp1PE1FRNKBdFWdLyKJwDxgTGv/mYmIAPGqWiIikcD3wDWq+kOIQ2v32ltN8XAgS1VXq2oF8C5wWohjahKqOgvID3UcTU1VN6nqfPd1MbAUyAhtVPtOHSXu20h3aT81lBasvSXFDGC9z/sc2sAfWHshIr2B3wFzQxxKkxCRcBH5BcgFvlTVNnFerV17S4qyhzL779wKiEgC8AFwraoWhTqepqCqHlUdAnQHDheRNtPt0Zq1t6SYA/Twed8d2BiiWIyf3D63D4C3VHVKqONpaqq6HfgGaFUTJ7RV7S0p/gRkikgfEYkCxgJTQxyTaYA7IPESsFRVHwt1PE1FRDqJSAf3dSwwClgW0qAM0M6SoqpWAVcB03E67Cer6uLQRtU0ROQdYA4wQERyROSSUMfURI4ELgSOF5Ff3OWUUAfVBNKBr0VkIc4/6y9V9b8hjsnQzi7JMcaYxrSrmqIxxjTGkqIxxviwpGiMMT4sKRpjjA9LisYY48OSYisiIh73kpTfROQ/IhK3D/t6VUTOdF+/KCIDG1j3WBE5Yi+OsVZEdnvqW33lu6xT0tDne1j/LhG5MdAYjdmVJcXWZaeqDnFnwakALvP90J0FKGCqemkjs84cCwScFI1pjSwptl7fAf3dWtzXIvI2sMidZOCfIvKTiCwUkb+Cc2eIiDwlIktE5FOgc/WOROQbERnqvh4tIvPdef5muJMwXAZc59ZSj3bvxvjAPcZPInKku22qiHwhIgtE5Dn2fK95HSLykYjMc+cUHL/LZ4+6scwQkU5uWT8R+dzd5jsR2b9JvpvGuCJCHYAJnIhEACcDn7tFhwODVHWNm1gKVfUwEYkGZovIFzizywwADgK6AEuAl3fZbyfgBeAYd18pqpovIs8CJar6iLve28C/VPV7EemJc4fQAcCdwPeqeo+I/AGok+Tq8Wf3GLHATyLygapuA+KB+ap6g4jc4e77KpyHPF2mqitFZBgwCTh+L76NxuyRJcXWJdadagqcmuJLOM3aH1V1jVt+IjC4ur8QSAYygWOAd1TVA2wUkZl72P9wYFb1vlS1vvkZRwEDnduSAUhyJ4A9BjjD3fZTESnw45wmiMjp7usebqzbAC/wnlv+JjDFnSnnCOA/PseO9uMYxvjNkmLrstOdaqqGmxxKfYuAq1V1+i7rnULj06SJH+uA0+0yQlV37iEWv+8bFZFjcRLsCFXdISLfADH1rK7ucbfv+j0wpilZn2LbMx243J1uCxHZT0TigVnAWLfPMR04bg/bzgF+LyJ93G1T3PJiINFnvS9wmrK46w1xX84CznfLTgY6NhJrMlDgJsT9cWqq1cKA6trueTjN8iJgjYic5R5DROTgRo5hTEAsKbY9L+L0F84X5yFWz+G0CD4EVgKLgGeAb3fdUFW34vQDThGRX6ltvn4CnF490AJMAIa6AzlLqB0Fvxs4RkTm4zTjsxuJ9XMgwp0p5l7A9/kkpcCBIjIPp8/wHrf8fOASN77FtJHHSZiWw2bJMcYYH1ZTNMYYH5YUjTHGhyVFY4zxYUnRGGN8WFI0xhgflhSNMcaHJUVjjPHx/wFeaTTTLwrLSwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluation on the training set \n",
    "RFC_train_score = calc_cost_class(X_train, y_train, RFC, 'Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Training Accuracy | Testing Accuracy |\n",
      "|     96.73         |    71.7         |\n",
      "The differance betewen the train accuracy and test accuracy is: 25.03%\n",
      "So maybe there is an (Overfiting)\n"
     ]
    }
   ],
   "source": [
    "# The final model evaluation\n",
    "cost_diff_class(RFC_train_score,RFC_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dadYirzrzGip"
   },
   "source": [
    "### **2nd Model  Evaluation (XG Boost Classifier)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ITE4LHiQvuIh",
    "outputId": "c61542ea-8a48-4d57-bb7b-84b9402908d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>>>>>>>>Testing Set Report<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Accuracy :  74.40898697683667\n",
      "Classification Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.79     24731\n",
      "           1       0.68      0.60      0.64      9846\n",
      "           2       0.77      0.74      0.75     12710\n",
      "           3       0.76      0.55      0.64      3008\n",
      "\n",
      "    accuracy                           0.74     50295\n",
      "   macro avg       0.74      0.68      0.71     50295\n",
      "weighted avg       0.74      0.74      0.74     50295\n",
      "\n",
      "Confusion Matrix: \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluation on the testing set \n",
    "XGB_C_test_score= calc_cost_class(X_test, y_test, XGB_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ITE4LHiQvuIh",
    "outputId": "c61542ea-8a48-4d57-bb7b-84b9402908d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>>>>>>>>Training Set Report<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Accuracy :  76.23845549712195\n",
      "Classification Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.83      0.80     98942\n",
      "           1       0.73      0.65      0.69     39210\n",
      "           2       0.77      0.74      0.76     51393\n",
      "           3       0.84      0.62      0.71     11633\n",
      "\n",
      "    accuracy                           0.76    201178\n",
      "   macro avg       0.78      0.71      0.74    201178\n",
      "weighted avg       0.76      0.76      0.76    201178\n",
      "\n",
      "Confusion Matrix: \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluation on the training set \n",
    "XGB_C_train_score = calc_cost_class(X_train, y_train, XGB_C, 'Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Training Accuracy | Testing Accuracy |\n",
      "|     76.24         |    74.41         |\n",
      "The differance betewen the train accuracy and test accuracy is: 1.83%\n",
      "The model is (Great)\n"
     ]
    }
   ],
   "source": [
    "# The final model evaluation\n",
    "cost_diff_class(XGB_C_train_score,XGB_C_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fEUrdHRYpLCA"
   },
   "source": [
    "## Invetgiate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_C_imp = XGB_C.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"94da931e-a0f9-4e2c-a3bf-9fcdc5ba2252\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"94da931e-a0f9-4e2c-a3bf-9fcdc5ba2252\")) {                    Plotly.newPlot(                        \"94da931e-a0f9-4e2c-a3bf-9fcdc5ba2252\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"x=%{x}<br>y=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"textposition\":\"auto\",\"x\":[\"Area\",\"CarBrand\",\"CarModel\",\"ManufactureYear\",\"PaymentType\",\"CarMade\",\"CarClass\",\"CarType\",\"PartsNumber\",\"part_Bridge\",\"part_Bumper\",\"part_Coilover\",\"part_Control Arms\",\"part_Dash insulator\",\"part_Decoration\",\"part_Door\",\"part_Fender\",\"part_Fiber\",\"part_Grill\",\"part_Handle\",\"part_Headlight\",\"part_Hinges\",\"part_Hood\",\"part_Injection\",\"part_Mirror\",\"part_Mudguard\",\"part_Muffler\",\"part_Other\",\"part_Power Window\",\"part_Radiator\",\"part_Rims\",\"part_Rotor\",\"part_Sensor\",\"part_Shock absorber\",\"part_Splash shield\",\"part_Stabilizer link\",\"part_Taillight\",\"part_Tie rod\",\"part_Tire\",\"part_Windshild \",\"pos_front\",\"pos_front left\",\"pos_front right\",\"pos_left\",\"pos_rear\",\"pos_rear left\",\"pos_rear right\",\"pos_right\",\"pos_undefined\",\"state_New\",\"state_Used\"],\"xaxis\":\"x\",\"y\":[0.008548641577363014,0.028421388939023018,0.018565502017736435,0.024505093693733215,0.004553113132715225,0.05838647857308388,0.014921477064490318,0.021063443273305893,0.1629720777273178,0.008556501939892769,0.025718027725815773,0.0046089510433375835,0.008724731393158436,0.011125851422548294,0.01617487519979477,0.1650623232126236,0.01889737695455551,0.003845732659101486,0.004837257321923971,0.005060917232185602,0.019002346321940422,0.004915405064821243,0.01343576330691576,0.013897999189794064,0.007770979311317205,0.005551626440137625,0.007271662820130587,0.0071355621330440044,0.0066232383251190186,0.009948384016752243,0.03276772052049637,0.006648318376392126,0.010286089964210987,0.004705735016614199,0.008439859375357628,0.004729053471237421,0.012805710546672344,0.005631814710795879,0.004076254554092884,0.010550741106271744,0.016635730862617493,0.012132523581385612,0.012912069447338581,0.007884984835982323,0.020991429686546326,0.021207816898822784,0.020566508173942566,0.009688571095466614,0.016371017321944237,0.028049083426594734,0.02281612530350685],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"x\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"y\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\"},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('94da931e-a0f9-4e2c-a3bf-9fcdc5ba2252');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "px.bar(\n",
    "    x = X_train.columns,\n",
    "    y = XGB_C_imp\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JhqUCJrNznO6"
   },
   "source": [
    "### **3rd Model  Evaluation (Logistic Regression)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ITE4LHiQvuIh",
    "outputId": "c61542ea-8a48-4d57-bb7b-84b9402908d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>>>>>>>>Testing Set Report<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Accuracy :  48.99294164429864\n",
      "Classification Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.98      0.66     24731\n",
      "           1       0.27      0.02      0.03      9846\n",
      "           2       0.29      0.02      0.04     12710\n",
      "           3       0.00      0.00      0.00      3008\n",
      "\n",
      "    accuracy                           0.49     50295\n",
      "   macro avg       0.26      0.25      0.18     50295\n",
      "weighted avg       0.37      0.49      0.34     50295\n",
      "\n",
      "Confusion Matrix: \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluation on the testing set \n",
    "LR_c_test_score= calc_cost_class(X_test, y_test, LR_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ITE4LHiQvuIh",
    "outputId": "c61542ea-8a48-4d57-bb7b-84b9402908d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>>>>>>>>Training Set Report<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Accuracy :  49.00088478859517\n",
      "Classification Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.98      0.66     98942\n",
      "           1       0.26      0.02      0.03     39210\n",
      "           2       0.29      0.02      0.04     51393\n",
      "           3       0.00      0.00      0.00     11633\n",
      "\n",
      "    accuracy                           0.49    201178\n",
      "   macro avg       0.26      0.25      0.18    201178\n",
      "weighted avg       0.37      0.49      0.34    201178\n",
      "\n",
      "Confusion Matrix: \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluation on the training set \n",
    "LR_c_train_score = calc_cost_class(X_train, y_train, LR_c, 'Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Training Accuracy | Testing Accuracy |\n",
      "|     49.0         |    48.99         |\n",
      "The differance betewen the train accuracy and test accuracy is: 0.01%\n",
      "The model is (Great)\n"
     ]
    }
   ],
   "source": [
    "# The final model evaluation\n",
    "cost_diff_class(LR_c_train_score,LR_c_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fEUrdHRYpLCA"
   },
   "source": [
    "## Model Optimization - Hyperparameter Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make copy from the original df to prefrome the hyperparametr tuning\n",
    "cl_h_df = df.copy()\n",
    "\n",
    "# Remove unwanted columns from Regression Training\n",
    "unwanted_cols = ['c_id','RegistrationTime', 'CloseTime', 'Hour','Month', 'Day', 'WeekDay', 'PartsList', 'PositionList', 'PartStateList']\n",
    "\n",
    "unwanted_cols.append('AssessmentCost')\n",
    "unwanted_cols.append('SparePartCost')\n",
    "unwanted_cols.append('TotalCost')\n",
    "unwanted_cols.append('SparePart_Differace%')\n",
    "unwanted_cols.append('AssessmentEvaluation')\n",
    "\n",
    "unwanted_cols.append('TimeEvaluation')\n",
    "unwanted_cols.append('PartOfDay')\n",
    "unwanted_cols.append('DurationTime')\n",
    "\n",
    "unwanted_cols.append('CarColor')\n",
    "# unwanted_cols.append('CarClass')\n",
    "# unwanted_cols.append('CarType')\n",
    "# unwanted_cols.append('ManufactureYear')\n",
    "\n",
    "# unwanted_cols.append('PartsNumber')\n",
    "# unwanted_cols.append('PaymentType')\n",
    "\n",
    "# unwanted_cols.append('PartStateList')\n",
    "\n",
    "target = 'TotalCostEvaluation'\n",
    "\n",
    "cl_h_df.drop(unwanted_cols, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# Extract the categorical and numircal columns\n",
    "cat_cols = cl_h_df.describe(exclude='number').columns\n",
    "num_cols = cl_h_df.describe().columns\n",
    "\n",
    "cl_h_df[cat_cols]=cl_h_df[cat_cols].apply(LabelEncoder().fit_transform)\n",
    "\n",
    "\n",
    "# Split the data to train and test with 80% for the train set and 20% for test set and make the random state to 42  \n",
    "X_train, X_test, y_train, y_test = train_test_split(cl_h_df.drop(target, axis=1), cl_h_df[target],  train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Now combine all last transfromers to one pipline.\n",
    "cl = Pipeline(\n",
    "    steps=[\n",
    "        ('Model', XGBRegressor())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 721 candidates, totalling 3605 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\user\\Documents\\OneDrive2\\OneDrive\\Big Data & AI (Bootcamp)\\CapstoneProjcet1\\MachineLearning.ipynb Cell 96\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Documents/OneDrive2/OneDrive/Big%20Data%20%26%20AI%20%28Bootcamp%29/CapstoneProjcet1/MachineLearning.ipynb#Y543sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m param_grid \u001b[39m=\u001b[39m [{\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Documents/OneDrive2/OneDrive/Big%20Data%20%26%20AI%20%28Bootcamp%29/CapstoneProjcet1/MachineLearning.ipynb#Y543sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39m# Speicfy the XG Boost Regressor model and it several parameters \u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Documents/OneDrive2/OneDrive/Big%20Data%20%26%20AI%20%28Bootcamp%29/CapstoneProjcet1/MachineLearning.ipynb#Y543sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mModel\u001b[39m\u001b[39m\"\u001b[39m:[XGBClassifier()],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/Documents/OneDrive2/OneDrive/Big%20Data%20%26%20AI%20%28Bootcamp%29/CapstoneProjcet1/MachineLearning.ipynb#Y543sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mModel\u001b[39m\u001b[39m\"\u001b[39m:[XGBClassifier()],   \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/Documents/OneDrive2/OneDrive/Big%20Data%20%26%20AI%20%28Bootcamp%29/CapstoneProjcet1/MachineLearning.ipynb#Y543sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m }]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/Documents/OneDrive2/OneDrive/Big%20Data%20%26%20AI%20%28Bootcamp%29/CapstoneProjcet1/MachineLearning.ipynb#Y543sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m grid_cl \u001b[39m=\u001b[39m GridSearchCV(cl, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/Documents/OneDrive2/OneDrive/Big%20Data%20%26%20AI%20%28Bootcamp%29/CapstoneProjcet1/MachineLearning.ipynb#Y543sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m                     param_grid\u001b[39m=\u001b[39mparam_grid, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/Documents/OneDrive2/OneDrive/Big%20Data%20%26%20AI%20%28Bootcamp%29/CapstoneProjcet1/MachineLearning.ipynb#Y543sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m                     cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/Documents/OneDrive2/OneDrive/Big%20Data%20%26%20AI%20%28Bootcamp%29/CapstoneProjcet1/MachineLearning.ipynb#Y543sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m                     error_score\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/Documents/OneDrive2/OneDrive/Big%20Data%20%26%20AI%20%28Bootcamp%29/CapstoneProjcet1/MachineLearning.ipynb#Y543sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m                    )\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/user/Documents/OneDrive2/OneDrive/Big%20Data%20%26%20AI%20%28Bootcamp%29/CapstoneProjcet1/MachineLearning.ipynb#Y543sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m grid_cl\u001b[39m.\u001b[39;49mfit(X_train,y_train)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:891\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    885\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    886\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    887\u001b[0m     )\n\u001b[0;32m    889\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 891\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    893\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    894\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    895\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1392\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1391\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1392\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:838\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    830\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    831\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    832\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    833\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    834\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    835\u001b[0m         )\n\u001b[0;32m    836\u001b[0m     )\n\u001b[1;32m--> 838\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    839\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    840\u001b[0m         clone(base_estimator),\n\u001b[0;32m    841\u001b[0m         X,\n\u001b[0;32m    842\u001b[0m         y,\n\u001b[0;32m    843\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    844\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    845\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    846\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    847\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    848\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    849\u001b[0m     )\n\u001b[0;32m    850\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    851\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    852\u001b[0m     )\n\u001b[0;32m    853\u001b[0m )\n\u001b[0;32m    855\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    856\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    857\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    858\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    859\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    860\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1053\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1055\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1056\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[0;32m   1057\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1058\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    933\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    934\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 935\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[0;32m    936\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    937\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    540\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    541\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 542\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m    543\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    544\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\lib\\concurrent\\futures\\_base.py:441\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m    439\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[1;32m--> 441\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    443\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    444\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\lib\\threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    311\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 312\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[0;32m    313\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    314\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "param_grid = [{\n",
    "    # Speicfy the XG Boost Regressor model and it several parameters \n",
    "    \"Model\":[XGBClassifier()],\n",
    "    \"Model__n_estimators\": [x for x in np.arange(150,301, 50)],\n",
    "    \"Model__max_depth\":[x for x in np.arange(3,12, 1)],\n",
    "    # \"Model__subsample\": [x for x in np.arange(0.75,1.01, 0.05)],\n",
    "    \"Model__eta\":  [0.01,0.15,0.25,0.3],    #[x for x in np.arange(0.01,0.35, 0.02)],\n",
    "    \"Model__gamma\": [1,2,4,6,8] #[x for x in np.arange(0,9, 1)],\n",
    "    \n",
    "},\n",
    "{\n",
    "    # Speicfy the XG Boost Regressor model and it several parameters \n",
    "    \"Model\":[XGBClassifier()],   \n",
    "}]\n",
    "\n",
    "grid_cl = GridSearchCV(cl, \n",
    "                    param_grid=param_grid, \n",
    "                    cv=5, \n",
    "                    verbose=1,  \n",
    "                    n_jobs=-1, \n",
    "                    error_score='raise'\n",
    "                   )\n",
    "\n",
    "grid_cl.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_Model</th>\n",
       "      <th>param_Model__eta</th>\n",
       "      <th>param_Model__gamma</th>\n",
       "      <th>param_Model__max_depth</th>\n",
       "      <th>param_Model__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>32.737361</td>\n",
       "      <td>0.593453</td>\n",
       "      <td>0.043610</td>\n",
       "      <td>0.010133</td>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>150</td>\n",
       "      <td>{'Model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.276313</td>\n",
       "      <td>0.276150</td>\n",
       "      <td>0.289174</td>\n",
       "      <td>0.285684</td>\n",
       "      <td>0.284130</td>\n",
       "      <td>0.282290</td>\n",
       "      <td>0.005210</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>61.039126</td>\n",
       "      <td>1.614892</td>\n",
       "      <td>0.044610</td>\n",
       "      <td>0.007737</td>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>300</td>\n",
       "      <td>{'Model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.276313</td>\n",
       "      <td>0.276150</td>\n",
       "      <td>0.289174</td>\n",
       "      <td>0.285684</td>\n",
       "      <td>0.284130</td>\n",
       "      <td>0.282290</td>\n",
       "      <td>0.005210</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>51.476975</td>\n",
       "      <td>1.251770</td>\n",
       "      <td>0.046011</td>\n",
       "      <td>0.008879</td>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>250</td>\n",
       "      <td>{'Model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.276313</td>\n",
       "      <td>0.276150</td>\n",
       "      <td>0.289174</td>\n",
       "      <td>0.285684</td>\n",
       "      <td>0.284130</td>\n",
       "      <td>0.282290</td>\n",
       "      <td>0.005210</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>42.078862</td>\n",
       "      <td>0.912306</td>\n",
       "      <td>0.047211</td>\n",
       "      <td>0.006883</td>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>200</td>\n",
       "      <td>{'Model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.276313</td>\n",
       "      <td>0.276150</td>\n",
       "      <td>0.289174</td>\n",
       "      <td>0.285684</td>\n",
       "      <td>0.284130</td>\n",
       "      <td>0.282290</td>\n",
       "      <td>0.005210</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>52.041302</td>\n",
       "      <td>1.791341</td>\n",
       "      <td>0.041410</td>\n",
       "      <td>0.007555</td>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>{'Model': XGBRegressor(base_score=None, booste...</td>\n",
       "      <td>0.276239</td>\n",
       "      <td>0.274027</td>\n",
       "      <td>0.289021</td>\n",
       "      <td>0.287573</td>\n",
       "      <td>0.284258</td>\n",
       "      <td>0.282223</td>\n",
       "      <td>0.006032</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "204      32.737361      0.593453         0.043610        0.010133   \n",
       "207      61.039126      1.614892         0.044610        0.007737   \n",
       "206      51.476975      1.251770         0.046011        0.008879   \n",
       "205      42.078862      0.912306         0.047211        0.006883   \n",
       "203      52.041302      1.791341         0.041410        0.007555   \n",
       "\n",
       "      param_Model param_Model__eta param_Model__gamma param_Model__max_depth  \\\n",
       "204  XGBRegressor             0.15                  1                      9   \n",
       "207  XGBRegressor             0.15                  1                      9   \n",
       "206  XGBRegressor             0.15                  1                      9   \n",
       "205  XGBRegressor             0.15                  1                      9   \n",
       "203  XGBRegressor             0.15                  1                      8   \n",
       "\n",
       "    param_Model__n_estimators  \\\n",
       "204                       150   \n",
       "207                       300   \n",
       "206                       250   \n",
       "205                       200   \n",
       "203                       300   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "204  {'Model': XGBRegressor(base_score=None, booste...           0.276313   \n",
       "207  {'Model': XGBRegressor(base_score=None, booste...           0.276313   \n",
       "206  {'Model': XGBRegressor(base_score=None, booste...           0.276313   \n",
       "205  {'Model': XGBRegressor(base_score=None, booste...           0.276313   \n",
       "203  {'Model': XGBRegressor(base_score=None, booste...           0.276239   \n",
       "\n",
       "     split1_test_score  split2_test_score  split3_test_score  \\\n",
       "204           0.276150           0.289174           0.285684   \n",
       "207           0.276150           0.289174           0.285684   \n",
       "206           0.276150           0.289174           0.285684   \n",
       "205           0.276150           0.289174           0.285684   \n",
       "203           0.274027           0.289021           0.287573   \n",
       "\n",
       "     split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "204           0.284130         0.282290        0.005210                1  \n",
       "207           0.284130         0.282290        0.005210                2  \n",
       "206           0.284130         0.282290        0.005210                3  \n",
       "205           0.284130         0.282290        0.005210                4  \n",
       "203           0.284258         0.282223        0.006032                5  "
      ]
     },
     "execution_count": 556,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all the grid search result in dataframe\n",
    "grid_cl_df = pd.DataFrame(grid_cl.cv_results_)\n",
    "\n",
    "# To take just the name of the model without any additoinal parameters\n",
    "grid_cl_df['param_Model'] = grid_cl_df['param_Model'].apply(lambda x : str(x).split('(')[0])\n",
    "\n",
    "# Sort the dataframe on the rank test score\n",
    "grid_cl_df= grid_cl_df.sort_values(by = ['rank_test_score'])\n",
    "\n",
    "# Get Five top result\n",
    "grid_cl_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The best result from the grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Model': XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
       "              colsample_bynode=None, colsample_bytree=None,\n",
       "              enable_categorical=False, eta=0.15, gamma=1, gpu_id=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_delta_step=None, max_depth=9,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=150, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, reg_alpha=None, reg_lambda=None,\n",
       "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
       "              validate_parameters=None, verbosity=None),\n",
       " 'Model__eta': 0.15,\n",
       " 'Model__gamma': 1,\n",
       " 'Model__max_depth': 9,\n",
       " 'Model__n_estimators': 150}"
      ]
     },
     "execution_count": 557,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cl.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>>>>>>>>Testing Set Report<<<<<<<<<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\user\\Documents\\OneDrive2\\OneDrive\\Big Data & AI (Bootcamp)\\CapstoneProjcet1\\MachineLearning.ipynb Cell 101\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Documents/OneDrive2/OneDrive/Big%20Data%20%26%20AI%20%28Bootcamp%29/CapstoneProjcet1/MachineLearning.ipynb#Y544sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Evaluation on the testing set \u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/user/Documents/OneDrive2/OneDrive/Big%20Data%20%26%20AI%20%28Bootcamp%29/CapstoneProjcet1/MachineLearning.ipynb#Y544sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m grid_cl_test_score\u001b[39m=\u001b[39m calc_cost_class(X_test, y_test, grid_cl)\n",
      "\u001b[1;32mc:\\Users\\user\\Documents\\OneDrive2\\OneDrive\\Big Data & AI (Bootcamp)\\CapstoneProjcet1\\MachineLearning.ipynb Cell 101\u001b[0m in \u001b[0;36mcalc_cost_class\u001b[1;34m(X_test, y_test, clf, setName)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Documents/OneDrive2/OneDrive/Big%20Data%20%26%20AI%20%28Bootcamp%29/CapstoneProjcet1/MachineLearning.ipynb#Y544sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m y_pred\u001b[39m=\u001b[39mclf\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Documents/OneDrive2/OneDrive/Big%20Data%20%26%20AI%20%28Bootcamp%29/CapstoneProjcet1/MachineLearning.ipynb#Y544sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m>>>>>>>>>>>>>>>>>>>>>>>\u001b[39m\u001b[39m{\u001b[39;00msetName\u001b[39m}\u001b[39;00m\u001b[39m Set Report<<<<<<<<<<<<<<<<<<<<<<<<<<\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Documents/OneDrive2/OneDrive/Big%20Data%20%26%20AI%20%28Bootcamp%29/CapstoneProjcet1/MachineLearning.ipynb#Y544sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mAccuracy : \u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/user/Documents/OneDrive2/OneDrive/Big%20Data%20%26%20AI%20%28Bootcamp%29/CapstoneProjcet1/MachineLearning.ipynb#Y544sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m accuracy_score(y_test,y_pred)\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/Documents/OneDrive2/OneDrive/Big%20Data%20%26%20AI%20%28Bootcamp%29/CapstoneProjcet1/MachineLearning.ipynb#Y544sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mClassification Report : \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/Documents/OneDrive2/OneDrive/Big%20Data%20%26%20AI%20%28Bootcamp%29/CapstoneProjcet1/MachineLearning.ipynb#Y544sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m classification_report(y_test, y_pred))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/Documents/OneDrive2/OneDrive/Big%20Data%20%26%20AI%20%28Bootcamp%29/CapstoneProjcet1/MachineLearning.ipynb#Y544sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mConfusion Matrix: \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:211\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[39m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \n\u001b[0;32m    147\u001b[0m \u001b[39mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[39m0.5\u001b[39;00m\n\u001b[0;32m    208\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[39m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m--> 211\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m    212\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    213\u001b[0m \u001b[39mif\u001b[39;00m y_type\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mmultilabel\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     90\u001b[0m     y_type \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[0;32m     92\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(y_type) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 93\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     94\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mClassification metrics can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt handle a mix of \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m targets\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m     95\u001b[0m             type_true, type_pred\n\u001b[0;32m     96\u001b[0m         )\n\u001b[0;32m     97\u001b[0m     )\n\u001b[0;32m     99\u001b[0m \u001b[39m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    100\u001b[0m y_type \u001b[39m=\u001b[39m y_type\u001b[39m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous targets"
     ]
    }
   ],
   "source": [
    "# Evaluation on the testing set \n",
    "grid_cl_test_score= calc_cost_class(X_test, y_test, grid_cl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/XGBC_Model_19_23-21']"
      ]
     },
     "execution_count": 616,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(XGB_R, f\"models/XGBR_Model_19_23-21\")\n",
    "joblib.dump(XGB_C, f\"models/XGBC_Model_19_23-21\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/scaler_7AM']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(RFR, f\"models/RFR_Model_7AM\")\n",
    "# joblib.dump(svr, f\"models/SVR_Model_7AM\")\n",
    "joblib.dump(XGB_R, f\"models/XGBR_Model_7AM\")\n",
    "# joblib.dump(Oencoder, f\"models/ordinal_endcoder_7AM\")\n",
    "# joblib.dump(scaler, f\"models/scaler_7AM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests on Actual value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'c_id': 147064,\n",
       " 'City': 'Riyadh',\n",
       " 'RegistrationTime': '2018-07-17 18:15:24.793000',\n",
       " 'CloseTime': '2018-07-17 18:30:00',\n",
       " 'CarBrand': 'Toyota',\n",
       " 'CarModel': 'FG',\n",
       " 'ManufactureYear': 2010,\n",
       " 'CarColor': 'white',\n",
       " 'AssessmentCost': 3057,\n",
       " 'SparePartCost': 557,\n",
       " 'TotalCost': 3614,\n",
       " 'PaymentType': 'POS',\n",
       " 'DurationTime': 14,\n",
       " 'Hour': 18,\n",
       " 'Month': 7,\n",
       " 'Day': 17,\n",
       " 'WeekDay': 'Tuesday',\n",
       " 'PartsList': ['Bumper', 'Decoration'],\n",
       " 'PositionList': ['rear right'],\n",
       " 'PartStateList': ['New'],\n",
       " 'CarMade': 'Japan',\n",
       " 'CarClass': 'Normal',\n",
       " 'CarType': 'Multi',\n",
       " 'SparePart_Differace%': 448.8330341113106,\n",
       " 'AssessmentEvaluation': 'Very High',\n",
       " 'PartsNumber': 2,\n",
       " 'TimeEvaluation': 'Acceptable',\n",
       " 'PartOfDay': 'Evening',\n",
       " 'RushHour': 'No'}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[146990].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame({\n",
    " 'Area': {0: 0.0},\n",
    " 'CarBrand': {0: 46.0},\n",
    " 'CarModel': {0: 540.0},\n",
    " 'ManufactureYear': {0: 0.6929804224731195},\n",
    " 'CarColor': {0: 16.0},\n",
    " 'PaymentType': {0: 0.0},\n",
    " 'CarMade': {0: 9.0},\n",
    " 'CarClass': {0: 1.0},\n",
    " 'CarType': {0: 1.0},\n",
    " 'part_Bridge': {0: 0},\n",
    " 'part_Bumper': {0: 1},\n",
    " 'part_Coilover': {0: 0},\n",
    " 'part_Control Arms': {0: 0},\n",
    " 'part_Dash insulator': {0: 0},\n",
    " 'part_Decoration': {0: 0},\n",
    " 'part_Door': {0: 0},\n",
    " 'part_Fender': {0: 1},\n",
    " 'part_Fiber': {0: 0},\n",
    " 'part_Grill': {0: 0},\n",
    " 'part_Handle': {0: 0},\n",
    " 'part_Headlight': {0: 0},\n",
    " 'part_Hinges': {0: 0},\n",
    " 'part_Hood': {0: 0},\n",
    " 'part_Injection': {0: 0},\n",
    " 'part_Mirror': {0: 0},\n",
    " 'part_Mudguard': {0: 0},\n",
    " 'part_Muffler': {0: 0},\n",
    " 'part_Other': {0: 0},\n",
    " 'part_Power Window': {0: 0},\n",
    " 'part_Radiator': {0: 0},\n",
    " 'part_Rims': {0: 0},\n",
    " 'part_Rotor': {0: 0},\n",
    " 'part_Sensor': {0: 0},\n",
    " 'part_Shock absorber': {0: 0},\n",
    " 'part_Splash shield': {0: 0},\n",
    " 'part_Stabilizer link': {0: 0},\n",
    " 'part_Taillight': {0: 0},\n",
    " 'part_Tie rod': {0: 0},\n",
    " 'part_Tire': {0: 0},\n",
    " 'part_Windshild ': {0: 0},\n",
    " 'pos_front': {0: 0},\n",
    " 'pos_left': {0: 0},\n",
    " 'pos_rear': {0: 1},\n",
    " 'pos_rear left': {0: 1},\n",
    " 'pos_rear right': {0: 0},\n",
    " 'pos_right': {0: 0},\n",
    " 'pos_undefined': {0: 0},\n",
    " 'state_New': {0: 1},\n",
    " 'state_Used': {0: 0}\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>CarBrand</th>\n",
       "      <th>CarModel</th>\n",
       "      <th>ManufactureYear</th>\n",
       "      <th>CarColor</th>\n",
       "      <th>PaymentType</th>\n",
       "      <th>CarMade</th>\n",
       "      <th>CarClass</th>\n",
       "      <th>CarType</th>\n",
       "      <th>part_Bridge</th>\n",
       "      <th>part_Bumper</th>\n",
       "      <th>part_Coilover</th>\n",
       "      <th>part_Control Arms</th>\n",
       "      <th>part_Dash insulator</th>\n",
       "      <th>part_Decoration</th>\n",
       "      <th>part_Door</th>\n",
       "      <th>part_Fender</th>\n",
       "      <th>part_Fiber</th>\n",
       "      <th>part_Grill</th>\n",
       "      <th>part_Handle</th>\n",
       "      <th>part_Headlight</th>\n",
       "      <th>part_Hinges</th>\n",
       "      <th>part_Hood</th>\n",
       "      <th>part_Injection</th>\n",
       "      <th>part_Mirror</th>\n",
       "      <th>part_Mudguard</th>\n",
       "      <th>part_Muffler</th>\n",
       "      <th>part_Other</th>\n",
       "      <th>part_Power Window</th>\n",
       "      <th>part_Radiator</th>\n",
       "      <th>part_Rims</th>\n",
       "      <th>part_Rotor</th>\n",
       "      <th>part_Sensor</th>\n",
       "      <th>part_Shock absorber</th>\n",
       "      <th>part_Splash shield</th>\n",
       "      <th>part_Stabilizer link</th>\n",
       "      <th>part_Taillight</th>\n",
       "      <th>part_Tie rod</th>\n",
       "      <th>part_Tire</th>\n",
       "      <th>part_Windshild</th>\n",
       "      <th>pos_front</th>\n",
       "      <th>pos_left</th>\n",
       "      <th>pos_rear</th>\n",
       "      <th>pos_rear left</th>\n",
       "      <th>pos_rear right</th>\n",
       "      <th>pos_right</th>\n",
       "      <th>pos_undefined</th>\n",
       "      <th>state_New</th>\n",
       "      <th>state_Used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>0.69298</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Area  CarBrand  CarModel  ManufactureYear  CarColor  PaymentType  CarMade  \\\n",
       "0   0.0      46.0     540.0          0.69298      16.0          0.0      9.0   \n",
       "\n",
       "   CarClass  CarType  part_Bridge  part_Bumper  part_Coilover  \\\n",
       "0       1.0      1.0            0            1              0   \n",
       "\n",
       "   part_Control Arms  part_Dash insulator  part_Decoration  part_Door  \\\n",
       "0                  0                    0                0          0   \n",
       "\n",
       "   part_Fender  part_Fiber  part_Grill  part_Handle  part_Headlight  \\\n",
       "0            1           0           0            0               0   \n",
       "\n",
       "   part_Hinges  part_Hood  part_Injection  part_Mirror  part_Mudguard  \\\n",
       "0            0          0               0            0              0   \n",
       "\n",
       "   part_Muffler  part_Other  part_Power Window  part_Radiator  part_Rims  \\\n",
       "0             0           0                  0              0          0   \n",
       "\n",
       "   part_Rotor  part_Sensor  part_Shock absorber  part_Splash shield  \\\n",
       "0           0            0                    0                   0   \n",
       "\n",
       "   part_Stabilizer link  part_Taillight  part_Tie rod  part_Tire  \\\n",
       "0                     0               0             0          0   \n",
       "\n",
       "   part_Windshild   pos_front  pos_left  pos_rear  pos_rear left  \\\n",
       "0                0          0         0         1              1   \n",
       "\n",
       "   pos_rear right  pos_right  pos_undefined  state_New  state_Used  \n",
       "0               0          0              0          1           0  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Feature shape mismatch, expected: 55, got 49",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\user\\Documents\\OneDrive2\\OneDrive\\Big Data & AI (Bootcamp)\\CapstoneProjcet1\\MachineLearning.ipynb Cell 60\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/user/Documents/OneDrive2/OneDrive/Big%20Data%20%26%20AI%20%28Bootcamp%29/CapstoneProjcet1/MachineLearning.ipynb#Y224sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m out \u001b[39m=\u001b[39m XGB_R\u001b[39m.\u001b[39;49mpredict(test_df)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Documents/OneDrive2/OneDrive/Big%20Data%20%26%20AI%20%28Bootcamp%29/CapstoneProjcet1/MachineLearning.ipynb#Y224sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m test_df[\u001b[39m'\u001b[39m\u001b[39mTotalCost\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m out\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:881\u001b[0m, in \u001b[0;36mXGBModel.predict\u001b[1;34m(self, X, output_margin, ntree_limit, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_can_use_inplace_predict():\n\u001b[0;32m    880\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 881\u001b[0m         predts \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_booster()\u001b[39m.\u001b[39;49minplace_predict(\n\u001b[0;32m    882\u001b[0m             data\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m    883\u001b[0m             iteration_range\u001b[39m=\u001b[39;49miteration_range,\n\u001b[0;32m    884\u001b[0m             predict_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmargin\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39mif\u001b[39;49;00m output_margin \u001b[39melse\u001b[39;49;00m \u001b[39m\"\u001b[39;49m\u001b[39mvalue\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    885\u001b[0m             missing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmissing,\n\u001b[0;32m    886\u001b[0m             base_margin\u001b[39m=\u001b[39;49mbase_margin,\n\u001b[0;32m    887\u001b[0m             validate_features\u001b[39m=\u001b[39;49mvalidate_features,\n\u001b[0;32m    888\u001b[0m         )\n\u001b[0;32m    889\u001b[0m         \u001b[39mif\u001b[39;00m _is_cupy_array(predts):\n\u001b[0;32m    890\u001b[0m             \u001b[39mimport\u001b[39;00m \u001b[39mcupy\u001b[39;00m     \u001b[39m# pylint: disable=import-error\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\lib\\site-packages\\xgboost\\core.py:2025\u001b[0m, in \u001b[0;36mBooster.inplace_predict\u001b[1;34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001b[0m\n\u001b[0;32m   2021\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m   2022\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m`shape` attribute is required when `validate_features` is True.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2023\u001b[0m         )\n\u001b[0;32m   2024\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data\u001b[39m.\u001b[39mshape) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_features() \u001b[39m!=\u001b[39m data\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]:\n\u001b[1;32m-> 2025\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   2026\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFeature shape mismatch, expected: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_features()\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2027\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgot \u001b[39m\u001b[39m{\u001b[39;00mdata\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2028\u001b[0m         )\n\u001b[0;32m   2030\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m _array_interface\n\u001b[0;32m   2031\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, np\u001b[39m.\u001b[39mndarray):\n",
      "\u001b[1;31mValueError\u001b[0m: Feature shape mismatch, expected: 55, got 49"
     ]
    }
   ],
   "source": [
    "out = XGB_R.predict(test_df)\n",
    "test_df['TotalCost'] = out\n",
    "# scaler.inverse_transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5144.9707]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>CarBrand</th>\n",
       "      <th>CarModel</th>\n",
       "      <th>ManufactureYear</th>\n",
       "      <th>CarColor</th>\n",
       "      <th>PaymentType</th>\n",
       "      <th>CarMade</th>\n",
       "      <th>CarClass</th>\n",
       "      <th>CarType</th>\n",
       "      <th>part_Bridge</th>\n",
       "      <th>part_Bumper</th>\n",
       "      <th>part_Coilover</th>\n",
       "      <th>part_Control Arms</th>\n",
       "      <th>part_Dash insulator</th>\n",
       "      <th>part_Decoration</th>\n",
       "      <th>part_Door</th>\n",
       "      <th>part_Fender</th>\n",
       "      <th>part_Fiber</th>\n",
       "      <th>part_Grill</th>\n",
       "      <th>part_Handle</th>\n",
       "      <th>part_Headlight</th>\n",
       "      <th>part_Hinges</th>\n",
       "      <th>part_Hood</th>\n",
       "      <th>part_Injection</th>\n",
       "      <th>part_Mirror</th>\n",
       "      <th>part_Mudguard</th>\n",
       "      <th>part_Muffler</th>\n",
       "      <th>part_Other</th>\n",
       "      <th>part_Power Window</th>\n",
       "      <th>part_Radiator</th>\n",
       "      <th>part_Rims</th>\n",
       "      <th>part_Rotor</th>\n",
       "      <th>part_Sensor</th>\n",
       "      <th>part_Shock absorber</th>\n",
       "      <th>part_Splash shield</th>\n",
       "      <th>part_Stabilizer link</th>\n",
       "      <th>part_Taillight</th>\n",
       "      <th>part_Tie rod</th>\n",
       "      <th>part_Tire</th>\n",
       "      <th>part_Windshild</th>\n",
       "      <th>pos_front</th>\n",
       "      <th>pos_left</th>\n",
       "      <th>pos_rear</th>\n",
       "      <th>pos_rear left</th>\n",
       "      <th>pos_rear right</th>\n",
       "      <th>pos_right</th>\n",
       "      <th>pos_undefined</th>\n",
       "      <th>state_New</th>\n",
       "      <th>state_Used</th>\n",
       "      <th>TotalCost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>0.69298</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5144.970703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Area  CarBrand  CarModel  ManufactureYear  CarColor  PaymentType  CarMade  \\\n",
       "0   0.0      46.0     540.0          0.69298      16.0          0.0      9.0   \n",
       "\n",
       "   CarClass  CarType  part_Bridge  part_Bumper  part_Coilover  \\\n",
       "0       1.0      1.0            0            1              0   \n",
       "\n",
       "   part_Control Arms  part_Dash insulator  part_Decoration  part_Door  \\\n",
       "0                  0                    0                0          0   \n",
       "\n",
       "   part_Fender  part_Fiber  part_Grill  part_Handle  part_Headlight  \\\n",
       "0            1           0           0            0               0   \n",
       "\n",
       "   part_Hinges  part_Hood  part_Injection  part_Mirror  part_Mudguard  \\\n",
       "0            0          0               0            0              0   \n",
       "\n",
       "   part_Muffler  part_Other  part_Power Window  part_Radiator  part_Rims  \\\n",
       "0             0           0                  0              0          0   \n",
       "\n",
       "   part_Rotor  part_Sensor  part_Shock absorber  part_Splash shield  \\\n",
       "0           0            0                    0                   0   \n",
       "\n",
       "   part_Stabilizer link  part_Taillight  part_Tie rod  part_Tire  \\\n",
       "0                     0               0             0          0   \n",
       "\n",
       "   part_Windshild   pos_front  pos_left  pos_rear  pos_rear left  \\\n",
       "0                0          0         0         1              1   \n",
       "\n",
       "   pos_rear right  pos_right  pos_undefined  state_New  state_Used  \\\n",
       "0               0          0              0          1           0   \n",
       "\n",
       "     TotalCost  \n",
       "0  5144.970703  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(out)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Additional Model (Deep Learning)\n",
    "#### Here we try to use Artifictial Neuaral Network with our built function to hyperparameter tuning with classification problem\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HyperTuning functions and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Override the callback function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code is an override on the Callback function of Keras and trying to build our own condition to interrupt the training \n",
    "# if the error for the second epoch is higher than the previous epoch by 2%\n",
    "class cut_theTraining(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, base_on):\n",
    "        super(cut_theTraining, self).__init__()\n",
    "        #Define my varibales \"base_on\" it is any loss that you want to cut from, whether it is a training or validation loss\n",
    "        #'Previous' varibale will save the previous epoch loss \n",
    "        self.base_on = base_on\n",
    "        self.previous=0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None): \n",
    "        # Init poitn if it's first epoch and there is not previous loss\n",
    "        if epoch==0:\n",
    "            self.previous= logs[self.base_on]\n",
    "            \n",
    "        # define the loss threshold \n",
    "        error_tolerance= self.previous+(self.previous*0.05)\n",
    "\n",
    "        #If the current loss was higher than the threshold, I would cut off the training\n",
    "        if logs[self.base_on] >= error_tolerance:\n",
    "            self.model.stop_training = True\n",
    "\n",
    "        #Make the current loss the previous one in preparation for the next iteration\n",
    "        if epoch>0:\n",
    "            self.previous= logs[self.base_on]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check user input function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a function to check user input\n",
    "def check_user_input(layers_nums, units_nums, activations, optimizers, epochs, batch_size):\n",
    "\n",
    "    #The number of layers must be entered as a list, and the number of layers must be greater than 3, otherwise an error will appear.\n",
    "    if type(layers_nums) is list:\n",
    "        for x in layers_nums:\n",
    "            if x<3:\n",
    "                raise Exception(\"Layers Number Must Be More than 2!\")\n",
    "    else:\n",
    "        raise Exception(\"Layers number Must Be in list!\")\n",
    "\n",
    "    # The number of units must be entered as a list, and the number of units must be greater than 0, otherwise an error will appear.\n",
    "    if type(units_nums) is list:\n",
    "        for x in units_nums:\n",
    "            if x<1:\n",
    "                raise Exception(\"Layers Number Must Be More than 0!\")\n",
    "    else:\n",
    "        raise Exception(\"Units number Must Be in list!\")  \n",
    "          \n",
    "    #The activations must be entered as a list, and the entered activations must be from the list below the condition\n",
    "    #(taken from the official website), otherwise an error will appear.\n",
    "    if type(activations) is list:\n",
    "        activationsList=['relu','sigmoid','softmax','softplus', 'softsign', 'tanh', 'selu','elu', 'exponential']\n",
    "        for x in activations:\n",
    "            if x not in activationsList:\n",
    "                raise Exception(f\"({x}) Not In Activations List\")\n",
    "    else:\n",
    "        raise Exception(\"Activations Must Be in list!\")\n",
    "\n",
    "    #The optimizers must be entered as a list, and the entered optimisers must be from the list below the condition \n",
    "    # (taken from the official website), otherwise an error will appear.\n",
    "    if type(optimizers) is list:\n",
    "        optimizersList=['sgd','rmsprop','adam','adadelta','adagrad','adamax','nadam','ftrl']\n",
    "        for x in optimizers:\n",
    "            if str(x).lower() not in optimizersList:\n",
    "                raise Exception(f\"({x}) Not In Optimizers List\")\n",
    "    else:\n",
    "        raise Exception(\"Activations Must Be in list!\")\n",
    "\n",
    "    #The epochs must be between 30 and 100, otherwise an error will appear.\n",
    "    if epochs<30 and epochs>100:\n",
    "        raise Exception(\"Epoch Number Must Be Between 30-100 !!\")\n",
    "\n",
    "    #The batch size must be more than or equal 1, otherwise an error will appear.\n",
    "    if batch_size<1:\n",
    "        raise Exception(\"Batch Size Must Be Greater than 0!!\")\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the function and set the default values, which enables the user to call the function without setting all the parameters\n",
    "def build_model(\n",
    "    X_train, y_train, X_test, y_test, base_on=None,\n",
    "    layers_nums=[3], units_nums=[6], activations=['relu'], optimizers=['adam'], epochs=100, batch_size=32):\n",
    "\n",
    "    #Verify user input\n",
    "    check_user_input(layers_nums, units_nums, activations, optimizers, epochs, batch_size)\n",
    "\n",
    "    if base_on:\n",
    "        base_on=cut_theTraining(base_on=base_on)\n",
    "\n",
    "    # Display the fits number by multiplying the lengths of inputs\n",
    "    fitting_number= len(layers_nums)*len(units_nums)*len(activations)*len(optimizers)\n",
    "    print(f'Number of fitting:{fitting_number}')\n",
    "\n",
    "    #Timer Start point\n",
    "    start_t=time.time()\n",
    "\n",
    "    # Initializing the result variable to put all the trained models in it\n",
    "    resutls={}\n",
    "    counter=0\n",
    "\n",
    "    #Initializing a global variable for a model\n",
    "    model = tf.keras.models.Sequential()\n",
    "\n",
    "    #This part is where the model is trained on all inputs by traditional loop (for)\n",
    "    for activation in activations:\n",
    "        for optimizer in optimizers:\n",
    "            for layer in layers_nums: \n",
    "                for unit in units_nums:\n",
    "                    #Take the current layer number and then create layers on the model variable \n",
    "                    '''\n",
    "                    For example, the current layer 3, this iteration will be from 0 to 2, as the first iteration will create a new model and a new layer, \n",
    "                    and the second iteration will be the creation of only one layer, and the third iteration will put the output layer and put the \n",
    "                    result of the model in the results variable\n",
    "                    '''\n",
    "                    for l in range(layer):\n",
    "\n",
    "                        #If it is the first iteration, create new model\n",
    "                        if l==0:\n",
    "                            print('#'*50)\n",
    "                            print(f'Initialize Model:{counter}')\n",
    "                            model = tf.keras.models.Sequential()\n",
    "                            \n",
    "                        #If this is the last iteration, add an output layer to the mod, train the mod, and save its result in the results variable\n",
    "                        if (l+1) == layer:\n",
    "                            model.add(Dense(units=4, activation='softmax'))\n",
    "                            model.compile(optimizer = optimizer, loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "                            model_history= model.fit(X_train, y_train.values, batch_size = batch_size, epochs = epochs, validation_data=(X_test, y_test), callbacks=base_on)\n",
    "\n",
    "                            resutls['Model_'+str(counter)]={\n",
    "                                'units':unit,\n",
    "                                'layers':layer,\n",
    "                                'activation':activation,\n",
    "                                'optimizer':optimizer,\n",
    "                                'epochs':epochs,\n",
    "                                'batch_size':batch_size,\n",
    "                                'model_history':model_history\n",
    "                            }\n",
    "\n",
    "                            print('='*50)\n",
    "                            print(f'End Model:{counter}')\n",
    "                            counter+=1\n",
    "                \n",
    "                        #Add a normal layer if it's a hidden layer in the middle loop\n",
    "                        model.add(Dense(units=unit, activation=activation))\n",
    "\n",
    "     #Timer End point\n",
    "    end_t=time.time()\n",
    "    \n",
    "    print('='*50)\n",
    "    print(f'Excection Time:\\n{round(end_t-start_t,2)}')\n",
    "    print(f'Number of fitting:\\n{fitting_number}')\n",
    "    print('='*50)\n",
    "\n",
    "    return resutls\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Best Model Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a function that returns the best model among the list of models in the result dictionary\n",
    "def best_model(resutls, on_val=False):\n",
    "\n",
    "    #The default variable for calculating the best accuracy\n",
    "    best_on='accuracy'\n",
    "    # If the user wants to calculate the best model for the accuracy of validation set, he/she makes this variable true\n",
    "    if on_val:\n",
    "        best_on='val_accuracy'\n",
    "\n",
    "    best_model = ''\n",
    "    max_accuarcy = 0\n",
    "    for k, v in resutls.items():\n",
    "        for k2,v2 in v.items():\n",
    "            if k2=='model_history':\n",
    "                if max_accuarcy < max(v2.history[best_on]):\n",
    "                    max_accuarcy= max(v2.history[best_on])\n",
    "                    best_model = k\n",
    "\n",
    "    return resutls[best_model]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Accuracy of Model Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model, on_val=False, is_cutted=False):\n",
    "\n",
    "    element=-1\n",
    "    on='accuracy'\n",
    "\n",
    "    # If the user wants to calculate the best accuarcy of validation set, he/she makes this variable true\n",
    "    if on_val:\n",
    "        on='val_accuracy'\n",
    "    if is_cutted:\n",
    "        element=-2\n",
    "    return model['model_history'].history[on][element]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_plot(accuracy, loss, val_accuracy=None, val_loss=None):\n",
    "    fig1 = go.Scatter(\n",
    "    y=accuracy,\n",
    "    name=\"Train_Accuracy\"\n",
    "    )\n",
    "\n",
    "\n",
    "    fig3 = go.Scatter(\n",
    "        y=loss,\n",
    "        name=\"Train_Loss\"\n",
    "    )\n",
    "\n",
    "\n",
    "    fig = make_subplots(rows=1, cols=2,\n",
    "    subplot_titles=(\"Accuracy in Each Epoch\", \"Loss in Each Epoch\")\n",
    "    )\n",
    "    fig.add_trace(fig1, row=1, col=1)\n",
    "    fig.add_trace(fig3, row=1, col=2)\n",
    "\n",
    "    if val_accuracy and val_loss:\n",
    "        fig2 = go.Scatter(\n",
    "            y=val_accuracy,\n",
    "            name=\"Val_Accuracy\")\n",
    "        fig4 = go.Scatter(\n",
    "            y=val_loss,\n",
    "            name=\"Val_Loss\")\n",
    "            \n",
    "        fig.add_trace(fig2, row=1, col=1)\n",
    "        fig.add_trace(fig4, row=1, col=2)\n",
    "\n",
    "    fig.update_layout(xaxis=dict(tickangle=90), title_text=\"Model Histroy linechart\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering and Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>CarBrand</th>\n",
       "      <th>CarModel</th>\n",
       "      <th>ManufactureYear</th>\n",
       "      <th>PaymentType</th>\n",
       "      <th>CarMade</th>\n",
       "      <th>CarClass</th>\n",
       "      <th>CarType</th>\n",
       "      <th>PartsNumber</th>\n",
       "      <th>TotalCostEvaluation</th>\n",
       "      <th>part_Bridge</th>\n",
       "      <th>part_Bumper</th>\n",
       "      <th>part_Coilover</th>\n",
       "      <th>part_Control Arms</th>\n",
       "      <th>part_Dash insulator</th>\n",
       "      <th>part_Decoration</th>\n",
       "      <th>part_Door</th>\n",
       "      <th>part_Fender</th>\n",
       "      <th>part_Fiber</th>\n",
       "      <th>part_Grill</th>\n",
       "      <th>part_Handle</th>\n",
       "      <th>part_Headlight</th>\n",
       "      <th>part_Hinges</th>\n",
       "      <th>part_Hood</th>\n",
       "      <th>part_Injection</th>\n",
       "      <th>part_Mirror</th>\n",
       "      <th>part_Mudguard</th>\n",
       "      <th>part_Muffler</th>\n",
       "      <th>part_Other</th>\n",
       "      <th>part_Power Window</th>\n",
       "      <th>part_Radiator</th>\n",
       "      <th>part_Rims</th>\n",
       "      <th>part_Rotor</th>\n",
       "      <th>part_Sensor</th>\n",
       "      <th>part_Shock absorber</th>\n",
       "      <th>part_Splash shield</th>\n",
       "      <th>part_Stabilizer link</th>\n",
       "      <th>part_Taillight</th>\n",
       "      <th>part_Tie rod</th>\n",
       "      <th>part_Tire</th>\n",
       "      <th>part_Windshild</th>\n",
       "      <th>pos_front</th>\n",
       "      <th>pos_front left</th>\n",
       "      <th>pos_front right</th>\n",
       "      <th>pos_left</th>\n",
       "      <th>pos_rear</th>\n",
       "      <th>pos_rear left</th>\n",
       "      <th>pos_rear right</th>\n",
       "      <th>pos_right</th>\n",
       "      <th>pos_undefined</th>\n",
       "      <th>state_New</th>\n",
       "      <th>state_Used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>96</td>\n",
       "      <td>815</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>96</td>\n",
       "      <td>815</td>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>655</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>362</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>412</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251468</th>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>740</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251469</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>278</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251470</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>505</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251471</th>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>278</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251472</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>674</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>251473 rows Ã— 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Area  CarBrand  CarModel  ManufactureYear  PaymentType  CarMade  \\\n",
       "0          4        96       815             2002            1       13   \n",
       "1          4        96       815             2008            1       13   \n",
       "2          2         5       655             2012            0        5   \n",
       "3          2        37       362             2011            1        9   \n",
       "4          1        50       412             2007            0        8   \n",
       "...      ...       ...       ...              ...          ...      ...   \n",
       "251468     1        40       740             2016            0        8   \n",
       "251469     0        37       278             2016            0        9   \n",
       "251470     3        12       505             2011            0       16   \n",
       "251471     1        37       278             2016            1        9   \n",
       "251472     0        37       674             2014            0        9   \n",
       "\n",
       "        CarClass  CarType  PartsNumber  TotalCostEvaluation  part_Bridge  \\\n",
       "0              0        1            4                    2            0   \n",
       "1              0        1            4                    0            0   \n",
       "2              0        0            1                    0            0   \n",
       "3              0        1            1                    2            0   \n",
       "4              0        0            2                    2            0   \n",
       "...          ...      ...          ...                  ...          ...   \n",
       "251468         1        1            2                    0            0   \n",
       "251469         1        1            5                    1            0   \n",
       "251470         1        1            1                    0            0   \n",
       "251471         1        1            2                    2            0   \n",
       "251472         1        1            1                    0            0   \n",
       "\n",
       "        part_Bumper  part_Coilover  part_Control Arms  part_Dash insulator  \\\n",
       "0                 0              0                  0                    0   \n",
       "1                 1              0                  0                    0   \n",
       "2                 1              0                  0                    0   \n",
       "3                 0              0                  0                    0   \n",
       "4                 1              0                  0                    0   \n",
       "...             ...            ...                ...                  ...   \n",
       "251468            0              0                  0                    0   \n",
       "251469            1              0                  0                    0   \n",
       "251470            0              0                  0                    1   \n",
       "251471            0              0                  0                    0   \n",
       "251472            0              0                  0                    0   \n",
       "\n",
       "        part_Decoration  part_Door  part_Fender  part_Fiber  part_Grill  \\\n",
       "0                     1          0            1           0           0   \n",
       "1                     1          0            0           0           0   \n",
       "2                     0          0            0           0           0   \n",
       "3                     0          0            0           0           0   \n",
       "4                     0          0            0           0           0   \n",
       "...                 ...        ...          ...         ...         ...   \n",
       "251468                0          0            0           0           0   \n",
       "251469                1          0            1           0           0   \n",
       "251470                0          0            0           0           0   \n",
       "251471                0          0            0           0           0   \n",
       "251472                0          1            0           0           0   \n",
       "\n",
       "        part_Handle  part_Headlight  part_Hinges  part_Hood  part_Injection  \\\n",
       "0                 0               0            0          0               0   \n",
       "1                 0               0            0          0               0   \n",
       "2                 0               0            0          0               0   \n",
       "3                 0               0            0          0               0   \n",
       "4                 0               0            0          0               0   \n",
       "...             ...             ...          ...        ...             ...   \n",
       "251468            0               0            0          0               0   \n",
       "251469            0               1            0          0               0   \n",
       "251470            0               0            0          0               0   \n",
       "251471            0               0            0          0               0   \n",
       "251472            0               0            0          0               0   \n",
       "\n",
       "        part_Mirror  part_Mudguard  part_Muffler  part_Other  \\\n",
       "0                 0              0             0           1   \n",
       "1                 0              0             0           1   \n",
       "2                 0              0             0           0   \n",
       "3                 0              0             0           0   \n",
       "4                 0              0             0           0   \n",
       "...             ...            ...           ...         ...   \n",
       "251468            0              0             0           1   \n",
       "251469            0              0             0           0   \n",
       "251470            0              0             0           0   \n",
       "251471            0              1             0           0   \n",
       "251472            0              0             0           0   \n",
       "\n",
       "        part_Power Window  part_Radiator  part_Rims  part_Rotor  part_Sensor  \\\n",
       "0                       0              0          0           0            0   \n",
       "1                       0              0          0           0            0   \n",
       "2                       0              0          0           0            0   \n",
       "3                       0              0          0           0            1   \n",
       "4                       0              0          0           0            1   \n",
       "...                   ...            ...        ...         ...          ...   \n",
       "251468                  0              0          1           0            0   \n",
       "251469                  0              0          0           0            0   \n",
       "251470                  0              0          0           0            0   \n",
       "251471                  0              0          0           0            0   \n",
       "251472                  0              0          0           0            0   \n",
       "\n",
       "        part_Shock absorber  part_Splash shield  part_Stabilizer link  \\\n",
       "0                         0                   0                     0   \n",
       "1                         0                   0                     0   \n",
       "2                         0                   0                     0   \n",
       "3                         0                   0                     0   \n",
       "4                         0                   0                     0   \n",
       "...                     ...                 ...                   ...   \n",
       "251468                    0                   0                     0   \n",
       "251469                    0                   1                     0   \n",
       "251470                    0                   0                     0   \n",
       "251471                    0                   1                     0   \n",
       "251472                    0                   0                     0   \n",
       "\n",
       "        part_Taillight  part_Tie rod  part_Tire  part_Windshild   pos_front  \\\n",
       "0                    1             0          0                0          0   \n",
       "1                    1             0          0                0          0   \n",
       "2                    0             0          0                0          0   \n",
       "3                    0             0          0                0          0   \n",
       "4                    0             0          0                0          1   \n",
       "...                ...           ...        ...              ...        ...   \n",
       "251468               0             0          0                0          0   \n",
       "251469               0             0          0                0          1   \n",
       "251470               0             0          0                0          0   \n",
       "251471               0             0          0                0          0   \n",
       "251472               0             0          0                0          0   \n",
       "\n",
       "        pos_front left  pos_front right  pos_left  pos_rear  pos_rear left  \\\n",
       "0                    1                0         1         0              1   \n",
       "1                    0                1         0         0              0   \n",
       "2                    0                0         0         1              0   \n",
       "3                    0                0         0         0              0   \n",
       "4                    0                1         0         0              0   \n",
       "...                ...              ...       ...       ...            ...   \n",
       "251468               0                0         0         0              0   \n",
       "251469               0                1         0         0              0   \n",
       "251470               1                0         0         0              1   \n",
       "251471               0                0         0         0              1   \n",
       "251472               1                0         0         0              0   \n",
       "\n",
       "        pos_rear right  pos_right  pos_undefined  state_New  state_Used  \n",
       "0                    0          0              0          1           0  \n",
       "1                    0          1              0          1           0  \n",
       "2                    0          0              0          1           0  \n",
       "3                    0          0              1          1           0  \n",
       "4                    0          0              0          1           0  \n",
       "...                ...        ...            ...        ...         ...  \n",
       "251468               1          0              0          1           0  \n",
       "251469               0          1              1          1           0  \n",
       "251470               0          0              0          1           0  \n",
       "251471               0          0              0          1           0  \n",
       "251472               0          0              0          1           0  \n",
       "\n",
       "[251473 rows x 52 columns]"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_df = df.copy()\n",
    "# Get dummies for parts regression dataframe \n",
    "deep_df = deep_df.join(deep_df['PartsList'].str.join('|').str.get_dummies().add_prefix('part_'))\n",
    "deep_df = deep_df.join(deep_df['PositionList'].str.join('|').str.get_dummies().add_prefix('pos_'))\n",
    "deep_df = deep_df.join(deep_df['PartStateList'].str.join('|').str.get_dummies().add_prefix('state_'))\n",
    "\n",
    "\n",
    "deep_df.head(1)\n",
    "# Remove unwanted columns from Regression Training\n",
    "unwanted_cols = ['c_id','RegistrationTime', 'CloseTime', 'Hour','Month', 'Day', 'WeekDay', 'PartsList', 'PositionList', 'PartStateList']\n",
    "\n",
    "unwanted_cols.append('AssessmentCost')\n",
    "unwanted_cols.append('SparePartCost')\n",
    "unwanted_cols.append('TotalCost')\n",
    "unwanted_cols.append('SparePart_Differace%')\n",
    "unwanted_cols.append('AssessmentEvaluation')\n",
    "\n",
    "unwanted_cols.append('TimeEvaluation')\n",
    "unwanted_cols.append('PartOfDay')\n",
    "unwanted_cols.append('DurationTime')\n",
    "\n",
    "unwanted_cols.append('CarColor')\n",
    "# unwanted_cols.append('CarClass')\n",
    "# unwanted_cols.append('CarType')\n",
    "# unwanted_cols.append('ManufactureYear')\n",
    "\n",
    "# unwanted_cols.append('PartsNumber')\n",
    "# unwanted_cols.append('PaymentType')\n",
    "\n",
    "# unwanted_cols.append('PartStateList')\n",
    "\n",
    "target = 'TotalCostEvaluation'\n",
    "\n",
    "deep_df.drop(unwanted_cols, axis=1, inplace=True)\n",
    "\n",
    "cat_cols = deep_df.describe(exclude='number').columns\n",
    "num_cols = deep_df.describe().columns\n",
    "\n",
    "\n",
    "deep_df[cat_cols]=deep_df[cat_cols].apply(LabelEncoder().fit_transform)\n",
    "deep_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ab_SFd3Lse5F"
   },
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(deep_df.drop(target, axis=1), deep_df[target],  train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build The Model and test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of fitting:24\n",
      "##################################################\n",
      "Initialize Model:0\n",
      "Epoch 1/100\n",
      "6287/6287 [==============================] - 6s 913us/step - loss: 1.5984 - accuracy: 0.4883 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 2/100\n",
      "6287/6287 [==============================] - 5s 856us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 3/100\n",
      "6287/6287 [==============================] - 5s 831us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 4/100\n",
      "6287/6287 [==============================] - 5s 836us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 5/100\n",
      "6287/6287 [==============================] - 5s 815us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 6/100\n",
      "6287/6287 [==============================] - 5s 823us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 7/100\n",
      "6287/6287 [==============================] - 5s 819us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 8/100\n",
      "6287/6287 [==============================] - 5s 836us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 9/100\n",
      "6287/6287 [==============================] - 5s 830us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 10/100\n",
      "6287/6287 [==============================] - 5s 849us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 11/100\n",
      "6287/6287 [==============================] - 5s 848us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 12/100\n",
      "6287/6287 [==============================] - 5s 836us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 13/100\n",
      "6287/6287 [==============================] - 5s 827us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 14/100\n",
      "6287/6287 [==============================] - 5s 841us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 15/100\n",
      "6287/6287 [==============================] - 5s 826us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 16/100\n",
      "6287/6287 [==============================] - 5s 838us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 17/100\n",
      "6287/6287 [==============================] - 5s 841us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 18/100\n",
      "6287/6287 [==============================] - 5s 847us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 19/100\n",
      "6287/6287 [==============================] - 5s 841us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 20/100\n",
      "6287/6287 [==============================] - 5s 851us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 21/100\n",
      "6287/6287 [==============================] - 5s 838us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 22/100\n",
      "6287/6287 [==============================] - 5s 825us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 23/100\n",
      "6287/6287 [==============================] - 5s 843us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 24/100\n",
      "6287/6287 [==============================] - 5s 862us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 25/100\n",
      "6287/6287 [==============================] - 5s 848us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 26/100\n",
      "6287/6287 [==============================] - 5s 847us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 27/100\n",
      "6287/6287 [==============================] - 5s 853us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 28/100\n",
      "6287/6287 [==============================] - 5s 819us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 29/100\n",
      "6287/6287 [==============================] - 5s 838us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 30/100\n",
      "6287/6287 [==============================] - 5s 848us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 31/100\n",
      "6287/6287 [==============================] - 5s 853us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 32/100\n",
      "6287/6287 [==============================] - 5s 849us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 33/100\n",
      "6287/6287 [==============================] - 5s 859us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 34/100\n",
      "6287/6287 [==============================] - 5s 846us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 35/100\n",
      "6287/6287 [==============================] - 5s 841us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 36/100\n",
      "6287/6287 [==============================] - 5s 844us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 37/100\n",
      "6287/6287 [==============================] - 5s 842us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 38/100\n",
      "6287/6287 [==============================] - 5s 835us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 39/100\n",
      "6287/6287 [==============================] - 5s 863us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 40/100\n",
      "6287/6287 [==============================] - 5s 837us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 41/100\n",
      "6287/6287 [==============================] - 5s 818us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 42/100\n",
      "6287/6287 [==============================] - 5s 853us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 43/100\n",
      "6287/6287 [==============================] - 5s 854us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 44/100\n",
      "6287/6287 [==============================] - 5s 863us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 45/100\n",
      "6287/6287 [==============================] - 5s 858us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 46/100\n",
      "6287/6287 [==============================] - 5s 868us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 47/100\n",
      "6287/6287 [==============================] - 5s 854us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 48/100\n",
      "6287/6287 [==============================] - 5s 844us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 49/100\n",
      "6287/6287 [==============================] - 5s 833us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 50/100\n",
      "6287/6287 [==============================] - 5s 801us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 51/100\n",
      "6287/6287 [==============================] - 5s 800us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 52/100\n",
      "6287/6287 [==============================] - 5s 839us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 53/100\n",
      "6287/6287 [==============================] - 5s 838us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 54/100\n",
      "6287/6287 [==============================] - 5s 862us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 55/100\n",
      "6287/6287 [==============================] - 5s 857us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 56/100\n",
      "6287/6287 [==============================] - 5s 843us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 57/100\n",
      "6287/6287 [==============================] - 5s 845us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 58/100\n",
      "6287/6287 [==============================] - 5s 854us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 59/100\n",
      "6287/6287 [==============================] - 5s 850us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 60/100\n",
      "6287/6287 [==============================] - 5s 855us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 61/100\n",
      "6287/6287 [==============================] - 5s 843us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 62/100\n",
      "6287/6287 [==============================] - 5s 845us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 63/100\n",
      "6287/6287 [==============================] - 5s 833us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 64/100\n",
      "6287/6287 [==============================] - 5s 818us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 65/100\n",
      "6287/6287 [==============================] - 5s 830us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 66/100\n",
      "6287/6287 [==============================] - 5s 855us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 67/100\n",
      "6287/6287 [==============================] - 5s 870us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 68/100\n",
      "6287/6287 [==============================] - 5s 838us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 69/100\n",
      "6287/6287 [==============================] - 5s 859us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 70/100\n",
      "6287/6287 [==============================] - 5s 851us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 71/100\n",
      "6287/6287 [==============================] - 5s 864us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 72/100\n",
      "6287/6287 [==============================] - 5s 854us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 73/100\n",
      "6287/6287 [==============================] - 5s 862us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 74/100\n",
      "6287/6287 [==============================] - 5s 842us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 75/100\n",
      "6287/6287 [==============================] - 5s 829us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 76/100\n",
      "6287/6287 [==============================] - 5s 834us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 77/100\n",
      "6287/6287 [==============================] - 5s 807us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 78/100\n",
      "6287/6287 [==============================] - 5s 839us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 79/100\n",
      "6287/6287 [==============================] - 5s 812us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 80/100\n",
      "6287/6287 [==============================] - 5s 863us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 81/100\n",
      "6287/6287 [==============================] - 5s 862us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 82/100\n",
      "6287/6287 [==============================] - 5s 845us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 83/100\n",
      "6287/6287 [==============================] - 5s 861us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 84/100\n",
      "6287/6287 [==============================] - 5s 830us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 85/100\n",
      "6287/6287 [==============================] - 5s 850us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 86/100\n",
      "6287/6287 [==============================] - 5s 824us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 87/100\n",
      "6287/6287 [==============================] - 5s 822us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 88/100\n",
      "6287/6287 [==============================] - 5s 842us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 89/100\n",
      "6287/6287 [==============================] - 5s 841us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 90/100\n",
      "6287/6287 [==============================] - 5s 865us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 91/100\n",
      "6287/6287 [==============================] - 5s 838us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 92/100\n",
      "6287/6287 [==============================] - 5s 819us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 93/100\n",
      "6287/6287 [==============================] - 5s 837us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 94/100\n",
      "6287/6287 [==============================] - 5s 846us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 95/100\n",
      "6287/6287 [==============================] - 5s 861us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 96/100\n",
      "6287/6287 [==============================] - 5s 834us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 97/100\n",
      "6287/6287 [==============================] - 5s 841us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 98/100\n",
      "6287/6287 [==============================] - 5s 826us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 99/100\n",
      "6287/6287 [==============================] - 5s 847us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 100/100\n",
      "6287/6287 [==============================] - 5s 838us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "==================================================\n",
      "End Model:0\n",
      "##################################################\n",
      "Initialize Model:1\n",
      "Epoch 1/100\n",
      "6287/6287 [==============================] - 6s 873us/step - loss: 1.4070 - accuracy: 0.5203 - val_loss: 0.8787 - val_accuracy: 0.5935\n",
      "Epoch 2/100\n",
      "6287/6287 [==============================] - 5s 847us/step - loss: 0.8480 - accuracy: 0.6205 - val_loss: 0.9214 - val_accuracy: 0.5813\n",
      "Epoch 3/100\n",
      "6287/6287 [==============================] - 5s 827us/step - loss: 0.8378 - accuracy: 0.6271 - val_loss: 0.8346 - val_accuracy: 0.6255\n",
      "Epoch 4/100\n",
      "6287/6287 [==============================] - 5s 832us/step - loss: 0.8293 - accuracy: 0.6299 - val_loss: 0.8309 - val_accuracy: 0.6246\n",
      "Epoch 5/100\n",
      "6287/6287 [==============================] - 5s 826us/step - loss: 0.8202 - accuracy: 0.6346 - val_loss: 0.7999 - val_accuracy: 0.6526\n",
      "Epoch 6/100\n",
      "6287/6287 [==============================] - 5s 803us/step - loss: 0.8146 - accuracy: 0.6380 - val_loss: 0.8362 - val_accuracy: 0.6328\n",
      "Epoch 7/100\n",
      "6287/6287 [==============================] - 5s 816us/step - loss: 0.8141 - accuracy: 0.6370 - val_loss: 0.8074 - val_accuracy: 0.6435\n",
      "Epoch 8/100\n",
      "6287/6287 [==============================] - 5s 838us/step - loss: 0.8108 - accuracy: 0.6391 - val_loss: 0.8154 - val_accuracy: 0.6476\n",
      "Epoch 9/100\n",
      "6287/6287 [==============================] - 5s 847us/step - loss: 0.8076 - accuracy: 0.6402 - val_loss: 0.7979 - val_accuracy: 0.6522\n",
      "Epoch 10/100\n",
      "6287/6287 [==============================] - 5s 833us/step - loss: 0.8067 - accuracy: 0.6413 - val_loss: 0.7999 - val_accuracy: 0.6513\n",
      "Epoch 11/100\n",
      "6287/6287 [==============================] - 5s 829us/step - loss: 0.8050 - accuracy: 0.6427 - val_loss: 0.7867 - val_accuracy: 0.6556\n",
      "Epoch 12/100\n",
      "6287/6287 [==============================] - 5s 837us/step - loss: 0.8031 - accuracy: 0.6445 - val_loss: 0.8069 - val_accuracy: 0.6438\n",
      "Epoch 13/100\n",
      "6287/6287 [==============================] - 5s 846us/step - loss: 0.8017 - accuracy: 0.6447 - val_loss: 0.7988 - val_accuracy: 0.6419\n",
      "Epoch 14/100\n",
      "6287/6287 [==============================] - 5s 844us/step - loss: 0.8008 - accuracy: 0.6446 - val_loss: 0.7855 - val_accuracy: 0.6589\n",
      "Epoch 15/100\n",
      "6287/6287 [==============================] - 5s 849us/step - loss: 0.7996 - accuracy: 0.6458 - val_loss: 0.7868 - val_accuracy: 0.6583\n",
      "Epoch 16/100\n",
      "6287/6287 [==============================] - 5s 847us/step - loss: 0.7969 - accuracy: 0.6474 - val_loss: 0.8311 - val_accuracy: 0.6406\n",
      "==================================================\n",
      "End Model:1\n",
      "##################################################\n",
      "Initialize Model:2\n",
      "Epoch 1/100\n",
      "6287/6287 [==============================] - 6s 827us/step - loss: 1.0674 - accuracy: 0.5687 - val_loss: 0.8367 - val_accuracy: 0.6315\n",
      "Epoch 2/100\n",
      "6287/6287 [==============================] - 5s 806us/step - loss: 0.8456 - accuracy: 0.6222 - val_loss: 0.8389 - val_accuracy: 0.6233\n",
      "Epoch 3/100\n",
      "6287/6287 [==============================] - 5s 807us/step - loss: 0.8359 - accuracy: 0.6280 - val_loss: 0.8291 - val_accuracy: 0.6360\n",
      "Epoch 4/100\n",
      "6287/6287 [==============================] - 5s 794us/step - loss: 0.8322 - accuracy: 0.6303 - val_loss: 0.8156 - val_accuracy: 0.6439\n",
      "Epoch 5/100\n",
      "6287/6287 [==============================] - 5s 793us/step - loss: 0.8306 - accuracy: 0.6308 - val_loss: 0.8148 - val_accuracy: 0.6384\n",
      "Epoch 6/100\n",
      "6287/6287 [==============================] - 5s 803us/step - loss: 0.8270 - accuracy: 0.6323 - val_loss: 0.8405 - val_accuracy: 0.6273\n",
      "Epoch 7/100\n",
      "6287/6287 [==============================] - 5s 797us/step - loss: 0.8259 - accuracy: 0.6321 - val_loss: 0.8222 - val_accuracy: 0.6353\n",
      "Epoch 8/100\n",
      "6287/6287 [==============================] - 5s 804us/step - loss: 0.8227 - accuracy: 0.6341 - val_loss: 0.8067 - val_accuracy: 0.6479\n",
      "Epoch 9/100\n",
      "6287/6287 [==============================] - 5s 811us/step - loss: 0.8228 - accuracy: 0.6332 - val_loss: 0.8272 - val_accuracy: 0.6323\n",
      "Epoch 10/100\n",
      "6287/6287 [==============================] - 5s 807us/step - loss: 0.8205 - accuracy: 0.6355 - val_loss: 0.8197 - val_accuracy: 0.6400\n",
      "Epoch 11/100\n",
      "6287/6287 [==============================] - 5s 811us/step - loss: 0.8188 - accuracy: 0.6353 - val_loss: 0.8411 - val_accuracy: 0.6211\n",
      "Epoch 12/100\n",
      "6287/6287 [==============================] - 5s 811us/step - loss: 0.8163 - accuracy: 0.6371 - val_loss: 0.8416 - val_accuracy: 0.6263\n",
      "Epoch 13/100\n",
      "6287/6287 [==============================] - 5s 825us/step - loss: 0.8132 - accuracy: 0.6379 - val_loss: 0.8006 - val_accuracy: 0.6478\n",
      "Epoch 14/100\n",
      "6287/6287 [==============================] - 5s 815us/step - loss: 0.8113 - accuracy: 0.6404 - val_loss: 0.7982 - val_accuracy: 0.6501\n",
      "Epoch 15/100\n",
      "6287/6287 [==============================] - 5s 819us/step - loss: 0.8100 - accuracy: 0.6401 - val_loss: 0.7959 - val_accuracy: 0.6526\n",
      "Epoch 16/100\n",
      "6287/6287 [==============================] - 5s 802us/step - loss: 0.8078 - accuracy: 0.6419 - val_loss: 0.8194 - val_accuracy: 0.6345\n",
      "Epoch 17/100\n",
      "6287/6287 [==============================] - 5s 793us/step - loss: 0.8055 - accuracy: 0.6432 - val_loss: 0.8263 - val_accuracy: 0.6363\n",
      "Epoch 18/100\n",
      "6287/6287 [==============================] - 5s 792us/step - loss: 0.8026 - accuracy: 0.6446 - val_loss: 0.8048 - val_accuracy: 0.6444\n",
      "Epoch 19/100\n",
      "6287/6287 [==============================] - 5s 783us/step - loss: 0.8020 - accuracy: 0.6441 - val_loss: 0.7943 - val_accuracy: 0.6521\n",
      "Epoch 20/100\n",
      "6287/6287 [==============================] - 5s 783us/step - loss: 0.7999 - accuracy: 0.6466 - val_loss: 0.8002 - val_accuracy: 0.6525\n",
      "Epoch 21/100\n",
      "6287/6287 [==============================] - 5s 795us/step - loss: 0.7990 - accuracy: 0.6465 - val_loss: 0.7868 - val_accuracy: 0.6549\n",
      "Epoch 22/100\n",
      "6287/6287 [==============================] - 5s 818us/step - loss: 0.7985 - accuracy: 0.6460 - val_loss: 0.7895 - val_accuracy: 0.6501\n",
      "Epoch 23/100\n",
      "6287/6287 [==============================] - 5s 819us/step - loss: 0.7983 - accuracy: 0.6474 - val_loss: 0.8009 - val_accuracy: 0.6440\n",
      "Epoch 24/100\n",
      "6287/6287 [==============================] - 5s 811us/step - loss: 0.7973 - accuracy: 0.6466 - val_loss: 0.7875 - val_accuracy: 0.6551\n",
      "Epoch 25/100\n",
      "6287/6287 [==============================] - 5s 817us/step - loss: 0.7973 - accuracy: 0.6471 - val_loss: 0.7838 - val_accuracy: 0.6579\n",
      "Epoch 26/100\n",
      "6287/6287 [==============================] - 5s 808us/step - loss: 0.7971 - accuracy: 0.6465 - val_loss: 0.8205 - val_accuracy: 0.6338\n",
      "Epoch 27/100\n",
      "6287/6287 [==============================] - 5s 809us/step - loss: 0.7972 - accuracy: 0.6473 - val_loss: 0.7848 - val_accuracy: 0.6550\n",
      "Epoch 28/100\n",
      "6287/6287 [==============================] - 5s 811us/step - loss: 0.7970 - accuracy: 0.6471 - val_loss: 0.7856 - val_accuracy: 0.6559\n",
      "Epoch 29/100\n",
      "6287/6287 [==============================] - 5s 799us/step - loss: 0.7959 - accuracy: 0.6480 - val_loss: 0.8015 - val_accuracy: 0.6499\n",
      "Epoch 30/100\n",
      "6287/6287 [==============================] - 5s 801us/step - loss: 0.7968 - accuracy: 0.6467 - val_loss: 0.7864 - val_accuracy: 0.6571\n",
      "Epoch 31/100\n",
      "6287/6287 [==============================] - 5s 800us/step - loss: 0.7956 - accuracy: 0.6470 - val_loss: 0.7865 - val_accuracy: 0.6568\n",
      "Epoch 32/100\n",
      "6287/6287 [==============================] - 5s 788us/step - loss: 0.7954 - accuracy: 0.6477 - val_loss: 0.8066 - val_accuracy: 0.6462\n",
      "Epoch 33/100\n",
      "6287/6287 [==============================] - 5s 798us/step - loss: 0.7957 - accuracy: 0.6476 - val_loss: 0.7836 - val_accuracy: 0.6586\n",
      "Epoch 34/100\n",
      "6287/6287 [==============================] - 5s 798us/step - loss: 0.7951 - accuracy: 0.6491 - val_loss: 0.7855 - val_accuracy: 0.6575\n",
      "Epoch 35/100\n",
      "6287/6287 [==============================] - 5s 814us/step - loss: 0.7950 - accuracy: 0.6486 - val_loss: 0.8084 - val_accuracy: 0.6355\n",
      "Epoch 36/100\n",
      "6287/6287 [==============================] - 5s 812us/step - loss: 0.7952 - accuracy: 0.6476 - val_loss: 0.7853 - val_accuracy: 0.6567\n",
      "Epoch 37/100\n",
      "6287/6287 [==============================] - 5s 813us/step - loss: 0.7942 - accuracy: 0.6491 - val_loss: 0.7839 - val_accuracy: 0.6572\n",
      "Epoch 38/100\n",
      "6287/6287 [==============================] - 5s 811us/step - loss: 0.7951 - accuracy: 0.6482 - val_loss: 0.7841 - val_accuracy: 0.6571\n",
      "Epoch 39/100\n",
      "6287/6287 [==============================] - 5s 810us/step - loss: 0.7944 - accuracy: 0.6487 - val_loss: 0.7876 - val_accuracy: 0.6542\n",
      "Epoch 40/100\n",
      "6287/6287 [==============================] - 5s 815us/step - loss: 0.7945 - accuracy: 0.6490 - val_loss: 0.7836 - val_accuracy: 0.6580\n",
      "Epoch 41/100\n",
      "6287/6287 [==============================] - 5s 809us/step - loss: 0.7941 - accuracy: 0.6480 - val_loss: 0.7969 - val_accuracy: 0.6460\n",
      "Epoch 42/100\n",
      "6287/6287 [==============================] - 5s 802us/step - loss: 0.7943 - accuracy: 0.6491 - val_loss: 0.7941 - val_accuracy: 0.6531\n",
      "Epoch 43/100\n",
      "6287/6287 [==============================] - 5s 804us/step - loss: 0.7942 - accuracy: 0.6497 - val_loss: 0.8020 - val_accuracy: 0.6471\n",
      "Epoch 44/100\n",
      "6287/6287 [==============================] - 5s 805us/step - loss: 0.7938 - accuracy: 0.6490 - val_loss: 0.7871 - val_accuracy: 0.6532\n",
      "Epoch 45/100\n",
      "6287/6287 [==============================] - 5s 811us/step - loss: 0.7936 - accuracy: 0.6487 - val_loss: 0.7847 - val_accuracy: 0.6575\n",
      "Epoch 46/100\n",
      "6287/6287 [==============================] - 5s 806us/step - loss: 0.7935 - accuracy: 0.6490 - val_loss: 0.7839 - val_accuracy: 0.6579\n",
      "Epoch 47/100\n",
      "6287/6287 [==============================] - 5s 809us/step - loss: 0.7941 - accuracy: 0.6486 - val_loss: 0.7861 - val_accuracy: 0.6582\n",
      "Epoch 48/100\n",
      "6287/6287 [==============================] - 5s 795us/step - loss: 0.7936 - accuracy: 0.6490 - val_loss: 0.7823 - val_accuracy: 0.6593\n",
      "Epoch 49/100\n",
      "6287/6287 [==============================] - 5s 791us/step - loss: 0.7937 - accuracy: 0.6493 - val_loss: 0.8003 - val_accuracy: 0.6458\n",
      "Epoch 50/100\n",
      "6287/6287 [==============================] - 5s 799us/step - loss: 0.7937 - accuracy: 0.6494 - val_loss: 0.7924 - val_accuracy: 0.6483\n",
      "Epoch 51/100\n",
      "6287/6287 [==============================] - 5s 820us/step - loss: 0.7937 - accuracy: 0.6498 - val_loss: 0.7852 - val_accuracy: 0.6552\n",
      "Epoch 52/100\n",
      "6287/6287 [==============================] - 5s 803us/step - loss: 0.7938 - accuracy: 0.6494 - val_loss: 0.7825 - val_accuracy: 0.6586\n",
      "Epoch 53/100\n",
      "6287/6287 [==============================] - 5s 787us/step - loss: 0.7931 - accuracy: 0.6491 - val_loss: 0.7840 - val_accuracy: 0.6576\n",
      "Epoch 54/100\n",
      "6287/6287 [==============================] - 5s 794us/step - loss: 0.7930 - accuracy: 0.6496 - val_loss: 0.7904 - val_accuracy: 0.6495\n",
      "Epoch 55/100\n",
      "6287/6287 [==============================] - 5s 806us/step - loss: 0.7925 - accuracy: 0.6501 - val_loss: 0.7828 - val_accuracy: 0.6581\n",
      "Epoch 56/100\n",
      "6287/6287 [==============================] - 5s 802us/step - loss: 0.7932 - accuracy: 0.6490 - val_loss: 0.7843 - val_accuracy: 0.6569\n",
      "Epoch 57/100\n",
      "6287/6287 [==============================] - 5s 805us/step - loss: 0.7933 - accuracy: 0.6500 - val_loss: 0.8142 - val_accuracy: 0.6338\n",
      "Epoch 58/100\n",
      "6287/6287 [==============================] - 5s 812us/step - loss: 0.7933 - accuracy: 0.6495 - val_loss: 0.7829 - val_accuracy: 0.6587\n",
      "Epoch 59/100\n",
      "6287/6287 [==============================] - 5s 801us/step - loss: 0.7928 - accuracy: 0.6504 - val_loss: 0.7851 - val_accuracy: 0.6552\n",
      "Epoch 60/100\n",
      "6287/6287 [==============================] - 5s 801us/step - loss: 0.7927 - accuracy: 0.6494 - val_loss: 0.7861 - val_accuracy: 0.6538\n",
      "Epoch 61/100\n",
      "6287/6287 [==============================] - 5s 805us/step - loss: 0.7927 - accuracy: 0.6506 - val_loss: 0.7849 - val_accuracy: 0.6546\n",
      "Epoch 62/100\n",
      "6287/6287 [==============================] - 5s 809us/step - loss: 0.7925 - accuracy: 0.6503 - val_loss: 0.7859 - val_accuracy: 0.6574\n",
      "Epoch 63/100\n",
      "6287/6287 [==============================] - 5s 801us/step - loss: 0.7923 - accuracy: 0.6503 - val_loss: 0.7820 - val_accuracy: 0.6594\n",
      "Epoch 64/100\n",
      "6287/6287 [==============================] - 5s 802us/step - loss: 0.7923 - accuracy: 0.6499 - val_loss: 0.7988 - val_accuracy: 0.6430\n",
      "Epoch 65/100\n",
      "6287/6287 [==============================] - 5s 794us/step - loss: 0.7922 - accuracy: 0.6502 - val_loss: 0.7864 - val_accuracy: 0.6548\n",
      "Epoch 66/100\n",
      "6287/6287 [==============================] - 5s 800us/step - loss: 0.7917 - accuracy: 0.6499 - val_loss: 0.7821 - val_accuracy: 0.6591\n",
      "Epoch 67/100\n",
      "6287/6287 [==============================] - 5s 803us/step - loss: 0.7917 - accuracy: 0.6500 - val_loss: 0.7976 - val_accuracy: 0.6481\n",
      "Epoch 68/100\n",
      "6287/6287 [==============================] - 5s 795us/step - loss: 0.7918 - accuracy: 0.6498 - val_loss: 0.7850 - val_accuracy: 0.6569\n",
      "Epoch 69/100\n",
      "6287/6287 [==============================] - 5s 788us/step - loss: 0.7915 - accuracy: 0.6503 - val_loss: 0.7877 - val_accuracy: 0.6569\n",
      "Epoch 70/100\n",
      "6287/6287 [==============================] - 5s 804us/step - loss: 0.7918 - accuracy: 0.6502 - val_loss: 0.7879 - val_accuracy: 0.6534\n",
      "Epoch 71/100\n",
      "6287/6287 [==============================] - 5s 815us/step - loss: 0.7918 - accuracy: 0.6513 - val_loss: 0.7860 - val_accuracy: 0.6578\n",
      "Epoch 72/100\n",
      "6287/6287 [==============================] - 5s 808us/step - loss: 0.7915 - accuracy: 0.6507 - val_loss: 0.7840 - val_accuracy: 0.6554\n",
      "Epoch 73/100\n",
      "6287/6287 [==============================] - 5s 809us/step - loss: 0.7913 - accuracy: 0.6511 - val_loss: 0.7835 - val_accuracy: 0.6572\n",
      "Epoch 74/100\n",
      "6287/6287 [==============================] - 5s 806us/step - loss: 0.7916 - accuracy: 0.6498 - val_loss: 0.7810 - val_accuracy: 0.6597\n",
      "Epoch 75/100\n",
      "6287/6287 [==============================] - 5s 807us/step - loss: 0.7916 - accuracy: 0.6507 - val_loss: 0.7925 - val_accuracy: 0.6468\n",
      "Epoch 76/100\n",
      "6287/6287 [==============================] - 5s 799us/step - loss: 0.7918 - accuracy: 0.6498 - val_loss: 0.7983 - val_accuracy: 0.6529\n",
      "Epoch 77/100\n",
      "6287/6287 [==============================] - 5s 818us/step - loss: 0.7918 - accuracy: 0.6501 - val_loss: 0.8200 - val_accuracy: 0.6411\n",
      "Epoch 78/100\n",
      "6287/6287 [==============================] - 5s 796us/step - loss: 0.7915 - accuracy: 0.6511 - val_loss: 0.7824 - val_accuracy: 0.6578\n",
      "Epoch 79/100\n",
      "6287/6287 [==============================] - 5s 791us/step - loss: 0.7917 - accuracy: 0.6513 - val_loss: 0.7815 - val_accuracy: 0.6583\n",
      "Epoch 80/100\n",
      "6287/6287 [==============================] - 5s 795us/step - loss: 0.7915 - accuracy: 0.6506 - val_loss: 0.7869 - val_accuracy: 0.6518\n",
      "Epoch 81/100\n",
      "6287/6287 [==============================] - 5s 802us/step - loss: 0.7911 - accuracy: 0.6510 - val_loss: 0.7876 - val_accuracy: 0.6569\n",
      "Epoch 82/100\n",
      "6287/6287 [==============================] - 5s 807us/step - loss: 0.7913 - accuracy: 0.6507 - val_loss: 0.7854 - val_accuracy: 0.6583\n",
      "Epoch 83/100\n",
      "6287/6287 [==============================] - 5s 818us/step - loss: 0.7909 - accuracy: 0.6512 - val_loss: 0.7814 - val_accuracy: 0.6597\n",
      "Epoch 84/100\n",
      "6287/6287 [==============================] - 5s 815us/step - loss: 0.7907 - accuracy: 0.6516 - val_loss: 0.7863 - val_accuracy: 0.6575\n",
      "Epoch 85/100\n",
      "6287/6287 [==============================] - 5s 813us/step - loss: 0.7910 - accuracy: 0.6512 - val_loss: 0.7877 - val_accuracy: 0.6584\n",
      "Epoch 86/100\n",
      "6287/6287 [==============================] - 5s 813us/step - loss: 0.7912 - accuracy: 0.6506 - val_loss: 0.7840 - val_accuracy: 0.6556\n",
      "Epoch 87/100\n",
      "6287/6287 [==============================] - 5s 826us/step - loss: 0.7909 - accuracy: 0.6516 - val_loss: 0.7916 - val_accuracy: 0.6559\n",
      "Epoch 88/100\n",
      "6287/6287 [==============================] - 5s 808us/step - loss: 0.7911 - accuracy: 0.6512 - val_loss: 0.7871 - val_accuracy: 0.6567\n",
      "Epoch 89/100\n",
      "6287/6287 [==============================] - 5s 816us/step - loss: 0.7909 - accuracy: 0.6510 - val_loss: 0.7848 - val_accuracy: 0.6605\n",
      "Epoch 90/100\n",
      "6287/6287 [==============================] - 5s 804us/step - loss: 0.7907 - accuracy: 0.6514 - val_loss: 0.7846 - val_accuracy: 0.6551\n",
      "Epoch 91/100\n",
      "6287/6287 [==============================] - 5s 810us/step - loss: 0.7900 - accuracy: 0.6521 - val_loss: 0.7824 - val_accuracy: 0.6575\n",
      "Epoch 92/100\n",
      "6287/6287 [==============================] - 5s 796us/step - loss: 0.7900 - accuracy: 0.6523 - val_loss: 0.7828 - val_accuracy: 0.6570\n",
      "Epoch 93/100\n",
      "6287/6287 [==============================] - 5s 787us/step - loss: 0.7905 - accuracy: 0.6506 - val_loss: 0.7831 - val_accuracy: 0.6560\n",
      "Epoch 94/100\n",
      "6287/6287 [==============================] - 5s 808us/step - loss: 0.7910 - accuracy: 0.6507 - val_loss: 0.7806 - val_accuracy: 0.6618\n",
      "Epoch 95/100\n",
      "6287/6287 [==============================] - 5s 804us/step - loss: 0.7909 - accuracy: 0.6509 - val_loss: 0.7880 - val_accuracy: 0.6497\n",
      "Epoch 96/100\n",
      "6287/6287 [==============================] - 5s 812us/step - loss: 0.7907 - accuracy: 0.6512 - val_loss: 0.7932 - val_accuracy: 0.6562\n",
      "Epoch 97/100\n",
      "6287/6287 [==============================] - 5s 817us/step - loss: 0.7906 - accuracy: 0.6506 - val_loss: 0.7827 - val_accuracy: 0.6583\n",
      "Epoch 98/100\n",
      "6287/6287 [==============================] - 5s 804us/step - loss: 0.7902 - accuracy: 0.6515 - val_loss: 0.7844 - val_accuracy: 0.6594\n",
      "Epoch 99/100\n",
      "6287/6287 [==============================] - 5s 815us/step - loss: 0.7904 - accuracy: 0.6511 - val_loss: 0.7822 - val_accuracy: 0.6602\n",
      "Epoch 100/100\n",
      "6287/6287 [==============================] - 5s 812us/step - loss: 0.7903 - accuracy: 0.6517 - val_loss: 0.7832 - val_accuracy: 0.6594\n",
      "==================================================\n",
      "End Model:2\n",
      "##################################################\n",
      "Initialize Model:3\n",
      "Epoch 1/100\n",
      "6287/6287 [==============================] - 6s 858us/step - loss: 1.6699 - accuracy: 0.5079 - val_loss: 1.2936 - val_accuracy: 0.4132\n",
      "Epoch 2/100\n",
      "6287/6287 [==============================] - 5s 838us/step - loss: 1.0591 - accuracy: 0.5543 - val_loss: 1.1569 - val_accuracy: 0.5048\n",
      "Epoch 3/100\n",
      "6287/6287 [==============================] - 5s 844us/step - loss: 0.9154 - accuracy: 0.5940 - val_loss: 0.8497 - val_accuracy: 0.6246\n",
      "Epoch 4/100\n",
      "6287/6287 [==============================] - 5s 846us/step - loss: 0.8902 - accuracy: 0.6032 - val_loss: 0.8082 - val_accuracy: 0.6444\n",
      "Epoch 5/100\n",
      "6287/6287 [==============================] - 5s 816us/step - loss: 0.8827 - accuracy: 0.6094 - val_loss: 0.8484 - val_accuracy: 0.6242\n",
      "Epoch 6/100\n",
      "6287/6287 [==============================] - 5s 815us/step - loss: 0.8698 - accuracy: 0.6130 - val_loss: 1.0785 - val_accuracy: 0.5306\n",
      "==================================================\n",
      "End Model:3\n",
      "##################################################\n",
      "Initialize Model:4\n",
      "Epoch 1/100\n",
      "6287/6287 [==============================] - 6s 876us/step - loss: 2.0621 - accuracy: 0.4447 - val_loss: 1.2003 - val_accuracy: 0.4916\n",
      "Epoch 2/100\n",
      "6287/6287 [==============================] - 6s 882us/step - loss: 1.1480 - accuracy: 0.4965 - val_loss: 0.9295 - val_accuracy: 0.6126\n",
      "Epoch 3/100\n",
      "6287/6287 [==============================] - 5s 868us/step - loss: 0.8992 - accuracy: 0.6033 - val_loss: 0.8212 - val_accuracy: 0.6408\n",
      "Epoch 4/100\n",
      "6287/6287 [==============================] - 6s 900us/step - loss: 0.8406 - accuracy: 0.6238 - val_loss: 0.8154 - val_accuracy: 0.6344\n",
      "Epoch 5/100\n",
      "6287/6287 [==============================] - 6s 885us/step - loss: 0.8258 - accuracy: 0.6296 - val_loss: 0.9016 - val_accuracy: 0.5830\n",
      "==================================================\n",
      "End Model:4\n",
      "##################################################\n",
      "Initialize Model:5\n",
      "Epoch 1/100\n",
      "6287/6287 [==============================] - 6s 878us/step - loss: 1.8519 - accuracy: 0.4860 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 2/100\n",
      "6287/6287 [==============================] - 6s 880us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 3/100\n",
      "6287/6287 [==============================] - 5s 861us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 4/100\n",
      "6287/6287 [==============================] - 5s 869us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 5/100\n",
      "6287/6287 [==============================] - 5s 860us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 6/100\n",
      "6287/6287 [==============================] - 5s 848us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1851 - val_accuracy: 0.4917\n",
      "Epoch 7/100\n",
      "6287/6287 [==============================] - 5s 866us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 8/100\n",
      "6287/6287 [==============================] - 5s 864us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 9/100\n",
      "6287/6287 [==============================] - 5s 866us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 10/100\n",
      "6287/6287 [==============================] - 5s 862us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 11/100\n",
      "6287/6287 [==============================] - 5s 860us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 12/100\n",
      "6287/6287 [==============================] - 5s 862us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 13/100\n",
      "6287/6287 [==============================] - 6s 890us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 14/100\n",
      "6287/6287 [==============================] - 5s 872us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 15/100\n",
      "6287/6287 [==============================] - 5s 873us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 16/100\n",
      "6287/6287 [==============================] - 5s 859us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 17/100\n",
      "6287/6287 [==============================] - 5s 866us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 18/100\n",
      "6287/6287 [==============================] - 5s 864us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 19/100\n",
      "6287/6287 [==============================] - 5s 874us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 20/100\n",
      "6287/6287 [==============================] - 5s 874us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 21/100\n",
      "6287/6287 [==============================] - 6s 889us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 22/100\n",
      "6287/6287 [==============================] - 5s 859us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 23/100\n",
      "6287/6287 [==============================] - 5s 869us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 24/100\n",
      "6287/6287 [==============================] - 5s 854us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 25/100\n",
      "6287/6287 [==============================] - 5s 851us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 26/100\n",
      "6287/6287 [==============================] - 6s 877us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 27/100\n",
      "6287/6287 [==============================] - 5s 872us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 28/100\n",
      "6287/6287 [==============================] - 5s 874us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 29/100\n",
      "6287/6287 [==============================] - 5s 873us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 30/100\n",
      "6287/6287 [==============================] - 5s 869us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 31/100\n",
      "6287/6287 [==============================] - 6s 876us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 32/100\n",
      "6287/6287 [==============================] - 6s 886us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 33/100\n",
      "6287/6287 [==============================] - 5s 871us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 34/100\n",
      "6287/6287 [==============================] - 6s 877us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 35/100\n",
      "6287/6287 [==============================] - 6s 876us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 36/100\n",
      "6287/6287 [==============================] - 5s 863us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 37/100\n",
      "6287/6287 [==============================] - 6s 875us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 38/100\n",
      "6287/6287 [==============================] - 5s 849us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 39/100\n",
      "6287/6287 [==============================] - 5s 857us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 40/100\n",
      "6287/6287 [==============================] - 5s 863us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 41/100\n",
      "6287/6287 [==============================] - 5s 873us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 42/100\n",
      "6287/6287 [==============================] - 5s 868us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 43/100\n",
      "6287/6287 [==============================] - 6s 881us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 44/100\n",
      "6287/6287 [==============================] - 6s 878us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 45/100\n",
      "6287/6287 [==============================] - 5s 870us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 46/100\n",
      "6287/6287 [==============================] - 5s 870us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 47/100\n",
      "6287/6287 [==============================] - 6s 886us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 48/100\n",
      "6287/6287 [==============================] - 6s 886us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 49/100\n",
      "6287/6287 [==============================] - 6s 879us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 50/100\n",
      "6287/6287 [==============================] - 5s 854us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1849 - val_accuracy: 0.4917\n",
      "Epoch 51/100\n",
      "6287/6287 [==============================] - 5s 860us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 52/100\n",
      "6287/6287 [==============================] - 5s 838us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 53/100\n",
      "6287/6287 [==============================] - 5s 824us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 54/100\n",
      "6287/6287 [==============================] - 5s 853us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 55/100\n",
      "6287/6287 [==============================] - 6s 885us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 56/100\n",
      "6287/6287 [==============================] - 6s 875us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 57/100\n",
      "6287/6287 [==============================] - 6s 881us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 58/100\n",
      "6287/6287 [==============================] - 6s 885us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 59/100\n",
      "6287/6287 [==============================] - 6s 876us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 60/100\n",
      "6287/6287 [==============================] - 6s 875us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 61/100\n",
      "6287/6287 [==============================] - 5s 871us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 62/100\n",
      "6287/6287 [==============================] - 5s 862us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 63/100\n",
      "6287/6287 [==============================] - 5s 869us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 64/100\n",
      "6287/6287 [==============================] - 5s 853us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 65/100\n",
      "6287/6287 [==============================] - 5s 851us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 66/100\n",
      "6287/6287 [==============================] - 5s 864us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 67/100\n",
      "6287/6287 [==============================] - 5s 863us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 68/100\n",
      "6287/6287 [==============================] - 5s 867us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 69/100\n",
      "6287/6287 [==============================] - 6s 884us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 70/100\n",
      "6287/6287 [==============================] - 6s 883us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 71/100\n",
      "6287/6287 [==============================] - 5s 870us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 72/100\n",
      "6287/6287 [==============================] - 5s 871us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 73/100\n",
      "6287/6287 [==============================] - 6s 883us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 74/100\n",
      "6287/6287 [==============================] - 6s 877us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 75/100\n",
      "6287/6287 [==============================] - 6s 875us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 76/100\n",
      "6287/6287 [==============================] - 5s 863us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 77/100\n",
      "6287/6287 [==============================] - 5s 873us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 78/100\n",
      "6287/6287 [==============================] - 5s 866us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 79/100\n",
      "6287/6287 [==============================] - 5s 874us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 80/100\n",
      "6287/6287 [==============================] - 5s 851us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 81/100\n",
      "6287/6287 [==============================] - 5s 860us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 82/100\n",
      "6287/6287 [==============================] - 5s 865us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 83/100\n",
      "6287/6287 [==============================] - 6s 885us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 84/100\n",
      "6287/6287 [==============================] - 6s 877us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 85/100\n",
      "6287/6287 [==============================] - 5s 865us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 86/100\n",
      "6287/6287 [==============================] - 6s 880us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 87/100\n",
      "6287/6287 [==============================] - 5s 872us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 88/100\n",
      "6287/6287 [==============================] - 5s 866us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 89/100\n",
      "6287/6287 [==============================] - 6s 878us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 90/100\n",
      "6287/6287 [==============================] - 5s 873us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 91/100\n",
      "6287/6287 [==============================] - 5s 873us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 92/100\n",
      "6287/6287 [==============================] - 5s 869us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 93/100\n",
      "6287/6287 [==============================] - 5s 871us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 94/100\n",
      "6287/6287 [==============================] - 5s 872us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 95/100\n",
      "6287/6287 [==============================] - 5s 865us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 96/100\n",
      "6287/6287 [==============================] - 5s 863us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 97/100\n",
      "6287/6287 [==============================] - 5s 874us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 98/100\n",
      "6287/6287 [==============================] - 5s 864us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 99/100\n",
      "6287/6287 [==============================] - 5s 856us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 100/100\n",
      "6287/6287 [==============================] - 5s 859us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "==================================================\n",
      "End Model:5\n",
      "##################################################\n",
      "Initialize Model:6\n",
      "Epoch 1/100\n",
      "6287/6287 [==============================] - 6s 882us/step - loss: 1.3364 - accuracy: 0.5620 - val_loss: 0.8697 - val_accuracy: 0.6028\n",
      "Epoch 2/100\n",
      "6287/6287 [==============================] - 5s 838us/step - loss: 0.8536 - accuracy: 0.6164 - val_loss: 0.8186 - val_accuracy: 0.6396\n",
      "Epoch 3/100\n",
      "6287/6287 [==============================] - 5s 842us/step - loss: 0.8374 - accuracy: 0.6248 - val_loss: 0.8059 - val_accuracy: 0.6454\n",
      "Epoch 4/100\n",
      "6287/6287 [==============================] - 5s 865us/step - loss: 0.8237 - accuracy: 0.6338 - val_loss: 0.8017 - val_accuracy: 0.6478\n",
      "Epoch 5/100\n",
      "6287/6287 [==============================] - 6s 878us/step - loss: 0.8166 - accuracy: 0.6369 - val_loss: 0.7931 - val_accuracy: 0.6559\n",
      "Epoch 6/100\n",
      "6287/6287 [==============================] - 5s 824us/step - loss: 0.8131 - accuracy: 0.6392 - val_loss: 0.8000 - val_accuracy: 0.6433\n",
      "Epoch 7/100\n",
      "6287/6287 [==============================] - 5s 831us/step - loss: 0.8086 - accuracy: 0.6409 - val_loss: 0.8492 - val_accuracy: 0.6257\n",
      "==================================================\n",
      "End Model:6\n",
      "##################################################\n",
      "Initialize Model:7\n",
      "Epoch 1/100\n",
      "6287/6287 [==============================] - 6s 865us/step - loss: 1.2852 - accuracy: 0.5526 - val_loss: 0.8253 - val_accuracy: 0.6372\n",
      "Epoch 2/100\n",
      "6287/6287 [==============================] - 5s 840us/step - loss: 0.8410 - accuracy: 0.6244 - val_loss: 0.8586 - val_accuracy: 0.6160\n",
      "Epoch 3/100\n",
      "6287/6287 [==============================] - 5s 855us/step - loss: 0.8341 - accuracy: 0.6293 - val_loss: 0.8303 - val_accuracy: 0.6359\n",
      "Epoch 4/100\n",
      "6287/6287 [==============================] - 5s 873us/step - loss: 0.8304 - accuracy: 0.6312 - val_loss: 0.8725 - val_accuracy: 0.6117\n",
      "==================================================\n",
      "End Model:7\n",
      "##################################################\n",
      "Initialize Model:8\n",
      "Epoch 1/100\n",
      "6287/6287 [==============================] - 6s 931us/step - loss: 1.2392 - accuracy: 0.4904 - val_loss: 1.1817 - val_accuracy: 0.4917\n",
      "Epoch 2/100\n",
      "6287/6287 [==============================] - 6s 908us/step - loss: 0.9099 - accuracy: 0.5938 - val_loss: 0.8218 - val_accuracy: 0.6418\n",
      "Epoch 3/100\n",
      "6287/6287 [==============================] - 6s 913us/step - loss: 0.8364 - accuracy: 0.6274 - val_loss: 0.8136 - val_accuracy: 0.6406\n",
      "Epoch 4/100\n",
      "6287/6287 [==============================] - 6s 892us/step - loss: 0.8303 - accuracy: 0.6302 - val_loss: 0.8244 - val_accuracy: 0.6401\n",
      "Epoch 5/100\n",
      "6287/6287 [==============================] - 6s 906us/step - loss: 0.8285 - accuracy: 0.6311 - val_loss: 0.8762 - val_accuracy: 0.5991\n",
      "==================================================\n",
      "End Model:8\n",
      "##################################################\n",
      "Initialize Model:9\n",
      "Epoch 1/100\n",
      "6287/6287 [==============================] - 6s 915us/step - loss: 1.3012 - accuracy: 0.5534 - val_loss: 0.8597 - val_accuracy: 0.6156\n",
      "Epoch 2/100\n",
      "6287/6287 [==============================] - 6s 907us/step - loss: 0.8477 - accuracy: 0.6232 - val_loss: 0.8248 - val_accuracy: 0.6363\n",
      "Epoch 3/100\n",
      "6287/6287 [==============================] - 6s 881us/step - loss: 0.8369 - accuracy: 0.6281 - val_loss: 0.8990 - val_accuracy: 0.5970\n",
      "==================================================\n",
      "End Model:9\n",
      "##################################################\n",
      "Initialize Model:10\n",
      "Epoch 1/100\n",
      "6287/6287 [==============================] - 6s 866us/step - loss: 6.1012 - accuracy: 0.4771 - val_loss: 1.1828 - val_accuracy: 0.4917\n",
      "Epoch 2/100\n",
      "6287/6287 [==============================] - 5s 849us/step - loss: 1.1808 - accuracy: 0.4917 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 3/100\n",
      "6287/6287 [==============================] - 5s 840us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 4/100\n",
      "6287/6287 [==============================] - 5s 842us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 5/100\n",
      "6287/6287 [==============================] - 5s 860us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 6/100\n",
      "6287/6287 [==============================] - 5s 864us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1849 - val_accuracy: 0.4917\n",
      "Epoch 7/100\n",
      "6287/6287 [==============================] - 5s 859us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 8/100\n",
      "6287/6287 [==============================] - 5s 853us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 9/100\n",
      "6287/6287 [==============================] - 5s 856us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 10/100\n",
      "6287/6287 [==============================] - 6s 889us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1849 - val_accuracy: 0.4917\n",
      "Epoch 11/100\n",
      "6287/6287 [==============================] - 5s 868us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 12/100\n",
      "6287/6287 [==============================] - 5s 861us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 13/100\n",
      "6287/6287 [==============================] - 5s 855us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 14/100\n",
      "6287/6287 [==============================] - 5s 858us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 15/100\n",
      "6287/6287 [==============================] - 5s 848us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 16/100\n",
      "6287/6287 [==============================] - 5s 859us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 17/100\n",
      "6287/6287 [==============================] - 5s 848us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 18/100\n",
      "6287/6287 [==============================] - 5s 838us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 19/100\n",
      "6287/6287 [==============================] - 5s 865us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 20/100\n",
      "6287/6287 [==============================] - 5s 858us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 21/100\n",
      "6287/6287 [==============================] - 5s 865us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 22/100\n",
      "6287/6287 [==============================] - 5s 861us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 23/100\n",
      "6287/6287 [==============================] - 5s 870us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 24/100\n",
      "6287/6287 [==============================] - 5s 855us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 25/100\n",
      "6287/6287 [==============================] - 5s 845us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 26/100\n",
      "6287/6287 [==============================] - 5s 845us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1849 - val_accuracy: 0.4917\n",
      "Epoch 27/100\n",
      "6287/6287 [==============================] - 5s 843us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 28/100\n",
      "6287/6287 [==============================] - 5s 839us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 29/100\n",
      "6287/6287 [==============================] - 5s 855us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 30/100\n",
      "6287/6287 [==============================] - 5s 862us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 31/100\n",
      "6287/6287 [==============================] - 5s 854us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 32/100\n",
      "6287/6287 [==============================] - 5s 861us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 33/100\n",
      "6287/6287 [==============================] - 5s 863us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 34/100\n",
      "6287/6287 [==============================] - 5s 857us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 35/100\n",
      "6287/6287 [==============================] - 5s 858us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 36/100\n",
      "6287/6287 [==============================] - 5s 843us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 37/100\n",
      "6287/6287 [==============================] - 5s 851us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 38/100\n",
      "6287/6287 [==============================] - 5s 857us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 39/100\n",
      "6287/6287 [==============================] - 5s 850us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 40/100\n",
      "6287/6287 [==============================] - 5s 848us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 41/100\n",
      "6287/6287 [==============================] - 5s 864us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 42/100\n",
      "6287/6287 [==============================] - 5s 864us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 43/100\n",
      "6287/6287 [==============================] - 5s 857us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 44/100\n",
      "6287/6287 [==============================] - 5s 846us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 45/100\n",
      "6287/6287 [==============================] - 5s 852us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 46/100\n",
      "6287/6287 [==============================] - 5s 838us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 47/100\n",
      "6287/6287 [==============================] - 5s 846us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 48/100\n",
      "6287/6287 [==============================] - 5s 859us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 49/100\n",
      "6287/6287 [==============================] - 5s 860us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 50/100\n",
      "6287/6287 [==============================] - 5s 852us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 51/100\n",
      "6287/6287 [==============================] - 5s 848us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 52/100\n",
      "6287/6287 [==============================] - 5s 859us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 53/100\n",
      "6287/6287 [==============================] - 5s 862us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 54/100\n",
      "6287/6287 [==============================] - 5s 874us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 55/100\n",
      "6287/6287 [==============================] - 5s 866us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 56/100\n",
      "6287/6287 [==============================] - 5s 866us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 57/100\n",
      "6287/6287 [==============================] - 5s 856us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 58/100\n",
      "6287/6287 [==============================] - 5s 854us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 59/100\n",
      "6287/6287 [==============================] - 5s 852us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 60/100\n",
      "6287/6287 [==============================] - 5s 856us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 61/100\n",
      "6287/6287 [==============================] - 5s 848us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 62/100\n",
      "6287/6287 [==============================] - 5s 848us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 63/100\n",
      "6287/6287 [==============================] - 5s 862us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 64/100\n",
      "6287/6287 [==============================] - 5s 862us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 65/100\n",
      "6287/6287 [==============================] - 5s 858us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 66/100\n",
      "6287/6287 [==============================] - 5s 860us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 67/100\n",
      "6287/6287 [==============================] - 6s 879us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 68/100\n",
      "6287/6287 [==============================] - 5s 871us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 69/100\n",
      "6287/6287 [==============================] - 5s 871us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 70/100\n",
      "6287/6287 [==============================] - 5s 873us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 71/100\n",
      "6287/6287 [==============================] - 5s 870us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 72/100\n",
      "6287/6287 [==============================] - 5s 855us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 73/100\n",
      "6287/6287 [==============================] - 5s 855us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 74/100\n",
      "6287/6287 [==============================] - 5s 830us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 75/100\n",
      "6287/6287 [==============================] - 5s 839us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 76/100\n",
      "6287/6287 [==============================] - 5s 845us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 77/100\n",
      "6287/6287 [==============================] - 5s 871us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 78/100\n",
      "6287/6287 [==============================] - 6s 876us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 79/100\n",
      "6287/6287 [==============================] - 5s 866us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 80/100\n",
      "6287/6287 [==============================] - 5s 871us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 81/100\n",
      "6287/6287 [==============================] - 5s 869us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 82/100\n",
      "6287/6287 [==============================] - 5s 872us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 83/100\n",
      "6287/6287 [==============================] - 5s 870us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 84/100\n",
      "6287/6287 [==============================] - 5s 858us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 85/100\n",
      "6287/6287 [==============================] - 5s 874us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 86/100\n",
      "6287/6287 [==============================] - 5s 847us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 87/100\n",
      "6287/6287 [==============================] - 5s 853us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 88/100\n",
      "6287/6287 [==============================] - 5s 862us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 89/100\n",
      "6287/6287 [==============================] - 5s 859us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 90/100\n",
      "6287/6287 [==============================] - 5s 866us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 91/100\n",
      "6287/6287 [==============================] - 5s 875us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 92/100\n",
      "6287/6287 [==============================] - 6s 879us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 93/100\n",
      "6287/6287 [==============================] - 5s 868us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 94/100\n",
      "6287/6287 [==============================] - 5s 872us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 95/100\n",
      "6287/6287 [==============================] - 5s 862us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 96/100\n",
      "6287/6287 [==============================] - 5s 871us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 97/100\n",
      "6287/6287 [==============================] - 5s 861us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 98/100\n",
      "6287/6287 [==============================] - 5s 869us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 99/100\n",
      "6287/6287 [==============================] - 5s 859us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 100/100\n",
      "6287/6287 [==============================] - 5s 869us/step - loss: 1.1812 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "==================================================\n",
      "End Model:10\n",
      "##################################################\n",
      "Initialize Model:11\n",
      "Epoch 1/100\n",
      "6287/6287 [==============================] - 6s 901us/step - loss: 1.4301 - accuracy: 0.5536 - val_loss: 0.8834 - val_accuracy: 0.5996\n",
      "Epoch 2/100\n",
      "6287/6287 [==============================] - 6s 912us/step - loss: 0.8570 - accuracy: 0.6145 - val_loss: 0.8254 - val_accuracy: 0.6341\n",
      "Epoch 3/100\n",
      "6287/6287 [==============================] - 6s 876us/step - loss: 0.8406 - accuracy: 0.6225 - val_loss: 0.8318 - val_accuracy: 0.6343\n",
      "Epoch 4/100\n",
      "6287/6287 [==============================] - 6s 884us/step - loss: 0.8290 - accuracy: 0.6301 - val_loss: 0.8129 - val_accuracy: 0.6394\n",
      "Epoch 5/100\n",
      "6287/6287 [==============================] - 6s 907us/step - loss: 0.8236 - accuracy: 0.6334 - val_loss: 0.8174 - val_accuracy: 0.6387\n",
      "Epoch 6/100\n",
      "6287/6287 [==============================] - 6s 898us/step - loss: 0.8180 - accuracy: 0.6361 - val_loss: 0.7998 - val_accuracy: 0.6491\n",
      "Epoch 7/100\n",
      "6287/6287 [==============================] - 6s 900us/step - loss: 0.8126 - accuracy: 0.6391 - val_loss: 0.7918 - val_accuracy: 0.6515\n",
      "Epoch 8/100\n",
      "6287/6287 [==============================] - 6s 897us/step - loss: 0.8104 - accuracy: 0.6402 - val_loss: 0.8108 - val_accuracy: 0.6350\n",
      "Epoch 9/100\n",
      "6287/6287 [==============================] - 6s 890us/step - loss: 0.8080 - accuracy: 0.6419 - val_loss: 0.7989 - val_accuracy: 0.6505\n",
      "Epoch 10/100\n",
      "6287/6287 [==============================] - 6s 879us/step - loss: 0.8065 - accuracy: 0.6420 - val_loss: 0.7979 - val_accuracy: 0.6502\n",
      "Epoch 11/100\n",
      "6287/6287 [==============================] - 6s 896us/step - loss: 0.8059 - accuracy: 0.6419 - val_loss: 0.7912 - val_accuracy: 0.6537\n",
      "Epoch 12/100\n",
      "6287/6287 [==============================] - 6s 898us/step - loss: 0.8041 - accuracy: 0.6435 - val_loss: 0.7947 - val_accuracy: 0.6516\n",
      "Epoch 13/100\n",
      "6287/6287 [==============================] - 6s 901us/step - loss: 0.8010 - accuracy: 0.6439 - val_loss: 0.8037 - val_accuracy: 0.6405\n",
      "Epoch 14/100\n",
      "6287/6287 [==============================] - 6s 891us/step - loss: 0.7974 - accuracy: 0.6465 - val_loss: 0.7825 - val_accuracy: 0.6599\n",
      "Epoch 15/100\n",
      "6287/6287 [==============================] - 6s 886us/step - loss: 0.7973 - accuracy: 0.6463 - val_loss: 0.7838 - val_accuracy: 0.6534\n",
      "Epoch 16/100\n",
      "6287/6287 [==============================] - 6s 893us/step - loss: 0.7955 - accuracy: 0.6476 - val_loss: 0.7799 - val_accuracy: 0.6578\n",
      "Epoch 17/100\n",
      "6287/6287 [==============================] - 5s 869us/step - loss: 0.7942 - accuracy: 0.6483 - val_loss: 0.7836 - val_accuracy: 0.6593\n",
      "Epoch 18/100\n",
      "6287/6287 [==============================] - 6s 892us/step - loss: 0.7935 - accuracy: 0.6488 - val_loss: 0.7847 - val_accuracy: 0.6545\n",
      "Epoch 19/100\n",
      "6287/6287 [==============================] - 6s 906us/step - loss: 0.7938 - accuracy: 0.6492 - val_loss: 0.7850 - val_accuracy: 0.6553\n",
      "Epoch 20/100\n",
      "6287/6287 [==============================] - 6s 903us/step - loss: 0.7917 - accuracy: 0.6501 - val_loss: 0.7774 - val_accuracy: 0.6595\n",
      "Epoch 21/100\n",
      "6287/6287 [==============================] - 6s 880us/step - loss: 0.7909 - accuracy: 0.6500 - val_loss: 0.7839 - val_accuracy: 0.6569\n",
      "Epoch 22/100\n",
      "6287/6287 [==============================] - 6s 886us/step - loss: 0.7908 - accuracy: 0.6500 - val_loss: 0.7849 - val_accuracy: 0.6544\n",
      "Epoch 23/100\n",
      "6287/6287 [==============================] - 6s 905us/step - loss: 0.7906 - accuracy: 0.6500 - val_loss: 0.7907 - val_accuracy: 0.6515\n",
      "Epoch 24/100\n",
      "6287/6287 [==============================] - 6s 917us/step - loss: 0.7907 - accuracy: 0.6508 - val_loss: 0.7807 - val_accuracy: 0.6586\n",
      "Epoch 25/100\n",
      "6287/6287 [==============================] - 6s 907us/step - loss: 0.7889 - accuracy: 0.6507 - val_loss: 0.7771 - val_accuracy: 0.6584\n",
      "Epoch 26/100\n",
      "6287/6287 [==============================] - 6s 916us/step - loss: 0.7881 - accuracy: 0.6520 - val_loss: 0.7877 - val_accuracy: 0.6526\n",
      "Epoch 27/100\n",
      "6287/6287 [==============================] - 6s 909us/step - loss: 0.7882 - accuracy: 0.6514 - val_loss: 0.7860 - val_accuracy: 0.6514\n",
      "Epoch 28/100\n",
      "6287/6287 [==============================] - 6s 896us/step - loss: 0.7874 - accuracy: 0.6516 - val_loss: 0.7841 - val_accuracy: 0.6568\n",
      "Epoch 29/100\n",
      "6287/6287 [==============================] - 6s 885us/step - loss: 0.7862 - accuracy: 0.6523 - val_loss: 0.7855 - val_accuracy: 0.6540\n",
      "Epoch 30/100\n",
      "6287/6287 [==============================] - 6s 875us/step - loss: 0.7857 - accuracy: 0.6530 - val_loss: 0.7816 - val_accuracy: 0.6566\n",
      "Epoch 31/100\n",
      "6287/6287 [==============================] - 5s 872us/step - loss: 0.7858 - accuracy: 0.6526 - val_loss: 0.7787 - val_accuracy: 0.6596\n",
      "Epoch 32/100\n",
      "6287/6287 [==============================] - 5s 875us/step - loss: 0.7856 - accuracy: 0.6522 - val_loss: 0.7889 - val_accuracy: 0.6525\n",
      "Epoch 33/100\n",
      "6287/6287 [==============================] - 6s 899us/step - loss: 0.7849 - accuracy: 0.6532 - val_loss: 0.7948 - val_accuracy: 0.6462\n",
      "Epoch 34/100\n",
      "6287/6287 [==============================] - 6s 907us/step - loss: 0.7835 - accuracy: 0.6539 - val_loss: 0.7722 - val_accuracy: 0.6596\n",
      "Epoch 35/100\n",
      "6287/6287 [==============================] - 6s 908us/step - loss: 0.7824 - accuracy: 0.6540 - val_loss: 0.7877 - val_accuracy: 0.6498\n",
      "Epoch 36/100\n",
      "6287/6287 [==============================] - 6s 906us/step - loss: 0.7809 - accuracy: 0.6552 - val_loss: 0.7791 - val_accuracy: 0.6586\n",
      "Epoch 37/100\n",
      "6287/6287 [==============================] - 6s 905us/step - loss: 0.7807 - accuracy: 0.6551 - val_loss: 0.7752 - val_accuracy: 0.6594\n",
      "Epoch 38/100\n",
      "6287/6287 [==============================] - 6s 896us/step - loss: 0.7795 - accuracy: 0.6551 - val_loss: 0.7819 - val_accuracy: 0.6571\n",
      "Epoch 39/100\n",
      "6287/6287 [==============================] - 6s 907us/step - loss: 0.7786 - accuracy: 0.6559 - val_loss: 0.7812 - val_accuracy: 0.6560\n",
      "Epoch 40/100\n",
      "6287/6287 [==============================] - 6s 903us/step - loss: 0.7774 - accuracy: 0.6565 - val_loss: 0.7860 - val_accuracy: 0.6496\n",
      "Epoch 41/100\n",
      "6287/6287 [==============================] - 6s 899us/step - loss: 0.7767 - accuracy: 0.6563 - val_loss: 0.7711 - val_accuracy: 0.6642\n",
      "Epoch 42/100\n",
      "6287/6287 [==============================] - 6s 895us/step - loss: 0.7754 - accuracy: 0.6570 - val_loss: 0.7719 - val_accuracy: 0.6623\n",
      "Epoch 43/100\n",
      "6287/6287 [==============================] - 6s 881us/step - loss: 0.7745 - accuracy: 0.6586 - val_loss: 0.7848 - val_accuracy: 0.6523\n",
      "Epoch 44/100\n",
      "6287/6287 [==============================] - 6s 876us/step - loss: 0.7731 - accuracy: 0.6579 - val_loss: 0.7619 - val_accuracy: 0.6677\n",
      "Epoch 45/100\n",
      "6287/6287 [==============================] - 6s 877us/step - loss: 0.7719 - accuracy: 0.6594 - val_loss: 0.7746 - val_accuracy: 0.6577\n",
      "Epoch 46/100\n",
      "6287/6287 [==============================] - 6s 905us/step - loss: 0.7707 - accuracy: 0.6593 - val_loss: 0.7609 - val_accuracy: 0.6650\n",
      "Epoch 47/100\n",
      "6287/6287 [==============================] - 6s 912us/step - loss: 0.7710 - accuracy: 0.6596 - val_loss: 0.7791 - val_accuracy: 0.6566\n",
      "Epoch 48/100\n",
      "6287/6287 [==============================] - 6s 908us/step - loss: 0.7688 - accuracy: 0.6598 - val_loss: 0.7670 - val_accuracy: 0.6581\n",
      "Epoch 49/100\n",
      "6287/6287 [==============================] - 6s 899us/step - loss: 0.7689 - accuracy: 0.6602 - val_loss: 0.7559 - val_accuracy: 0.6668\n",
      "Epoch 50/100\n",
      "6287/6287 [==============================] - 6s 908us/step - loss: 0.7678 - accuracy: 0.6601 - val_loss: 0.7615 - val_accuracy: 0.6625\n",
      "Epoch 51/100\n",
      "6287/6287 [==============================] - 6s 909us/step - loss: 0.7671 - accuracy: 0.6607 - val_loss: 0.7565 - val_accuracy: 0.6675\n",
      "Epoch 52/100\n",
      "6287/6287 [==============================] - 6s 911us/step - loss: 0.7663 - accuracy: 0.6616 - val_loss: 0.7772 - val_accuracy: 0.6548\n",
      "Epoch 53/100\n",
      "6287/6287 [==============================] - 6s 903us/step - loss: 0.7665 - accuracy: 0.6610 - val_loss: 0.7582 - val_accuracy: 0.6661\n",
      "Epoch 54/100\n",
      "6287/6287 [==============================] - 6s 907us/step - loss: 0.7656 - accuracy: 0.6614 - val_loss: 0.7550 - val_accuracy: 0.6667\n",
      "Epoch 55/100\n",
      "6287/6287 [==============================] - 6s 891us/step - loss: 0.7647 - accuracy: 0.6619 - val_loss: 0.7599 - val_accuracy: 0.6654\n",
      "Epoch 56/100\n",
      "6287/6287 [==============================] - 6s 877us/step - loss: 0.7639 - accuracy: 0.6615 - val_loss: 0.7637 - val_accuracy: 0.6611\n",
      "Epoch 57/100\n",
      "6287/6287 [==============================] - 6s 880us/step - loss: 0.7632 - accuracy: 0.6636 - val_loss: 0.7715 - val_accuracy: 0.6598\n",
      "Epoch 58/100\n",
      "6287/6287 [==============================] - 6s 889us/step - loss: 0.7631 - accuracy: 0.6625 - val_loss: 0.7600 - val_accuracy: 0.6631\n",
      "Epoch 59/100\n",
      "6287/6287 [==============================] - 6s 888us/step - loss: 0.7627 - accuracy: 0.6630 - val_loss: 0.7658 - val_accuracy: 0.6657\n",
      "Epoch 60/100\n",
      "6287/6287 [==============================] - 6s 904us/step - loss: 0.7626 - accuracy: 0.6624 - val_loss: 0.7508 - val_accuracy: 0.6700\n",
      "Epoch 61/100\n",
      "6287/6287 [==============================] - 6s 907us/step - loss: 0.7626 - accuracy: 0.6630 - val_loss: 0.7561 - val_accuracy: 0.6683\n",
      "Epoch 62/100\n",
      "6287/6287 [==============================] - 6s 906us/step - loss: 0.7614 - accuracy: 0.6643 - val_loss: 0.7578 - val_accuracy: 0.6655\n",
      "Epoch 63/100\n",
      "6287/6287 [==============================] - 6s 899us/step - loss: 0.7612 - accuracy: 0.6630 - val_loss: 0.7548 - val_accuracy: 0.6681\n",
      "Epoch 64/100\n",
      "6287/6287 [==============================] - 6s 919us/step - loss: 0.7616 - accuracy: 0.6631 - val_loss: 0.7530 - val_accuracy: 0.6669\n",
      "Epoch 65/100\n",
      "6287/6287 [==============================] - 6s 903us/step - loss: 0.7609 - accuracy: 0.6637 - val_loss: 0.7639 - val_accuracy: 0.6605\n",
      "Epoch 66/100\n",
      "6287/6287 [==============================] - 6s 894us/step - loss: 0.7605 - accuracy: 0.6633 - val_loss: 0.7595 - val_accuracy: 0.6647\n",
      "Epoch 67/100\n",
      "6287/6287 [==============================] - 6s 885us/step - loss: 0.7595 - accuracy: 0.6646 - val_loss: 0.7497 - val_accuracy: 0.6701\n",
      "Epoch 68/100\n",
      "6287/6287 [==============================] - 6s 887us/step - loss: 0.7596 - accuracy: 0.6638 - val_loss: 0.7582 - val_accuracy: 0.6631\n",
      "Epoch 69/100\n",
      "6287/6287 [==============================] - 6s 893us/step - loss: 0.7595 - accuracy: 0.6640 - val_loss: 0.7520 - val_accuracy: 0.6678\n",
      "Epoch 70/100\n",
      "6287/6287 [==============================] - 6s 895us/step - loss: 0.7586 - accuracy: 0.6649 - val_loss: 0.7536 - val_accuracy: 0.6679\n",
      "Epoch 71/100\n",
      "6287/6287 [==============================] - 6s 888us/step - loss: 0.7596 - accuracy: 0.6641 - val_loss: 0.7501 - val_accuracy: 0.6693\n",
      "Epoch 72/100\n",
      "6287/6287 [==============================] - 6s 889us/step - loss: 0.7585 - accuracy: 0.6650 - val_loss: 0.7494 - val_accuracy: 0.6697\n",
      "Epoch 73/100\n",
      "6287/6287 [==============================] - 6s 891us/step - loss: 0.7577 - accuracy: 0.6649 - val_loss: 0.7470 - val_accuracy: 0.6720\n",
      "Epoch 74/100\n",
      "6287/6287 [==============================] - 6s 897us/step - loss: 0.7574 - accuracy: 0.6655 - val_loss: 0.7584 - val_accuracy: 0.6684\n",
      "Epoch 75/100\n",
      "6287/6287 [==============================] - 6s 901us/step - loss: 0.7577 - accuracy: 0.6651 - val_loss: 0.7513 - val_accuracy: 0.6692\n",
      "Epoch 76/100\n",
      "6287/6287 [==============================] - 6s 893us/step - loss: 0.7567 - accuracy: 0.6656 - val_loss: 0.7519 - val_accuracy: 0.6682\n",
      "Epoch 77/100\n",
      "6287/6287 [==============================] - 6s 894us/step - loss: 0.7573 - accuracy: 0.6652 - val_loss: 0.7533 - val_accuracy: 0.6701\n",
      "Epoch 78/100\n",
      "6287/6287 [==============================] - 6s 891us/step - loss: 0.7561 - accuracy: 0.6656 - val_loss: 0.7666 - val_accuracy: 0.6633\n",
      "Epoch 79/100\n",
      "6287/6287 [==============================] - 6s 892us/step - loss: 0.7558 - accuracy: 0.6669 - val_loss: 0.7730 - val_accuracy: 0.6577\n",
      "Epoch 80/100\n",
      "6287/6287 [==============================] - 6s 902us/step - loss: 0.7557 - accuracy: 0.6667 - val_loss: 0.7532 - val_accuracy: 0.6682\n",
      "Epoch 81/100\n",
      "6287/6287 [==============================] - 6s 909us/step - loss: 0.7546 - accuracy: 0.6666 - val_loss: 0.7486 - val_accuracy: 0.6705\n",
      "Epoch 82/100\n",
      "6287/6287 [==============================] - 6s 915us/step - loss: 0.7551 - accuracy: 0.6660 - val_loss: 0.7875 - val_accuracy: 0.6482\n",
      "==================================================\n",
      "End Model:11\n",
      "##################################################\n",
      "Initialize Model:12\n",
      "Epoch 1/100\n",
      "6287/6287 [==============================] - 6s 893us/step - loss: 1.1877 - accuracy: 0.4892 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 2/100\n",
      "6287/6287 [==============================] - 5s 866us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 3/100\n",
      "6287/6287 [==============================] - 5s 853us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 4/100\n",
      "6287/6287 [==============================] - 5s 863us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 5/100\n",
      "6287/6287 [==============================] - 5s 859us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 6/100\n",
      "6287/6287 [==============================] - 5s 874us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 7/100\n",
      "6287/6287 [==============================] - 5s 873us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 8/100\n",
      "6287/6287 [==============================] - 5s 870us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 9/100\n",
      "6287/6287 [==============================] - 5s 865us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 10/100\n",
      "6287/6287 [==============================] - 6s 875us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 11/100\n",
      "6287/6287 [==============================] - 5s 873us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 12/100\n",
      "6287/6287 [==============================] - 6s 877us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 13/100\n",
      "6287/6287 [==============================] - 5s 874us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 14/100\n",
      "6287/6287 [==============================] - 6s 876us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 15/100\n",
      "6287/6287 [==============================] - 5s 871us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1850 - val_accuracy: 0.4917\n",
      "Epoch 16/100\n",
      "6287/6287 [==============================] - 5s 867us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 17/100\n",
      "6287/6287 [==============================] - 5s 864us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 18/100\n",
      "6287/6287 [==============================] - 5s 848us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 19/100\n",
      "6287/6287 [==============================] - 5s 852us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 20/100\n",
      "6287/6287 [==============================] - 5s 860us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 21/100\n",
      "6287/6287 [==============================] - 5s 869us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 22/100\n",
      "6287/6287 [==============================] - 6s 875us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1849 - val_accuracy: 0.4917\n",
      "Epoch 23/100\n",
      "6287/6287 [==============================] - 6s 877us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 24/100\n",
      "6287/6287 [==============================] - 6s 875us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 25/100\n",
      "6287/6287 [==============================] - 6s 882us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 26/100\n",
      "6287/6287 [==============================] - 6s 882us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 27/100\n",
      "6287/6287 [==============================] - 6s 882us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1850 - val_accuracy: 0.4917\n",
      "Epoch 28/100\n",
      "6287/6287 [==============================] - 6s 886us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 29/100\n",
      "6287/6287 [==============================] - 5s 864us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 30/100\n",
      "6287/6287 [==============================] - 5s 857us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 31/100\n",
      "6287/6287 [==============================] - 5s 845us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 32/100\n",
      "6287/6287 [==============================] - 5s 827us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 33/100\n",
      "6287/6287 [==============================] - 5s 834us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 34/100\n",
      "6287/6287 [==============================] - 6s 876us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 35/100\n",
      "6287/6287 [==============================] - 6s 880us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 36/100\n",
      "6287/6287 [==============================] - 6s 885us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 37/100\n",
      "6287/6287 [==============================] - 6s 876us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 38/100\n",
      "6287/6287 [==============================] - 6s 883us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 39/100\n",
      "6287/6287 [==============================] - 5s 864us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 40/100\n",
      "6287/6287 [==============================] - 5s 870us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 41/100\n",
      "6287/6287 [==============================] - 5s 863us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 42/100\n",
      "6287/6287 [==============================] - 6s 877us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 43/100\n",
      "6287/6287 [==============================] - 5s 854us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 44/100\n",
      "6287/6287 [==============================] - 5s 849us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 45/100\n",
      "6287/6287 [==============================] - 5s 850us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 46/100\n",
      "6287/6287 [==============================] - 5s 858us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 47/100\n",
      "6287/6287 [==============================] - 5s 858us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 48/100\n",
      "6287/6287 [==============================] - 5s 864us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 49/100\n",
      "6287/6287 [==============================] - 6s 882us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 50/100\n",
      "6287/6287 [==============================] - 6s 898us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 51/100\n",
      "6287/6287 [==============================] - 5s 872us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1851 - val_accuracy: 0.4917\n",
      "Epoch 52/100\n",
      "6287/6287 [==============================] - 6s 882us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 53/100\n",
      "6287/6287 [==============================] - 5s 871us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 54/100\n",
      "6287/6287 [==============================] - 6s 877us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 55/100\n",
      "6287/6287 [==============================] - 5s 867us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 56/100\n",
      "6287/6287 [==============================] - 6s 876us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 57/100\n",
      "6287/6287 [==============================] - 5s 873us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 58/100\n",
      "6287/6287 [==============================] - 5s 863us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 59/100\n",
      "6287/6287 [==============================] - 5s 874us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 60/100\n",
      "6287/6287 [==============================] - 5s 857us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 61/100\n",
      "6287/6287 [==============================] - 5s 861us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 62/100\n",
      "6287/6287 [==============================] - 5s 870us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 63/100\n",
      "6287/6287 [==============================] - 6s 888us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 64/100\n",
      "6287/6287 [==============================] - 6s 881us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 65/100\n",
      "6287/6287 [==============================] - 6s 878us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1850 - val_accuracy: 0.4917\n",
      "Epoch 66/100\n",
      "6287/6287 [==============================] - 6s 889us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 67/100\n",
      "6287/6287 [==============================] - 5s 869us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 68/100\n",
      "6287/6287 [==============================] - 5s 865us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 69/100\n",
      "6287/6287 [==============================] - 5s 875us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 70/100\n",
      "6287/6287 [==============================] - 6s 883us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 71/100\n",
      "6287/6287 [==============================] - 6s 885us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 72/100\n",
      "6287/6287 [==============================] - 5s 867us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 73/100\n",
      "6287/6287 [==============================] - 5s 869us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 74/100\n",
      "6287/6287 [==============================] - 5s 867us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 75/100\n",
      "6287/6287 [==============================] - 5s 864us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 76/100\n",
      "6287/6287 [==============================] - 5s 864us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 77/100\n",
      "6287/6287 [==============================] - 6s 879us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 78/100\n",
      "6287/6287 [==============================] - 6s 876us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 79/100\n",
      "6287/6287 [==============================] - 5s 864us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 80/100\n",
      "6287/6287 [==============================] - 5s 857us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 81/100\n",
      "6287/6287 [==============================] - 6s 877us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 82/100\n",
      "6287/6287 [==============================] - 6s 880us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 83/100\n",
      "6287/6287 [==============================] - 6s 891us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 84/100\n",
      "6287/6287 [==============================] - 5s 875us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1849 - val_accuracy: 0.4917\n",
      "Epoch 85/100\n",
      "6287/6287 [==============================] - 6s 887us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 86/100\n",
      "6287/6287 [==============================] - 5s 872us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1849 - val_accuracy: 0.4917\n",
      "Epoch 87/100\n",
      "6287/6287 [==============================] - 5s 871us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 88/100\n",
      "6287/6287 [==============================] - 6s 901us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 89/100\n",
      "6287/6287 [==============================] - 5s 847us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 90/100\n",
      "6287/6287 [==============================] - 5s 847us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 91/100\n",
      "6287/6287 [==============================] - 5s 874us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 92/100\n",
      "6287/6287 [==============================] - 5s 873us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1849 - val_accuracy: 0.4917\n",
      "Epoch 93/100\n",
      "6287/6287 [==============================] - 6s 879us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 94/100\n",
      "6287/6287 [==============================] - 6s 883us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 95/100\n",
      "6287/6287 [==============================] - 6s 883us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 96/100\n",
      "6287/6287 [==============================] - 6s 887us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 97/100\n",
      "6287/6287 [==============================] - 6s 882us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 98/100\n",
      "6287/6287 [==============================] - 6s 876us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 99/100\n",
      "6287/6287 [==============================] - 6s 879us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 100/100\n",
      "6287/6287 [==============================] - 5s 867us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "==================================================\n",
      "End Model:12\n",
      "##################################################\n",
      "Initialize Model:13\n",
      "Epoch 1/100\n",
      "6287/6287 [==============================] - 6s 868us/step - loss: 1.1880 - accuracy: 0.4912 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 2/100\n",
      "6287/6287 [==============================] - 5s 849us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 3/100\n",
      "6287/6287 [==============================] - 5s 842us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 4/100\n",
      "6287/6287 [==============================] - 5s 839us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 5/100\n",
      "6287/6287 [==============================] - 5s 872us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 6/100\n",
      "6287/6287 [==============================] - 5s 873us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 7/100\n",
      "6287/6287 [==============================] - 5s 873us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 8/100\n",
      "6287/6287 [==============================] - 5s 864us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 9/100\n",
      "6287/6287 [==============================] - 5s 872us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 10/100\n",
      "6287/6287 [==============================] - 6s 879us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 11/100\n",
      "6287/6287 [==============================] - 6s 879us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 12/100\n",
      "6287/6287 [==============================] - 6s 879us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 13/100\n",
      "6287/6287 [==============================] - 5s 868us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 14/100\n",
      "6287/6287 [==============================] - 5s 872us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 15/100\n",
      "6287/6287 [==============================] - 5s 840us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 16/100\n",
      "6287/6287 [==============================] - 5s 854us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 17/100\n",
      "6287/6287 [==============================] - 5s 847us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 18/100\n",
      "6287/6287 [==============================] - 5s 857us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 19/100\n",
      "6287/6287 [==============================] - 5s 873us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 20/100\n",
      "6287/6287 [==============================] - 6s 878us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1850 - val_accuracy: 0.4917\n",
      "Epoch 21/100\n",
      "6287/6287 [==============================] - 6s 883us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 22/100\n",
      "6287/6287 [==============================] - 5s 871us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 23/100\n",
      "6287/6287 [==============================] - 6s 886us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 24/100\n",
      "6287/6287 [==============================] - 5s 873us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 25/100\n",
      "6287/6287 [==============================] - 6s 882us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 26/100\n",
      "6287/6287 [==============================] - 5s 855us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 27/100\n",
      "6287/6287 [==============================] - 5s 859us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 28/100\n",
      "6287/6287 [==============================] - 5s 853us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 29/100\n",
      "6287/6287 [==============================] - 5s 871us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1849 - val_accuracy: 0.4917\n",
      "Epoch 30/100\n",
      "6287/6287 [==============================] - 5s 866us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 31/100\n",
      "6287/6287 [==============================] - 5s 863us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 32/100\n",
      "6287/6287 [==============================] - 5s 858us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 33/100\n",
      "6287/6287 [==============================] - 5s 863us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 34/100\n",
      "6287/6287 [==============================] - 5s 870us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 35/100\n",
      "6287/6287 [==============================] - 5s 871us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1852 - val_accuracy: 0.4917\n",
      "Epoch 36/100\n",
      "6287/6287 [==============================] - 5s 874us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 37/100\n",
      "6287/6287 [==============================] - 5s 860us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 38/100\n",
      "6287/6287 [==============================] - 5s 867us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 39/100\n",
      "6287/6287 [==============================] - 5s 859us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1849 - val_accuracy: 0.4917\n",
      "Epoch 40/100\n",
      "6287/6287 [==============================] - 6s 875us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 41/100\n",
      "6287/6287 [==============================] - 6s 875us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 42/100\n",
      "6287/6287 [==============================] - 6s 885us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 43/100\n",
      "6287/6287 [==============================] - 5s 869us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 44/100\n",
      "6287/6287 [==============================] - 5s 859us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 45/100\n",
      "6287/6287 [==============================] - 5s 854us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 46/100\n",
      "6287/6287 [==============================] - 5s 841us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 47/100\n",
      "6287/6287 [==============================] - 5s 852us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 48/100\n",
      "6287/6287 [==============================] - 5s 861us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 49/100\n",
      "6287/6287 [==============================] - 5s 872us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 50/100\n",
      "6287/6287 [==============================] - 5s 873us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 51/100\n",
      "6287/6287 [==============================] - 5s 855us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 52/100\n",
      "6287/6287 [==============================] - 5s 873us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 53/100\n",
      "6287/6287 [==============================] - 5s 868us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 54/100\n",
      "6287/6287 [==============================] - 5s 863us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 55/100\n",
      "6287/6287 [==============================] - 5s 860us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 56/100\n",
      "6287/6287 [==============================] - 6s 877us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 57/100\n",
      "6287/6287 [==============================] - 5s 867us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 58/100\n",
      "6287/6287 [==============================] - 5s 862us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 59/100\n",
      "6287/6287 [==============================] - 5s 859us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 60/100\n",
      "6287/6287 [==============================] - 5s 857us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 61/100\n",
      "6287/6287 [==============================] - 5s 859us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 62/100\n",
      "6287/6287 [==============================] - 6s 879us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 63/100\n",
      "6287/6287 [==============================] - 5s 863us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 64/100\n",
      "6287/6287 [==============================] - 5s 868us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 65/100\n",
      "6287/6287 [==============================] - 5s 874us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 66/100\n",
      "6287/6287 [==============================] - 5s 872us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 67/100\n",
      "6287/6287 [==============================] - 6s 876us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 68/100\n",
      "6287/6287 [==============================] - 6s 877us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 69/100\n",
      "6287/6287 [==============================] - 5s 874us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 70/100\n",
      "6287/6287 [==============================] - 5s 868us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 71/100\n",
      "6287/6287 [==============================] - 6s 876us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 72/100\n",
      "6287/6287 [==============================] - 5s 860us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 73/100\n",
      "6287/6287 [==============================] - 5s 849us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 74/100\n",
      "6287/6287 [==============================] - 5s 845us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 75/100\n",
      "6287/6287 [==============================] - 5s 828us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 76/100\n",
      "6287/6287 [==============================] - 5s 832us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 77/100\n",
      "6287/6287 [==============================] - 6s 880us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 78/100\n",
      "6287/6287 [==============================] - 6s 886us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 79/100\n",
      "6287/6287 [==============================] - 5s 868us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 80/100\n",
      "6287/6287 [==============================] - 6s 888us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 81/100\n",
      "6287/6287 [==============================] - 6s 883us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1850 - val_accuracy: 0.4917\n",
      "Epoch 82/100\n",
      "6287/6287 [==============================] - 6s 880us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 83/100\n",
      "6287/6287 [==============================] - 6s 882us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1849 - val_accuracy: 0.4917\n",
      "Epoch 84/100\n",
      "6287/6287 [==============================] - 5s 867us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 85/100\n",
      "6287/6287 [==============================] - 5s 862us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 86/100\n",
      "6287/6287 [==============================] - 5s 854us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 87/100\n",
      "6287/6287 [==============================] - 5s 855us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 88/100\n",
      "6287/6287 [==============================] - 5s 864us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 89/100\n",
      "6287/6287 [==============================] - 5s 853us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 90/100\n",
      "6287/6287 [==============================] - 5s 857us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 91/100\n",
      "6287/6287 [==============================] - 6s 891us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 92/100\n",
      "6287/6287 [==============================] - 6s 882us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 93/100\n",
      "6287/6287 [==============================] - 5s 873us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 94/100\n",
      "6287/6287 [==============================] - 6s 878us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 95/100\n",
      "6287/6287 [==============================] - 6s 878us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 96/100\n",
      "6287/6287 [==============================] - 5s 868us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 97/100\n",
      "6287/6287 [==============================] - 6s 875us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 98/100\n",
      "6287/6287 [==============================] - 5s 866us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 99/100\n",
      "6287/6287 [==============================] - 5s 870us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 100/100\n",
      "6287/6287 [==============================] - 6s 879us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "==================================================\n",
      "End Model:13\n",
      "##################################################\n",
      "Initialize Model:14\n",
      "Epoch 1/100\n",
      "6287/6287 [==============================] - 6s 868us/step - loss: 1.1863 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 2/100\n",
      "6287/6287 [==============================] - 5s 849us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 3/100\n",
      "6287/6287 [==============================] - 5s 842us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 4/100\n",
      "6287/6287 [==============================] - 5s 841us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1851 - val_accuracy: 0.4917\n",
      "Epoch 5/100\n",
      "6287/6287 [==============================] - 5s 858us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 6/100\n",
      "6287/6287 [==============================] - 5s 868us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 7/100\n",
      "6287/6287 [==============================] - 5s 852us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 8/100\n",
      "6287/6287 [==============================] - 5s 849us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 9/100\n",
      "6287/6287 [==============================] - 5s 848us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 10/100\n",
      "6287/6287 [==============================] - 5s 847us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 11/100\n",
      "6287/6287 [==============================] - 5s 829us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 12/100\n",
      "6287/6287 [==============================] - 5s 854us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 13/100\n",
      "6287/6287 [==============================] - 5s 849us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 14/100\n",
      "6287/6287 [==============================] - 5s 849us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 15/100\n",
      "6287/6287 [==============================] - 5s 843us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 16/100\n",
      "6287/6287 [==============================] - 5s 841us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 17/100\n",
      "6287/6287 [==============================] - 5s 843us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 18/100\n",
      "6287/6287 [==============================] - 5s 841us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 19/100\n",
      "6287/6287 [==============================] - 5s 832us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 20/100\n",
      "6287/6287 [==============================] - 5s 845us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 21/100\n",
      "6287/6287 [==============================] - 5s 844us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 22/100\n",
      "6287/6287 [==============================] - 5s 835us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1850 - val_accuracy: 0.4917\n",
      "Epoch 23/100\n",
      "6287/6287 [==============================] - 5s 831us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 24/100\n",
      "6287/6287 [==============================] - 5s 833us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 25/100\n",
      "6287/6287 [==============================] - 5s 841us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 26/100\n",
      "6287/6287 [==============================] - 5s 851us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 27/100\n",
      "6287/6287 [==============================] - 5s 854us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 28/100\n",
      "6287/6287 [==============================] - 5s 852us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 29/100\n",
      "6287/6287 [==============================] - 5s 847us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 30/100\n",
      "6287/6287 [==============================] - 5s 850us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 31/100\n",
      "6287/6287 [==============================] - 5s 841us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 32/100\n",
      "6287/6287 [==============================] - 5s 820us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 33/100\n",
      "6287/6287 [==============================] - 5s 827us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 34/100\n",
      "6287/6287 [==============================] - 5s 825us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 35/100\n",
      "6287/6287 [==============================] - 5s 837us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 36/100\n",
      "6287/6287 [==============================] - 5s 857us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 37/100\n",
      "6287/6287 [==============================] - 5s 839us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 38/100\n",
      "6287/6287 [==============================] - 5s 841us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 39/100\n",
      "6287/6287 [==============================] - 5s 842us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 40/100\n",
      "6287/6287 [==============================] - 5s 850us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 41/100\n",
      "6287/6287 [==============================] - 5s 854us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 42/100\n",
      "6287/6287 [==============================] - 5s 859us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 43/100\n",
      "6287/6287 [==============================] - 5s 858us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 44/100\n",
      "6287/6287 [==============================] - 5s 844us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 45/100\n",
      "6287/6287 [==============================] - 5s 828us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 46/100\n",
      "6287/6287 [==============================] - 5s 836us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 47/100\n",
      "6287/6287 [==============================] - 5s 827us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 48/100\n",
      "6287/6287 [==============================] - 5s 818us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 49/100\n",
      "6287/6287 [==============================] - 5s 855us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 50/100\n",
      "6287/6287 [==============================] - 5s 855us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 51/100\n",
      "6287/6287 [==============================] - 5s 865us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 52/100\n",
      "6287/6287 [==============================] - 5s 857us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 53/100\n",
      "6287/6287 [==============================] - 5s 852us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 54/100\n",
      "6287/6287 [==============================] - 5s 855us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 55/100\n",
      "6287/6287 [==============================] - 5s 859us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 56/100\n",
      "6287/6287 [==============================] - 5s 853us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 57/100\n",
      "6287/6287 [==============================] - 5s 845us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 58/100\n",
      "6287/6287 [==============================] - 5s 850us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 59/100\n",
      "6287/6287 [==============================] - 5s 830us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 60/100\n",
      "6287/6287 [==============================] - 5s 830us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 61/100\n",
      "6287/6287 [==============================] - 5s 842us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 62/100\n",
      "6287/6287 [==============================] - 5s 845us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 63/100\n",
      "6287/6287 [==============================] - 5s 841us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 64/100\n",
      "6287/6287 [==============================] - 5s 863us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 65/100\n",
      "6287/6287 [==============================] - 5s 861us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 66/100\n",
      "6287/6287 [==============================] - 6s 876us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 67/100\n",
      "6287/6287 [==============================] - 6s 953us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 68/100\n",
      "6287/6287 [==============================] - 6s 899us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 69/100\n",
      "6287/6287 [==============================] - 6s 889us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 70/100\n",
      "6287/6287 [==============================] - 6s 889us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 71/100\n",
      "6287/6287 [==============================] - 5s 872us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 72/100\n",
      "6287/6287 [==============================] - 5s 869us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1849 - val_accuracy: 0.4917\n",
      "Epoch 73/100\n",
      "6287/6287 [==============================] - 6s 887us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 74/100\n",
      "6287/6287 [==============================] - 6s 880us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1850 - val_accuracy: 0.4917\n",
      "Epoch 75/100\n",
      "6287/6287 [==============================] - 6s 886us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 76/100\n",
      "6287/6287 [==============================] - 6s 880us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 77/100\n",
      "6287/6287 [==============================] - 6s 879us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 78/100\n",
      "6287/6287 [==============================] - 6s 892us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 79/100\n",
      "6287/6287 [==============================] - 6s 894us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 80/100\n",
      "6287/6287 [==============================] - 5s 872us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 81/100\n",
      "6287/6287 [==============================] - 5s 861us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 82/100\n",
      "6287/6287 [==============================] - 5s 869us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 83/100\n",
      "6287/6287 [==============================] - 5s 871us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 84/100\n",
      "6287/6287 [==============================] - 5s 865us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 85/100\n",
      "6287/6287 [==============================] - 6s 891us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 86/100\n",
      "6287/6287 [==============================] - 6s 886us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 87/100\n",
      "6287/6287 [==============================] - 6s 895us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 88/100\n",
      "6287/6287 [==============================] - 6s 879us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 89/100\n",
      "6287/6287 [==============================] - 6s 888us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 90/100\n",
      "6287/6287 [==============================] - 6s 876us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 91/100\n",
      "6287/6287 [==============================] - 5s 866us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 92/100\n",
      "6287/6287 [==============================] - 6s 896us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 93/100\n",
      "6287/6287 [==============================] - 6s 906us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 94/100\n",
      "6287/6287 [==============================] - 6s 882us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 95/100\n",
      "6287/6287 [==============================] - 6s 882us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 96/100\n",
      "6287/6287 [==============================] - 6s 895us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 97/100\n",
      "6287/6287 [==============================] - 6s 890us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 98/100\n",
      "6287/6287 [==============================] - 6s 887us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 99/100\n",
      "6287/6287 [==============================] - 6s 896us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 100/100\n",
      "6287/6287 [==============================] - 6s 886us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "==================================================\n",
      "End Model:14\n",
      "##################################################\n",
      "Initialize Model:15\n",
      "Epoch 1/100\n",
      "6287/6287 [==============================] - 6s 931us/step - loss: 1.1880 - accuracy: 0.4897 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 2/100\n",
      "6287/6287 [==============================] - 6s 953us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 3/100\n",
      "6287/6287 [==============================] - 6s 899us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 4/100\n",
      "6287/6287 [==============================] - 6s 907us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 5/100\n",
      "6287/6287 [==============================] - 6s 899us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 6/100\n",
      "6287/6287 [==============================] - 6s 899us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 7/100\n",
      "6287/6287 [==============================] - 6s 907us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 8/100\n",
      "6287/6287 [==============================] - 6s 907us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 9/100\n",
      "6287/6287 [==============================] - 6s 907us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 10/100\n",
      "6287/6287 [==============================] - 6s 906us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 11/100\n",
      "6287/6287 [==============================] - 6s 910us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 12/100\n",
      "6287/6287 [==============================] - 6s 915us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 13/100\n",
      "6287/6287 [==============================] - 6s 911us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 14/100\n",
      "6287/6287 [==============================] - 6s 917us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 15/100\n",
      "6287/6287 [==============================] - 6s 904us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 16/100\n",
      "6287/6287 [==============================] - 6s 897us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 17/100\n",
      "6287/6287 [==============================] - 6s 890us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 18/100\n",
      "6287/6287 [==============================] - 5s 871us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1849 - val_accuracy: 0.4917\n",
      "Epoch 19/100\n",
      "6287/6287 [==============================] - 5s 872us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 20/100\n",
      "6287/6287 [==============================] - 6s 929us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 21/100\n",
      "6287/6287 [==============================] - 6s 913us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 22/100\n",
      "6287/6287 [==============================] - 6s 911us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 23/100\n",
      "6287/6287 [==============================] - 6s 907us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 24/100\n",
      "6287/6287 [==============================] - 6s 930us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 25/100\n",
      "6287/6287 [==============================] - 6s 916us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 26/100\n",
      "6287/6287 [==============================] - 6s 919us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 27/100\n",
      "6287/6287 [==============================] - 6s 906us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 28/100\n",
      "6287/6287 [==============================] - 6s 917us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 29/100\n",
      "6287/6287 [==============================] - 6s 893us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 30/100\n",
      "6287/6287 [==============================] - 6s 914us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 31/100\n",
      "6287/6287 [==============================] - 6s 904us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 32/100\n",
      "6287/6287 [==============================] - 6s 912us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 33/100\n",
      "6287/6287 [==============================] - 6s 920us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 34/100\n",
      "6287/6287 [==============================] - 6s 932us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 35/100\n",
      "6287/6287 [==============================] - 6s 917us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1853 - val_accuracy: 0.4917\n",
      "Epoch 36/100\n",
      "6287/6287 [==============================] - 6s 903us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 37/100\n",
      "6287/6287 [==============================] - 6s 918us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 38/100\n",
      "6287/6287 [==============================] - 6s 918us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 39/100\n",
      "6287/6287 [==============================] - 6s 905us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 40/100\n",
      "6287/6287 [==============================] - 6s 915us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 41/100\n",
      "6287/6287 [==============================] - 6s 906us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 42/100\n",
      "6287/6287 [==============================] - 6s 899us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 43/100\n",
      "6287/6287 [==============================] - 6s 899us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 44/100\n",
      "6287/6287 [==============================] - 6s 898us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1851 - val_accuracy: 0.4917\n",
      "Epoch 45/100\n",
      "6287/6287 [==============================] - 6s 902us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 46/100\n",
      "6287/6287 [==============================] - 6s 882us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 47/100\n",
      "6287/6287 [==============================] - 6s 907us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 48/100\n",
      "6287/6287 [==============================] - 6s 921us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 49/100\n",
      "6287/6287 [==============================] - 6s 919us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 50/100\n",
      "6287/6287 [==============================] - 6s 911us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1849 - val_accuracy: 0.4917\n",
      "Epoch 51/100\n",
      "6287/6287 [==============================] - 6s 928us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 52/100\n",
      "6287/6287 [==============================] - 6s 939us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 53/100\n",
      "6287/6287 [==============================] - 6s 901us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 54/100\n",
      "6287/6287 [==============================] - 6s 921us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 55/100\n",
      "6287/6287 [==============================] - 6s 915us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 56/100\n",
      "6287/6287 [==============================] - 6s 905us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1849 - val_accuracy: 0.4917\n",
      "Epoch 57/100\n",
      "6287/6287 [==============================] - 6s 910us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 58/100\n",
      "6287/6287 [==============================] - 6s 910us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 59/100\n",
      "6287/6287 [==============================] - 6s 896us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 60/100\n",
      "6287/6287 [==============================] - 6s 880us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 61/100\n",
      "6287/6287 [==============================] - 6s 895us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 62/100\n",
      "6287/6287 [==============================] - 6s 909us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 63/100\n",
      "6287/6287 [==============================] - 6s 898us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 64/100\n",
      "6287/6287 [==============================] - 6s 887us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1849 - val_accuracy: 0.4917\n",
      "Epoch 65/100\n",
      "6287/6287 [==============================] - 6s 895us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 66/100\n",
      "6287/6287 [==============================] - 6s 917us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 67/100\n",
      "6287/6287 [==============================] - 6s 919us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 68/100\n",
      "6287/6287 [==============================] - 6s 924us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 69/100\n",
      "6287/6287 [==============================] - 6s 917us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 70/100\n",
      "6287/6287 [==============================] - 6s 919us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 71/100\n",
      "6287/6287 [==============================] - 6s 893us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 72/100\n",
      "6287/6287 [==============================] - 6s 915us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 73/100\n",
      "6287/6287 [==============================] - 6s 876us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 74/100\n",
      "6287/6287 [==============================] - 5s 871us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 75/100\n",
      "6287/6287 [==============================] - 6s 902us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 76/100\n",
      "6287/6287 [==============================] - 6s 905us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 77/100\n",
      "6287/6287 [==============================] - 6s 913us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 78/100\n",
      "6287/6287 [==============================] - 6s 913us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 79/100\n",
      "6287/6287 [==============================] - 6s 924us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 80/100\n",
      "6287/6287 [==============================] - 6s 895us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 81/100\n",
      "6287/6287 [==============================] - 6s 902us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 82/100\n",
      "6287/6287 [==============================] - 6s 907us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 83/100\n",
      "6287/6287 [==============================] - 6s 912us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 84/100\n",
      "6287/6287 [==============================] - 6s 915us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 85/100\n",
      "6287/6287 [==============================] - 6s 912us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 86/100\n",
      "6287/6287 [==============================] - 6s 902us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 87/100\n",
      "6287/6287 [==============================] - 6s 886us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 88/100\n",
      "6287/6287 [==============================] - 6s 884us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 89/100\n",
      "6287/6287 [==============================] - 6s 920us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 90/100\n",
      "6287/6287 [==============================] - 6s 901us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 91/100\n",
      "6287/6287 [==============================] - 6s 924us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 92/100\n",
      "6287/6287 [==============================] - 6s 918us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 93/100\n",
      "6287/6287 [==============================] - 6s 922us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 94/100\n",
      "6287/6287 [==============================] - 6s 931us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 95/100\n",
      "6287/6287 [==============================] - 6s 912us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 96/100\n",
      "6287/6287 [==============================] - 6s 919us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 97/100\n",
      "6287/6287 [==============================] - 6s 933us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 98/100\n",
      "6287/6287 [==============================] - 6s 903us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 99/100\n",
      "6287/6287 [==============================] - 6s 909us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 100/100\n",
      "6287/6287 [==============================] - 6s 901us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "==================================================\n",
      "End Model:15\n",
      "##################################################\n",
      "Initialize Model:16\n",
      "Epoch 1/100\n",
      "6287/6287 [==============================] - 6s 972us/step - loss: 1.1893 - accuracy: 0.4882 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 2/100\n",
      "6287/6287 [==============================] - 6s 968us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 3/100\n",
      "6287/6287 [==============================] - 6s 979us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 4/100\n",
      "6287/6287 [==============================] - 6s 988us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1849 - val_accuracy: 0.4917\n",
      "Epoch 5/100\n",
      "6287/6287 [==============================] - 6s 969us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 6/100\n",
      "6287/6287 [==============================] - 6s 959us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 7/100\n",
      "6287/6287 [==============================] - 6s 967us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 8/100\n",
      "6287/6287 [==============================] - 6s 963us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 9/100\n",
      "6287/6287 [==============================] - 6s 955us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 10/100\n",
      "6287/6287 [==============================] - 6s 952us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 11/100\n",
      "6287/6287 [==============================] - 6s 963us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 12/100\n",
      "6287/6287 [==============================] - 6s 968us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 13/100\n",
      "6287/6287 [==============================] - 6s 970us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 14/100\n",
      "6287/6287 [==============================] - 6s 961us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 15/100\n",
      "6287/6287 [==============================] - 6s 971us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 16/100\n",
      "6287/6287 [==============================] - 6s 975us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 17/100\n",
      "6287/6287 [==============================] - 6s 994us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 18/100\n",
      "6287/6287 [==============================] - 6s 972us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 19/100\n",
      "6287/6287 [==============================] - 6s 963us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 20/100\n",
      "6287/6287 [==============================] - 6s 976us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 21/100\n",
      "6287/6287 [==============================] - 6s 961us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 22/100\n",
      "6287/6287 [==============================] - 6s 968us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 23/100\n",
      "6287/6287 [==============================] - 6s 984us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 24/100\n",
      "6287/6287 [==============================] - 6s 980us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 25/100\n",
      "6287/6287 [==============================] - 6s 967us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 26/100\n",
      "6287/6287 [==============================] - 6s 972us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 27/100\n",
      "6287/6287 [==============================] - 6s 957us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 28/100\n",
      "6287/6287 [==============================] - 6s 947us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 29/100\n",
      "6287/6287 [==============================] - 6s 974us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 30/100\n",
      "6287/6287 [==============================] - 6s 978us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 31/100\n",
      "6287/6287 [==============================] - 6s 983us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 32/100\n",
      "6287/6287 [==============================] - 6s 965us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 33/100\n",
      "6287/6287 [==============================] - 6s 973us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 34/100\n",
      "6287/6287 [==============================] - 6s 972us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 35/100\n",
      "6287/6287 [==============================] - 6s 982us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 36/100\n",
      "6287/6287 [==============================] - 6s 975us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 37/100\n",
      "6287/6287 [==============================] - 6s 975us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 38/100\n",
      "6287/6287 [==============================] - 6s 973us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 39/100\n",
      "6287/6287 [==============================] - 6s 969us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 40/100\n",
      "6287/6287 [==============================] - 6s 965us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 41/100\n",
      "6287/6287 [==============================] - 6s 955us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 42/100\n",
      "6287/6287 [==============================] - 6s 952us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 43/100\n",
      "6287/6287 [==============================] - 6s 967us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 44/100\n",
      "6287/6287 [==============================] - 6s 973us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 45/100\n",
      "6287/6287 [==============================] - 6s 979us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 46/100\n",
      "6287/6287 [==============================] - 6s 972us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 47/100\n",
      "6287/6287 [==============================] - 6s 997us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 48/100\n",
      "6287/6287 [==============================] - 6s 977us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 49/100\n",
      "6287/6287 [==============================] - 6s 985us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 50/100\n",
      "6287/6287 [==============================] - 6s 979us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 51/100\n",
      "6287/6287 [==============================] - 6s 980us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 52/100\n",
      "6287/6287 [==============================] - 6s 964us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 53/100\n",
      "6287/6287 [==============================] - 6s 959us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 54/100\n",
      "6287/6287 [==============================] - 6s 920us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 55/100\n",
      "6287/6287 [==============================] - 6s 934us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 56/100\n",
      "6287/6287 [==============================] - 6s 986us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 57/100\n",
      "6287/6287 [==============================] - 6s 992us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1850 - val_accuracy: 0.4917\n",
      "Epoch 58/100\n",
      "6287/6287 [==============================] - 6s 982us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 59/100\n",
      "6287/6287 [==============================] - 6s 986us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 60/100\n",
      "6287/6287 [==============================] - 6s 981us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 61/100\n",
      "6287/6287 [==============================] - 6s 981us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 62/100\n",
      "6287/6287 [==============================] - 6s 974us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 63/100\n",
      "6287/6287 [==============================] - 6s 983us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 64/100\n",
      "6287/6287 [==============================] - 6s 956us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 65/100\n",
      "6287/6287 [==============================] - 6s 964us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 66/100\n",
      "6287/6287 [==============================] - 6s 948us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 67/100\n",
      "6287/6287 [==============================] - 6s 973us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 68/100\n",
      "6287/6287 [==============================] - 6s 968us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 69/100\n",
      "6287/6287 [==============================] - 6s 984us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 70/100\n",
      "6287/6287 [==============================] - 6s 992us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 71/100\n",
      "6287/6287 [==============================] - 6s 976us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 72/100\n",
      "6287/6287 [==============================] - 6s 985us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1849 - val_accuracy: 0.4917\n",
      "Epoch 73/100\n",
      "6287/6287 [==============================] - 6s 969us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 74/100\n",
      "6287/6287 [==============================] - 7s 1ms/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 75/100\n",
      "6287/6287 [==============================] - 6s 983us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 76/100\n",
      "6287/6287 [==============================] - 6s 983us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 77/100\n",
      "6287/6287 [==============================] - 6s 972us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 78/100\n",
      "6287/6287 [==============================] - 6s 988us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 79/100\n",
      "6287/6287 [==============================] - 6s 985us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 80/100\n",
      "6287/6287 [==============================] - 6s 958us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 81/100\n",
      "6287/6287 [==============================] - 6s 959us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 82/100\n",
      "6287/6287 [==============================] - 6s 975us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 83/100\n",
      "6287/6287 [==============================] - 6s 984us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 84/100\n",
      "6287/6287 [==============================] - 6s 988us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 85/100\n",
      "6287/6287 [==============================] - 6s 985us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 86/100\n",
      "6287/6287 [==============================] - 6s 971us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 87/100\n",
      "6287/6287 [==============================] - 6s 964us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 88/100\n",
      "6287/6287 [==============================] - 6s 965us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 89/100\n",
      "6287/6287 [==============================] - 6s 981us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 90/100\n",
      "6287/6287 [==============================] - 6s 995us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 91/100\n",
      "6287/6287 [==============================] - 6s 976us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1849 - val_accuracy: 0.4917\n",
      "Epoch 92/100\n",
      "6287/6287 [==============================] - 6s 989us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 93/100\n",
      "6287/6287 [==============================] - 6s 973us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 94/100\n",
      "6287/6287 [==============================] - 6s 964us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 95/100\n",
      "6287/6287 [==============================] - 6s 980us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 96/100\n",
      "6287/6287 [==============================] - 6s 983us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 97/100\n",
      "6287/6287 [==============================] - 6s 969us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 98/100\n",
      "6287/6287 [==============================] - 6s 965us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 99/100\n",
      "6287/6287 [==============================] - 6s 945us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 100/100\n",
      "6287/6287 [==============================] - 6s 980us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "==================================================\n",
      "End Model:16\n",
      "##################################################\n",
      "Initialize Model:17\n",
      "Epoch 1/100\n",
      "6287/6287 [==============================] - 7s 1ms/step - loss: 1.1886 - accuracy: 0.4876 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 2/100\n",
      "6287/6287 [==============================] - 6s 1ms/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1853 - val_accuracy: 0.4917\n",
      "Epoch 3/100\n",
      "6287/6287 [==============================] - 6s 986us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 4/100\n",
      "6287/6287 [==============================] - 6s 979us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 5/100\n",
      "6287/6287 [==============================] - 6s 970us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 6/100\n",
      "6287/6287 [==============================] - 6s 958us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 7/100\n",
      "6287/6287 [==============================] - 6s 955us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 8/100\n",
      "6287/6287 [==============================] - 6s 946us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 9/100\n",
      "6287/6287 [==============================] - 6s 985us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 10/100\n",
      "6287/6287 [==============================] - 6s 984us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 11/100\n",
      "6287/6287 [==============================] - 6s 993us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 12/100\n",
      "6287/6287 [==============================] - 6s 986us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 13/100\n",
      "6287/6287 [==============================] - 6s 991us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 14/100\n",
      "6287/6287 [==============================] - 6s 992us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 15/100\n",
      "6287/6287 [==============================] - 6s 971us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 16/100\n",
      "6287/6287 [==============================] - 6s 987us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 17/100\n",
      "6287/6287 [==============================] - 6s 993us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 18/100\n",
      "6287/6287 [==============================] - 6s 972us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 19/100\n",
      "6287/6287 [==============================] - 6s 975us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 20/100\n",
      "6287/6287 [==============================] - 6s 955us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 21/100\n",
      "6287/6287 [==============================] - 6s 951us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 22/100\n",
      "6287/6287 [==============================] - 6s 984us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 23/100\n",
      "6287/6287 [==============================] - 6s 989us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 24/100\n",
      "6287/6287 [==============================] - 6s 987us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 25/100\n",
      "6287/6287 [==============================] - 6s 980us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1851 - val_accuracy: 0.4917\n",
      "Epoch 26/100\n",
      "6287/6287 [==============================] - 6s 989us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 27/100\n",
      "6287/6287 [==============================] - 6s 1ms/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 28/100\n",
      "6287/6287 [==============================] - 6s 983us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 29/100\n",
      "6287/6287 [==============================] - 6s 984us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 30/100\n",
      "6287/6287 [==============================] - 6s 979us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 31/100\n",
      "6287/6287 [==============================] - 6s 971us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 32/100\n",
      "6287/6287 [==============================] - 6s 963us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 33/100\n",
      "6287/6287 [==============================] - 6s 969us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 34/100\n",
      "6287/6287 [==============================] - 6s 956us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 35/100\n",
      "6287/6287 [==============================] - 6s 981us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 36/100\n",
      "6287/6287 [==============================] - 6s 998us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 37/100\n",
      "6287/6287 [==============================] - 6s 999us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 38/100\n",
      "6287/6287 [==============================] - 6s 990us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 39/100\n",
      "6287/6287 [==============================] - 6s 987us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 40/100\n",
      "6287/6287 [==============================] - 6s 980us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 41/100\n",
      "6287/6287 [==============================] - 6s 978us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 42/100\n",
      "6287/6287 [==============================] - 6s 969us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 43/100\n",
      "6287/6287 [==============================] - 6s 963us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 44/100\n",
      "6287/6287 [==============================] - 6s 980us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 45/100\n",
      "6287/6287 [==============================] - 6s 985us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 46/100\n",
      "6287/6287 [==============================] - 6s 973us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 47/100\n",
      "6287/6287 [==============================] - 6s 976us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 48/100\n",
      "6287/6287 [==============================] - 6s 975us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 49/100\n",
      "6287/6287 [==============================] - 6s 994us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 50/100\n",
      "6287/6287 [==============================] - 6s 977us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 51/100\n",
      "6287/6287 [==============================] - 6s 969us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 52/100\n",
      "6287/6287 [==============================] - 6s 973us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 53/100\n",
      "6287/6287 [==============================] - 6s 973us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 54/100\n",
      "6287/6287 [==============================] - 6s 981us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 55/100\n",
      "6287/6287 [==============================] - 6s 993us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 56/100\n",
      "6287/6287 [==============================] - 6s 993us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 57/100\n",
      "6287/6287 [==============================] - 6s 988us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1849 - val_accuracy: 0.4917\n",
      "Epoch 58/100\n",
      "6287/6287 [==============================] - 6s 989us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 59/100\n",
      "6287/6287 [==============================] - 6s 959us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 60/100\n",
      "6287/6287 [==============================] - 6s 969us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 61/100\n",
      "6287/6287 [==============================] - 6s 962us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 62/100\n",
      "6287/6287 [==============================] - 6s 986us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 63/100\n",
      "6287/6287 [==============================] - 6s 983us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 64/100\n",
      "6287/6287 [==============================] - 6s 979us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 65/100\n",
      "6287/6287 [==============================] - 6s 973us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 66/100\n",
      "6287/6287 [==============================] - 6s 983us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 67/100\n",
      "6287/6287 [==============================] - 6s 983us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 68/100\n",
      "6287/6287 [==============================] - 6s 982us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 69/100\n",
      "6287/6287 [==============================] - 6s 978us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 70/100\n",
      "6287/6287 [==============================] - 6s 985us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 71/100\n",
      "6287/6287 [==============================] - 6s 975us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 72/100\n",
      "6287/6287 [==============================] - 6s 991us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 73/100\n",
      "6287/6287 [==============================] - 6s 969us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 74/100\n",
      "6287/6287 [==============================] - 6s 974us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 75/100\n",
      "6287/6287 [==============================] - 6s 978us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 76/100\n",
      "6287/6287 [==============================] - 6s 976us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 77/100\n",
      "6287/6287 [==============================] - 6s 966us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 78/100\n",
      "6287/6287 [==============================] - 6s 944us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 79/100\n",
      "6287/6287 [==============================] - 6s 955us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 80/100\n",
      "6287/6287 [==============================] - 6s 943us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 81/100\n",
      "6287/6287 [==============================] - 6s 956us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 82/100\n",
      "6287/6287 [==============================] - 6s 957us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 83/100\n",
      "6287/6287 [==============================] - 6s 960us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 84/100\n",
      "6287/6287 [==============================] - 6s 922us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 85/100\n",
      "6287/6287 [==============================] - 6s 931us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 86/100\n",
      "6287/6287 [==============================] - 6s 909us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 87/100\n",
      "6287/6287 [==============================] - 6s 905us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 88/100\n",
      "6287/6287 [==============================] - 6s 924us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 89/100\n",
      "6287/6287 [==============================] - 6s 946us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 90/100\n",
      "6287/6287 [==============================] - 6s 951us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 91/100\n",
      "6287/6287 [==============================] - 6s 953us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 92/100\n",
      "6287/6287 [==============================] - 6s 957us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 93/100\n",
      "6287/6287 [==============================] - 6s 951us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 94/100\n",
      "6287/6287 [==============================] - 6s 956us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 95/100\n",
      "6287/6287 [==============================] - 6s 945us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 96/100\n",
      "6287/6287 [==============================] - 6s 943us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 97/100\n",
      "6287/6287 [==============================] - 6s 933us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 98/100\n",
      "6287/6287 [==============================] - 6s 926us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 99/100\n",
      "6287/6287 [==============================] - 6s 928us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1849 - val_accuracy: 0.4917\n",
      "Epoch 100/100\n",
      "6287/6287 [==============================] - 6s 926us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "==================================================\n",
      "End Model:17\n",
      "##################################################\n",
      "Initialize Model:18\n",
      "Epoch 1/100\n",
      "6287/6287 [==============================] - 6s 927us/step - loss: 1.1849 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 2/100\n",
      "6287/6287 [==============================] - 6s 928us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 3/100\n",
      "6287/6287 [==============================] - 6s 918us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 4/100\n",
      "6287/6287 [==============================] - 6s 906us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 5/100\n",
      "6287/6287 [==============================] - 6s 902us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 6/100\n",
      "6287/6287 [==============================] - 6s 907us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 7/100\n",
      "6287/6287 [==============================] - 6s 907us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 8/100\n",
      "6287/6287 [==============================] - 6s 920us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 9/100\n",
      "6287/6287 [==============================] - 6s 906us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 10/100\n",
      "6287/6287 [==============================] - 6s 903us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 11/100\n",
      "6287/6287 [==============================] - 6s 910us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 12/100\n",
      "6287/6287 [==============================] - 6s 902us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 13/100\n",
      "6287/6287 [==============================] - 6s 905us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 14/100\n",
      "6287/6287 [==============================] - 6s 885us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 15/100\n",
      "6287/6287 [==============================] - 6s 903us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 16/100\n",
      "6287/6287 [==============================] - 6s 906us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 17/100\n",
      "6287/6287 [==============================] - 6s 908us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 18/100\n",
      "6287/6287 [==============================] - 6s 904us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1849 - val_accuracy: 0.4917\n",
      "Epoch 19/100\n",
      "6287/6287 [==============================] - 6s 889us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 20/100\n",
      "6287/6287 [==============================] - 6s 894us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 21/100\n",
      "6287/6287 [==============================] - 6s 900us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 22/100\n",
      "6287/6287 [==============================] - 6s 888us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 23/100\n",
      "6287/6287 [==============================] - 6s 887us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 24/100\n",
      "6287/6287 [==============================] - 6s 904us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1849 - val_accuracy: 0.4917\n",
      "Epoch 25/100\n",
      "6287/6287 [==============================] - 6s 909us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 26/100\n",
      "6287/6287 [==============================] - 6s 892us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 27/100\n",
      "6287/6287 [==============================] - 6s 894us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 28/100\n",
      "6287/6287 [==============================] - 6s 888us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1851 - val_accuracy: 0.4917\n",
      "Epoch 29/100\n",
      "6287/6287 [==============================] - 6s 888us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 30/100\n",
      "6287/6287 [==============================] - 6s 896us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 31/100\n",
      "6287/6287 [==============================] - 6s 906us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1849 - val_accuracy: 0.4917\n",
      "Epoch 32/100\n",
      "6287/6287 [==============================] - 6s 894us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 33/100\n",
      "6287/6287 [==============================] - 6s 887us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 34/100\n",
      "6287/6287 [==============================] - 6s 878us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 35/100\n",
      "6287/6287 [==============================] - 6s 894us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 36/100\n",
      "6287/6287 [==============================] - 6s 900us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 37/100\n",
      "6287/6287 [==============================] - 6s 905us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 38/100\n",
      "6287/6287 [==============================] - 6s 899us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 39/100\n",
      "6287/6287 [==============================] - 6s 902us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 40/100\n",
      "6287/6287 [==============================] - 6s 887us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 41/100\n",
      "6287/6287 [==============================] - 6s 898us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 42/100\n",
      "6287/6287 [==============================] - 6s 887us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 43/100\n",
      "6287/6287 [==============================] - 6s 882us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 44/100\n",
      "6287/6287 [==============================] - 6s 877us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 45/100\n",
      "6287/6287 [==============================] - 6s 900us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 46/100\n",
      "6287/6287 [==============================] - 6s 903us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 47/100\n",
      "6287/6287 [==============================] - 6s 922us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 48/100\n",
      "6287/6287 [==============================] - 6s 919us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 49/100\n",
      "6287/6287 [==============================] - 6s 923us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 50/100\n",
      "6287/6287 [==============================] - 6s 910us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 51/100\n",
      "6287/6287 [==============================] - 6s 911us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 52/100\n",
      "6287/6287 [==============================] - 6s 911us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 53/100\n",
      "6287/6287 [==============================] - 6s 916us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 54/100\n",
      "6287/6287 [==============================] - 6s 895us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 55/100\n",
      "6287/6287 [==============================] - 6s 900us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 56/100\n",
      "6287/6287 [==============================] - 6s 897us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 57/100\n",
      "6287/6287 [==============================] - 6s 884us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 58/100\n",
      "6287/6287 [==============================] - 6s 883us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 59/100\n",
      "6287/6287 [==============================] - 6s 908us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 60/100\n",
      "6287/6287 [==============================] - 6s 899us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 61/100\n",
      "6287/6287 [==============================] - 6s 908us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 62/100\n",
      "6287/6287 [==============================] - 6s 918us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 63/100\n",
      "6287/6287 [==============================] - 6s 915us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 64/100\n",
      "6287/6287 [==============================] - 6s 917us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 65/100\n",
      "6287/6287 [==============================] - 6s 911us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 66/100\n",
      "6287/6287 [==============================] - 6s 902us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 67/100\n",
      "6287/6287 [==============================] - 6s 909us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 68/100\n",
      "6287/6287 [==============================] - 6s 897us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 69/100\n",
      "6287/6287 [==============================] - 6s 890us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 70/100\n",
      "6287/6287 [==============================] - 6s 893us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 71/100\n",
      "6287/6287 [==============================] - 6s 885us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 72/100\n",
      "6287/6287 [==============================] - 6s 893us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 73/100\n",
      "6287/6287 [==============================] - 6s 909us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 74/100\n",
      "6287/6287 [==============================] - 6s 917us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 75/100\n",
      "6287/6287 [==============================] - 6s 904us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 76/100\n",
      "6287/6287 [==============================] - 6s 911us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 77/100\n",
      "6287/6287 [==============================] - 6s 900us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 78/100\n",
      "6287/6287 [==============================] - 6s 909us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 79/100\n",
      "6287/6287 [==============================] - 6s 897us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 80/100\n",
      "6287/6287 [==============================] - 6s 893us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 81/100\n",
      "6287/6287 [==============================] - 6s 889us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 82/100\n",
      "6287/6287 [==============================] - 6s 893us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 83/100\n",
      "6287/6287 [==============================] - 6s 893us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 84/100\n",
      "6287/6287 [==============================] - 6s 910us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 85/100\n",
      "6287/6287 [==============================] - 6s 906us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 86/100\n",
      "6287/6287 [==============================] - 6s 905us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 87/100\n",
      "6287/6287 [==============================] - 6s 899us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 88/100\n",
      "6287/6287 [==============================] - 6s 911us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 89/100\n",
      "6287/6287 [==============================] - 6s 897us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 90/100\n",
      "6287/6287 [==============================] - 6s 895us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 91/100\n",
      "6287/6287 [==============================] - 6s 897us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 92/100\n",
      "6287/6287 [==============================] - 6s 901us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 93/100\n",
      "6287/6287 [==============================] - 6s 909us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 94/100\n",
      "6287/6287 [==============================] - 6s 916us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 95/100\n",
      "6287/6287 [==============================] - 6s 912us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 96/100\n",
      "6287/6287 [==============================] - 6s 905us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 97/100\n",
      "6287/6287 [==============================] - 6s 918us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 98/100\n",
      "6287/6287 [==============================] - 6s 905us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1849 - val_accuracy: 0.4917\n",
      "Epoch 99/100\n",
      "6287/6287 [==============================] - 6s 898us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 100/100\n",
      "6287/6287 [==============================] - 6s 890us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "==================================================\n",
      "End Model:18\n",
      "##################################################\n",
      "Initialize Model:19\n",
      "Epoch 1/100\n",
      "6287/6287 [==============================] - 6s 960us/step - loss: 1.1904 - accuracy: 0.4870 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 2/100\n",
      "6287/6287 [==============================] - 6s 972us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 3/100\n",
      "6287/6287 [==============================] - 6s 941us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 4/100\n",
      "6287/6287 [==============================] - 6s 936us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 5/100\n",
      "6287/6287 [==============================] - 6s 934us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 6/100\n",
      "6287/6287 [==============================] - 6s 941us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 7/100\n",
      "6287/6287 [==============================] - 6s 946us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 8/100\n",
      "6287/6287 [==============================] - 6s 921us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 9/100\n",
      "6287/6287 [==============================] - 6s 940us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 10/100\n",
      "6287/6287 [==============================] - 6s 925us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 11/100\n",
      "6287/6287 [==============================] - 6s 927us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 12/100\n",
      "6287/6287 [==============================] - 6s 935us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 13/100\n",
      "6287/6287 [==============================] - 6s 922us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 14/100\n",
      "6287/6287 [==============================] - 6s 935us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 15/100\n",
      "6287/6287 [==============================] - 6s 947us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 16/100\n",
      "6287/6287 [==============================] - 6s 934us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 17/100\n",
      "6287/6287 [==============================] - 6s 943us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 18/100\n",
      "6287/6287 [==============================] - 6s 935us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1849 - val_accuracy: 0.4917\n",
      "Epoch 19/100\n",
      "6287/6287 [==============================] - 6s 948us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 20/100\n",
      "6287/6287 [==============================] - 6s 944us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 21/100\n",
      "6287/6287 [==============================] - 6s 949us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 22/100\n",
      "6287/6287 [==============================] - 6s 943us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 23/100\n",
      "6287/6287 [==============================] - 6s 940us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 24/100\n",
      "6287/6287 [==============================] - 6s 921us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 25/100\n",
      "6287/6287 [==============================] - 6s 913us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 26/100\n",
      "6287/6287 [==============================] - 6s 901us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 27/100\n",
      "6287/6287 [==============================] - 6s 902us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 28/100\n",
      "6287/6287 [==============================] - 6s 931us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 29/100\n",
      "6287/6287 [==============================] - 6s 969us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 30/100\n",
      "6287/6287 [==============================] - 6s 944us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 31/100\n",
      "6287/6287 [==============================] - 6s 940us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 32/100\n",
      "6287/6287 [==============================] - 6s 958us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 33/100\n",
      "6287/6287 [==============================] - 6s 934us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 34/100\n",
      "6287/6287 [==============================] - 6s 943us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 35/100\n",
      "6287/6287 [==============================] - 6s 936us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1849 - val_accuracy: 0.4917\n",
      "Epoch 36/100\n",
      "6287/6287 [==============================] - 6s 939us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 37/100\n",
      "6287/6287 [==============================] - 6s 921us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 38/100\n",
      "6287/6287 [==============================] - 6s 933us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 39/100\n",
      "6287/6287 [==============================] - 6s 930us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 40/100\n",
      "6287/6287 [==============================] - 6s 936us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 41/100\n",
      "6287/6287 [==============================] - 6s 924us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 42/100\n",
      "6287/6287 [==============================] - 6s 954us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 43/100\n",
      "6287/6287 [==============================] - 6s 948us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 44/100\n",
      "6287/6287 [==============================] - 6s 942us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 45/100\n",
      "6287/6287 [==============================] - 6s 938us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 46/100\n",
      "6287/6287 [==============================] - 6s 944us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 47/100\n",
      "6287/6287 [==============================] - 6s 932us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 48/100\n",
      "6287/6287 [==============================] - 6s 930us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 49/100\n",
      "6287/6287 [==============================] - 6s 919us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 50/100\n",
      "6287/6287 [==============================] - 6s 938us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 51/100\n",
      "6287/6287 [==============================] - 6s 921us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 52/100\n",
      "6287/6287 [==============================] - 6s 931us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 53/100\n",
      "6287/6287 [==============================] - 6s 927us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 54/100\n",
      "6287/6287 [==============================] - 6s 923us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 55/100\n",
      "6287/6287 [==============================] - 6s 930us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 56/100\n",
      "6287/6287 [==============================] - 7s 1ms/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 57/100\n",
      "6287/6287 [==============================] - 6s 981us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 58/100\n",
      "6287/6287 [==============================] - 6s 934us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 59/100\n",
      "6287/6287 [==============================] - 6s 947us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 60/100\n",
      "6287/6287 [==============================] - 6s 932us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 61/100\n",
      "6287/6287 [==============================] - 6s 937us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 62/100\n",
      "6287/6287 [==============================] - 6s 955us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 63/100\n",
      "6287/6287 [==============================] - 6s 945us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 64/100\n",
      "6287/6287 [==============================] - 6s 941us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 65/100\n",
      "6287/6287 [==============================] - 6s 947us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 66/100\n",
      "6287/6287 [==============================] - 6s 945us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 67/100\n",
      "6287/6287 [==============================] - 6s 927us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 68/100\n",
      "6287/6287 [==============================] - 6s 941us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 69/100\n",
      "6287/6287 [==============================] - 6s 937us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 70/100\n",
      "6287/6287 [==============================] - 6s 949us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 71/100\n",
      "6287/6287 [==============================] - 6s 929us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 72/100\n",
      "6287/6287 [==============================] - 6s 921us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 73/100\n",
      "6287/6287 [==============================] - 6s 937us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 74/100\n",
      "6287/6287 [==============================] - 6s 957us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 75/100\n",
      "6287/6287 [==============================] - 6s 945us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 76/100\n",
      "6287/6287 [==============================] - 6s 955us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 77/100\n",
      "6287/6287 [==============================] - 6s 965us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 78/100\n",
      "6287/6287 [==============================] - 6s 942us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 79/100\n",
      "6287/6287 [==============================] - 6s 942us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 80/100\n",
      "6287/6287 [==============================] - 6s 932us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 81/100\n",
      "6287/6287 [==============================] - 6s 915us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 82/100\n",
      "6287/6287 [==============================] - 6s 927us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 83/100\n",
      "6287/6287 [==============================] - 6s 940us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 84/100\n",
      "6287/6287 [==============================] - 6s 947us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 85/100\n",
      "6287/6287 [==============================] - 6s 952us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 86/100\n",
      "6287/6287 [==============================] - 6s 960us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1852 - val_accuracy: 0.4917\n",
      "Epoch 87/100\n",
      "6287/6287 [==============================] - 6s 957us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 88/100\n",
      "6287/6287 [==============================] - 6s 964us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 89/100\n",
      "6287/6287 [==============================] - 6s 955us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1849 - val_accuracy: 0.4917\n",
      "Epoch 90/100\n",
      "6287/6287 [==============================] - 6s 954us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 91/100\n",
      "6287/6287 [==============================] - 6s 958us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 92/100\n",
      "6287/6287 [==============================] - 6s 942us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 93/100\n",
      "6287/6287 [==============================] - 6s 983us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 94/100\n",
      "6287/6287 [==============================] - 6s 965us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 95/100\n",
      "6287/6287 [==============================] - 6s 971us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 96/100\n",
      "6287/6287 [==============================] - 6s 1000us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 97/100\n",
      "6287/6287 [==============================] - 6s 991us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 98/100\n",
      "6287/6287 [==============================] - 6s 981us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 99/100\n",
      "6287/6287 [==============================] - 6s 992us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 100/100\n",
      "6287/6287 [==============================] - 6s 1ms/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "==================================================\n",
      "End Model:19\n",
      "##################################################\n",
      "Initialize Model:20\n",
      "Epoch 1/100\n",
      "6287/6287 [==============================] - 7s 1ms/step - loss: 1.1880 - accuracy: 0.4901 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 2/100\n",
      "6287/6287 [==============================] - 7s 1ms/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 3/100\n",
      "6287/6287 [==============================] - 6s 1ms/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 4/100\n",
      "6287/6287 [==============================] - 7s 1ms/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 5/100\n",
      "6287/6287 [==============================] - 6s 978us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 6/100\n",
      "6287/6287 [==============================] - 6s 942us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 7/100\n",
      "6287/6287 [==============================] - 6s 938us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 8/100\n",
      "6287/6287 [==============================] - 6s 929us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 9/100\n",
      "6287/6287 [==============================] - 6s 955us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 10/100\n",
      "6287/6287 [==============================] - 6s 996us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 11/100\n",
      "6287/6287 [==============================] - 6s 982us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 12/100\n",
      "6287/6287 [==============================] - 6s 954us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 13/100\n",
      "6287/6287 [==============================] - 6s 969us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 14/100\n",
      "6287/6287 [==============================] - 6s 947us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 15/100\n",
      "6287/6287 [==============================] - 6s 968us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 16/100\n",
      "6287/6287 [==============================] - 6s 926us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1849 - val_accuracy: 0.4917\n",
      "Epoch 17/100\n",
      "6287/6287 [==============================] - 6s 946us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 18/100\n",
      "6287/6287 [==============================] - 6s 1ms/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 19/100\n",
      "6287/6287 [==============================] - 6s 959us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 20/100\n",
      "6287/6287 [==============================] - 6s 981us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 21/100\n",
      "6287/6287 [==============================] - 6s 911us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 22/100\n",
      "6287/6287 [==============================] - 6s 917us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 23/100\n",
      "6287/6287 [==============================] - 6s 955us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 24/100\n",
      "6287/6287 [==============================] - 6s 956us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 25/100\n",
      "6287/6287 [==============================] - 6s 933us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 26/100\n",
      "6287/6287 [==============================] - 6s 946us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 27/100\n",
      "6287/6287 [==============================] - 6s 978us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 28/100\n",
      "6287/6287 [==============================] - 6s 968us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 29/100\n",
      "6287/6287 [==============================] - 6s 991us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 30/100\n",
      "6287/6287 [==============================] - 6s 964us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 31/100\n",
      "6287/6287 [==============================] - 6s 973us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 32/100\n",
      "6287/6287 [==============================] - 6s 929us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 33/100\n",
      "6287/6287 [==============================] - 6s 935us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 34/100\n",
      "6287/6287 [==============================] - 6s 931us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 35/100\n",
      "6287/6287 [==============================] - 6s 930us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 36/100\n",
      "6287/6287 [==============================] - 6s 931us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 37/100\n",
      "6287/6287 [==============================] - 6s 933us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 38/100\n",
      "6287/6287 [==============================] - 6s 930us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 39/100\n",
      "6287/6287 [==============================] - 6s 936us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 40/100\n",
      "6287/6287 [==============================] - 6s 977us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 41/100\n",
      "6287/6287 [==============================] - 6s 991us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 42/100\n",
      "6287/6287 [==============================] - 6s 936us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 43/100\n",
      "6287/6287 [==============================] - 6s 964us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 44/100\n",
      "6287/6287 [==============================] - 6s 938us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 45/100\n",
      "6287/6287 [==============================] - 6s 939us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 46/100\n",
      "6287/6287 [==============================] - 6s 968us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 47/100\n",
      "6287/6287 [==============================] - 6s 955us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 48/100\n",
      "6287/6287 [==============================] - 6s 932us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 49/100\n",
      "6287/6287 [==============================] - 6s 924us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 50/100\n",
      "6287/6287 [==============================] - 6s 977us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 51/100\n",
      "6287/6287 [==============================] - 6s 1ms/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 52/100\n",
      "6287/6287 [==============================] - 6s 1ms/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 53/100\n",
      "6287/6287 [==============================] - 6s 1ms/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 54/100\n",
      "6287/6287 [==============================] - 7s 1ms/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 55/100\n",
      "6287/6287 [==============================] - 7s 1ms/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 56/100\n",
      "6287/6287 [==============================] - 6s 1ms/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 57/100\n",
      "6287/6287 [==============================] - 6s 1ms/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 58/100\n",
      "6287/6287 [==============================] - 6s 1ms/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1849 - val_accuracy: 0.4917\n",
      "Epoch 59/100\n",
      "6287/6287 [==============================] - 6s 1ms/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 60/100\n",
      "6287/6287 [==============================] - 6s 956us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 61/100\n",
      "6287/6287 [==============================] - 6s 978us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 62/100\n",
      "6287/6287 [==============================] - 6s 973us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 63/100\n",
      "6287/6287 [==============================] - 6s 999us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 64/100\n",
      "6287/6287 [==============================] - 6s 1ms/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 65/100\n",
      "6287/6287 [==============================] - 6s 1ms/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 66/100\n",
      "6287/6287 [==============================] - 6s 1ms/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 67/100\n",
      "6287/6287 [==============================] - 6s 972us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 68/100\n",
      "6287/6287 [==============================] - 6s 982us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 69/100\n",
      "6287/6287 [==============================] - 6s 963us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1849 - val_accuracy: 0.4917\n",
      "Epoch 70/100\n",
      "6287/6287 [==============================] - 6s 992us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 71/100\n",
      "6287/6287 [==============================] - 6s 952us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 72/100\n",
      "6287/6287 [==============================] - 6s 982us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 73/100\n",
      "6287/6287 [==============================] - 6s 982us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 74/100\n",
      "6287/6287 [==============================] - 6s 971us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 75/100\n",
      "6287/6287 [==============================] - 6s 1ms/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 76/100\n",
      "6287/6287 [==============================] - 6s 1ms/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 77/100\n",
      "6287/6287 [==============================] - 6s 1ms/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 78/100\n",
      "6287/6287 [==============================] - 6s 992us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 79/100\n",
      "6287/6287 [==============================] - 6s 977us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 80/100\n",
      "6287/6287 [==============================] - 6s 991us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 81/100\n",
      "6287/6287 [==============================] - 6s 997us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 82/100\n",
      "6287/6287 [==============================] - 6s 978us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1849 - val_accuracy: 0.4917\n",
      "Epoch 83/100\n",
      "6287/6287 [==============================] - 6s 981us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 84/100\n",
      "6287/6287 [==============================] - 6s 973us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 85/100\n",
      "6287/6287 [==============================] - 6s 1ms/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 86/100\n",
      "6287/6287 [==============================] - 6s 994us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 87/100\n",
      "6287/6287 [==============================] - 6s 951us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 88/100\n",
      "6287/6287 [==============================] - 6s 972us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 89/100\n",
      "6287/6287 [==============================] - 7s 1ms/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 90/100\n",
      "6287/6287 [==============================] - 6s 996us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 91/100\n",
      "6287/6287 [==============================] - 6s 1ms/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 92/100\n",
      "6287/6287 [==============================] - 6s 1ms/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 93/100\n",
      "6287/6287 [==============================] - 6s 963us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 94/100\n",
      "6287/6287 [==============================] - 6s 964us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 95/100\n",
      "6287/6287 [==============================] - 6s 997us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 96/100\n",
      "6287/6287 [==============================] - 6s 1ms/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 97/100\n",
      "6287/6287 [==============================] - 6s 1ms/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 98/100\n",
      "6287/6287 [==============================] - 6s 1ms/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 99/100\n",
      "6287/6287 [==============================] - 6s 953us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 100/100\n",
      "6287/6287 [==============================] - 6s 955us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "==================================================\n",
      "End Model:20\n",
      "##################################################\n",
      "Initialize Model:21\n",
      "Epoch 1/100\n",
      "6287/6287 [==============================] - 7s 994us/step - loss: 1.1901 - accuracy: 0.4880 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 2/100\n",
      "6287/6287 [==============================] - 6s 989us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 3/100\n",
      "6287/6287 [==============================] - 6s 1ms/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 4/100\n",
      "6287/6287 [==============================] - 6s 971us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 5/100\n",
      "6287/6287 [==============================] - 6s 949us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 6/100\n",
      "6287/6287 [==============================] - 6s 962us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 7/100\n",
      "6287/6287 [==============================] - 6s 963us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1849 - val_accuracy: 0.4917\n",
      "Epoch 8/100\n",
      "6287/6287 [==============================] - 6s 965us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 9/100\n",
      "6287/6287 [==============================] - 6s 996us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 10/100\n",
      "6287/6287 [==============================] - 6s 982us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 11/100\n",
      "6287/6287 [==============================] - 6s 980us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 12/100\n",
      "6287/6287 [==============================] - 6s 1000us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 13/100\n",
      "6287/6287 [==============================] - 6s 986us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 14/100\n",
      "6287/6287 [==============================] - 6s 949us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 15/100\n",
      "6287/6287 [==============================] - 6s 974us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 16/100\n",
      "6287/6287 [==============================] - 6s 969us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 17/100\n",
      "6287/6287 [==============================] - 6s 972us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 18/100\n",
      "6287/6287 [==============================] - 6s 985us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 19/100\n",
      "6287/6287 [==============================] - 6s 970us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 20/100\n",
      "6287/6287 [==============================] - 6s 981us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 21/100\n",
      "6287/6287 [==============================] - 6s 976us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 22/100\n",
      "6287/6287 [==============================] - 6s 942us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 23/100\n",
      "6287/6287 [==============================] - 6s 939us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 24/100\n",
      "6287/6287 [==============================] - 6s 943us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 25/100\n",
      "6287/6287 [==============================] - 6s 914us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 26/100\n",
      "6287/6287 [==============================] - 6s 918us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1850 - val_accuracy: 0.4917\n",
      "Epoch 27/100\n",
      "6287/6287 [==============================] - 6s 914us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 28/100\n",
      "6287/6287 [==============================] - 6s 905us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 29/100\n",
      "6287/6287 [==============================] - 6s 970us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 30/100\n",
      "6287/6287 [==============================] - 6s 944us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 31/100\n",
      "6287/6287 [==============================] - 6s 921us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 32/100\n",
      "6287/6287 [==============================] - 6s 922us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 33/100\n",
      "6287/6287 [==============================] - 6s 908us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 34/100\n",
      "6287/6287 [==============================] - 6s 943us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 35/100\n",
      "6287/6287 [==============================] - 6s 937us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 36/100\n",
      "6287/6287 [==============================] - 6s 938us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 37/100\n",
      "6287/6287 [==============================] - 6s 935us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 38/100\n",
      "6287/6287 [==============================] - 6s 919us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 39/100\n",
      "6287/6287 [==============================] - 6s 905us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 40/100\n",
      "6287/6287 [==============================] - 6s 922us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 41/100\n",
      "6287/6287 [==============================] - 6s 935us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 42/100\n",
      "6287/6287 [==============================] - 6s 914us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 43/100\n",
      "6287/6287 [==============================] - 6s 949us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1849 - val_accuracy: 0.4917\n",
      "Epoch 44/100\n",
      "6287/6287 [==============================] - 6s 933us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 45/100\n",
      "6287/6287 [==============================] - 6s 929us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 46/100\n",
      "6287/6287 [==============================] - 6s 924us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 47/100\n",
      "6287/6287 [==============================] - 6s 906us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 48/100\n",
      "6287/6287 [==============================] - 6s 924us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 49/100\n",
      "6287/6287 [==============================] - 6s 924us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 50/100\n",
      "6287/6287 [==============================] - 6s 902us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 51/100\n",
      "6287/6287 [==============================] - 6s 916us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 52/100\n",
      "6287/6287 [==============================] - 6s 956us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 53/100\n",
      "6287/6287 [==============================] - 6s 905us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 54/100\n",
      "6287/6287 [==============================] - 6s 919us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 55/100\n",
      "6287/6287 [==============================] - 6s 910us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 56/100\n",
      "6287/6287 [==============================] - 6s 909us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 57/100\n",
      "6287/6287 [==============================] - 6s 932us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 58/100\n",
      "6287/6287 [==============================] - 6s 951us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 59/100\n",
      "6287/6287 [==============================] - 6s 938us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 60/100\n",
      "6287/6287 [==============================] - 6s 925us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 61/100\n",
      "6287/6287 [==============================] - 6s 909us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 62/100\n",
      "6287/6287 [==============================] - 6s 932us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 63/100\n",
      "6287/6287 [==============================] - 6s 916us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 64/100\n",
      "6287/6287 [==============================] - 6s 928us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 65/100\n",
      "6287/6287 [==============================] - 6s 948us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 66/100\n",
      "6287/6287 [==============================] - 6s 961us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 67/100\n",
      "6287/6287 [==============================] - 6s 952us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 68/100\n",
      "6287/6287 [==============================] - 6s 944us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 69/100\n",
      "6287/6287 [==============================] - 6s 917us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 70/100\n",
      "6287/6287 [==============================] - 6s 909us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 71/100\n",
      "6287/6287 [==============================] - 6s 918us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 72/100\n",
      "6287/6287 [==============================] - 6s 938us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1850 - val_accuracy: 0.4917\n",
      "Epoch 73/100\n",
      "6287/6287 [==============================] - 6s 937us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 74/100\n",
      "6287/6287 [==============================] - 6s 920us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 75/100\n",
      "6287/6287 [==============================] - 6s 963us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 76/100\n",
      "6287/6287 [==============================] - 6s 967us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 77/100\n",
      "6287/6287 [==============================] - 6s 995us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 78/100\n",
      "6287/6287 [==============================] - 6s 935us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 79/100\n",
      "6287/6287 [==============================] - 6s 953us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 80/100\n",
      "6287/6287 [==============================] - 6s 952us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 81/100\n",
      "6287/6287 [==============================] - 6s 909us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 82/100\n",
      "6287/6287 [==============================] - 6s 924us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 83/100\n",
      "6287/6287 [==============================] - 6s 949us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 84/100\n",
      "6287/6287 [==============================] - 6s 924us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 85/100\n",
      "6287/6287 [==============================] - 6s 929us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 86/100\n",
      "6287/6287 [==============================] - 6s 963us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 87/100\n",
      "6287/6287 [==============================] - 6s 963us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 88/100\n",
      "6287/6287 [==============================] - 6s 1ms/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 89/100\n",
      "6287/6287 [==============================] - 6s 986us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 90/100\n",
      "6287/6287 [==============================] - 6s 1ms/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 91/100\n",
      "6287/6287 [==============================] - 7s 1ms/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 92/100\n",
      "6287/6287 [==============================] - 6s 1ms/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 93/100\n",
      "6287/6287 [==============================] - 6s 955us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 94/100\n",
      "6287/6287 [==============================] - 6s 937us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 95/100\n",
      "6287/6287 [==============================] - 6s 987us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 96/100\n",
      "6287/6287 [==============================] - 6s 953us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 97/100\n",
      "6287/6287 [==============================] - 6s 964us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 98/100\n",
      "6287/6287 [==============================] - 6s 989us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 99/100\n",
      "6287/6287 [==============================] - 6s 984us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 100/100\n",
      "6287/6287 [==============================] - 7s 1ms/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "==================================================\n",
      "End Model:21\n",
      "##################################################\n",
      "Initialize Model:22\n",
      "Epoch 1/100\n",
      "6287/6287 [==============================] - 7s 977us/step - loss: 1.1847 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 2/100\n",
      "6287/6287 [==============================] - 6s 948us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 3/100\n",
      "6287/6287 [==============================] - 6s 932us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 4/100\n",
      "6287/6287 [==============================] - 6s 977us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 5/100\n",
      "6287/6287 [==============================] - 6s 912us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 6/100\n",
      "6287/6287 [==============================] - 6s 925us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 7/100\n",
      "6287/6287 [==============================] - 6s 926us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 8/100\n",
      "6287/6287 [==============================] - 6s 924us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 9/100\n",
      "6287/6287 [==============================] - 6s 984us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1851 - val_accuracy: 0.4917\n",
      "Epoch 10/100\n",
      "6287/6287 [==============================] - 6s 950us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 11/100\n",
      "6287/6287 [==============================] - 6s 948us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 12/100\n",
      "6287/6287 [==============================] - 6s 948us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 13/100\n",
      "6287/6287 [==============================] - 6s 942us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 14/100\n",
      "6287/6287 [==============================] - 6s 962us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 15/100\n",
      "6287/6287 [==============================] - 6s 941us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 16/100\n",
      "6287/6287 [==============================] - 6s 960us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 17/100\n",
      "6287/6287 [==============================] - 6s 966us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 18/100\n",
      "6287/6287 [==============================] - 6s 978us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 19/100\n",
      "6287/6287 [==============================] - 6s 928us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 20/100\n",
      "6287/6287 [==============================] - 6s 923us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 21/100\n",
      "6287/6287 [==============================] - 6s 973us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 22/100\n",
      "6287/6287 [==============================] - 6s 989us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 23/100\n",
      "6287/6287 [==============================] - 6s 961us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 24/100\n",
      "6287/6287 [==============================] - 6s 943us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 25/100\n",
      "6287/6287 [==============================] - 6s 992us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 26/100\n",
      "6287/6287 [==============================] - 6s 971us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 27/100\n",
      "6287/6287 [==============================] - 6s 1ms/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 28/100\n",
      "6287/6287 [==============================] - 6s 951us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1849 - val_accuracy: 0.4917\n",
      "Epoch 29/100\n",
      "6287/6287 [==============================] - 6s 928us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 30/100\n",
      "6287/6287 [==============================] - 6s 921us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 31/100\n",
      "6287/6287 [==============================] - 6s 943us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 32/100\n",
      "6287/6287 [==============================] - 6s 927us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 33/100\n",
      "6287/6287 [==============================] - 6s 998us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 34/100\n",
      "6287/6287 [==============================] - 6s 922us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 35/100\n",
      "6287/6287 [==============================] - 6s 914us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 36/100\n",
      "6287/6287 [==============================] - 6s 977us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 37/100\n",
      "6287/6287 [==============================] - 6s 936us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 38/100\n",
      "6287/6287 [==============================] - 6s 937us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 39/100\n",
      "6287/6287 [==============================] - 6s 894us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 40/100\n",
      "6287/6287 [==============================] - 6s 908us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 41/100\n",
      "6287/6287 [==============================] - 6s 908us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 42/100\n",
      "6287/6287 [==============================] - 6s 1ms/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 43/100\n",
      "6287/6287 [==============================] - 6s 965us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 44/100\n",
      "6287/6287 [==============================] - 6s 996us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 45/100\n",
      "6287/6287 [==============================] - 6s 945us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 46/100\n",
      "6287/6287 [==============================] - 6s 939us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 47/100\n",
      "6287/6287 [==============================] - 6s 992us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 48/100\n",
      "6287/6287 [==============================] - 6s 958us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 49/100\n",
      "6287/6287 [==============================] - 6s 974us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 50/100\n",
      "6287/6287 [==============================] - 6s 928us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 51/100\n",
      "6287/6287 [==============================] - 6s 938us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 52/100\n",
      "6287/6287 [==============================] - 6s 900us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 53/100\n",
      "6287/6287 [==============================] - 6s 927us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 54/100\n",
      "6287/6287 [==============================] - 6s 949us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 55/100\n",
      "6287/6287 [==============================] - 6s 945us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 56/100\n",
      "6287/6287 [==============================] - 6s 989us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 57/100\n",
      "6287/6287 [==============================] - 6s 946us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 58/100\n",
      "6287/6287 [==============================] - 6s 921us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 59/100\n",
      "6287/6287 [==============================] - 6s 898us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 60/100\n",
      "6287/6287 [==============================] - 6s 927us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 61/100\n",
      "6287/6287 [==============================] - 6s 931us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 62/100\n",
      "6287/6287 [==============================] - 6s 1ms/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 63/100\n",
      "6287/6287 [==============================] - 6s 994us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 64/100\n",
      "6287/6287 [==============================] - 6s 931us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 65/100\n",
      "6287/6287 [==============================] - 6s 937us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 66/100\n",
      "6287/6287 [==============================] - 6s 956us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 67/100\n",
      "6287/6287 [==============================] - 6s 956us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 68/100\n",
      "6287/6287 [==============================] - 6s 987us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 69/100\n",
      "6287/6287 [==============================] - 6s 953us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 70/100\n",
      "6287/6287 [==============================] - 6s 957us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 71/100\n",
      "6287/6287 [==============================] - 6s 950us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 72/100\n",
      "6287/6287 [==============================] - 6s 929us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 73/100\n",
      "6287/6287 [==============================] - 6s 954us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 74/100\n",
      "6287/6287 [==============================] - 6s 946us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 75/100\n",
      "6287/6287 [==============================] - 6s 924us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 76/100\n",
      "6287/6287 [==============================] - 6s 998us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 77/100\n",
      "6287/6287 [==============================] - 6s 1ms/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 78/100\n",
      "6287/6287 [==============================] - 6s 921us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 79/100\n",
      "6287/6287 [==============================] - 6s 985us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 80/100\n",
      "6287/6287 [==============================] - 6s 1ms/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 81/100\n",
      "6287/6287 [==============================] - 6s 1ms/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 82/100\n",
      "6287/6287 [==============================] - 6s 925us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 83/100\n",
      "6287/6287 [==============================] - 6s 941us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 84/100\n",
      "6287/6287 [==============================] - 6s 931us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 85/100\n",
      "6287/6287 [==============================] - 6s 932us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 86/100\n",
      "6287/6287 [==============================] - 6s 909us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 87/100\n",
      "6287/6287 [==============================] - 6s 920us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 88/100\n",
      "6287/6287 [==============================] - 6s 908us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 89/100\n",
      "6287/6287 [==============================] - 6s 921us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 90/100\n",
      "6287/6287 [==============================] - 6s 892us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 91/100\n",
      "6287/6287 [==============================] - 6s 896us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 92/100\n",
      "6287/6287 [==============================] - 6s 942us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 93/100\n",
      "6287/6287 [==============================] - 6s 916us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 94/100\n",
      "6287/6287 [==============================] - 6s 942us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 95/100\n",
      "6287/6287 [==============================] - 7s 1ms/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 96/100\n",
      "6287/6287 [==============================] - 6s 965us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 97/100\n",
      "6287/6287 [==============================] - 6s 914us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 98/100\n",
      "6287/6287 [==============================] - 6s 923us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 99/100\n",
      "6287/6287 [==============================] - 6s 922us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 100/100\n",
      "6287/6287 [==============================] - 6s 927us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "==================================================\n",
      "End Model:22\n",
      "##################################################\n",
      "Initialize Model:23\n",
      "Epoch 1/100\n",
      "6287/6287 [==============================] - 7s 1ms/step - loss: 1.1885 - accuracy: 0.4891 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 2/100\n",
      "6287/6287 [==============================] - 6s 1ms/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 3/100\n",
      "6287/6287 [==============================] - 6s 966us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 4/100\n",
      "6287/6287 [==============================] - 6s 941us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 5/100\n",
      "6287/6287 [==============================] - 6s 937us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 6/100\n",
      "6287/6287 [==============================] - 6s 945us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 7/100\n",
      "6287/6287 [==============================] - 6s 991us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 8/100\n",
      "6287/6287 [==============================] - 6s 987us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1849 - val_accuracy: 0.4917\n",
      "Epoch 9/100\n",
      "6287/6287 [==============================] - 6s 1ms/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 10/100\n",
      "6287/6287 [==============================] - 7s 1ms/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 11/100\n",
      "6287/6287 [==============================] - 6s 1ms/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 12/100\n",
      "6287/6287 [==============================] - 6s 984us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 13/100\n",
      "6287/6287 [==============================] - 6s 980us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 14/100\n",
      "6287/6287 [==============================] - 7s 1ms/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 15/100\n",
      "6287/6287 [==============================] - 6s 1ms/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 16/100\n",
      "6287/6287 [==============================] - 6s 1ms/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 17/100\n",
      "6287/6287 [==============================] - 6s 1ms/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1851 - val_accuracy: 0.4917\n",
      "Epoch 18/100\n",
      "6287/6287 [==============================] - 6s 1ms/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 19/100\n",
      "6287/6287 [==============================] - 7s 1ms/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 20/100\n",
      "6287/6287 [==============================] - 6s 999us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 21/100\n",
      "6287/6287 [==============================] - 6s 947us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 22/100\n",
      "6287/6287 [==============================] - 6s 944us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 23/100\n",
      "6287/6287 [==============================] - 6s 974us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 24/100\n",
      "6287/6287 [==============================] - 6s 966us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1850 - val_accuracy: 0.4917\n",
      "Epoch 25/100\n",
      "6287/6287 [==============================] - 6s 984us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 26/100\n",
      "6287/6287 [==============================] - 6s 1ms/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 27/100\n",
      "6287/6287 [==============================] - 6s 963us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1850 - val_accuracy: 0.4917\n",
      "Epoch 28/100\n",
      "6287/6287 [==============================] - 6s 966us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 29/100\n",
      "6287/6287 [==============================] - 6s 990us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 30/100\n",
      "6287/6287 [==============================] - 7s 1ms/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 31/100\n",
      "6287/6287 [==============================] - 6s 973us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 32/100\n",
      "6287/6287 [==============================] - 6s 1ms/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 33/100\n",
      "6287/6287 [==============================] - 7s 1ms/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 34/100\n",
      "6287/6287 [==============================] - 7s 1ms/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1850 - val_accuracy: 0.4917\n",
      "Epoch 35/100\n",
      "6287/6287 [==============================] - 6s 1ms/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 36/100\n",
      "6287/6287 [==============================] - 6s 1ms/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1849 - val_accuracy: 0.4917\n",
      "Epoch 37/100\n",
      "6287/6287 [==============================] - 6s 982us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 38/100\n",
      "6287/6287 [==============================] - 6s 960us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 39/100\n",
      "6287/6287 [==============================] - 6s 994us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 40/100\n",
      "6287/6287 [==============================] - 6s 1ms/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 41/100\n",
      "6287/6287 [==============================] - 6s 1ms/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 42/100\n",
      "6287/6287 [==============================] - 6s 945us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 43/100\n",
      "6287/6287 [==============================] - 6s 951us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 44/100\n",
      "6287/6287 [==============================] - 6s 938us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 45/100\n",
      "6287/6287 [==============================] - 6s 966us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 46/100\n",
      "6287/6287 [==============================] - 6s 954us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 47/100\n",
      "6287/6287 [==============================] - 6s 959us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1851 - val_accuracy: 0.4917\n",
      "Epoch 48/100\n",
      "6287/6287 [==============================] - 6s 958us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 49/100\n",
      "6287/6287 [==============================] - 6s 967us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 50/100\n",
      "6287/6287 [==============================] - 6s 980us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 51/100\n",
      "6287/6287 [==============================] - 6s 957us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 52/100\n",
      "6287/6287 [==============================] - 6s 961us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 53/100\n",
      "6287/6287 [==============================] - 6s 1ms/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 54/100\n",
      "6287/6287 [==============================] - 6s 926us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 55/100\n",
      "6287/6287 [==============================] - 6s 941us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 56/100\n",
      "6287/6287 [==============================] - 6s 1ms/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 57/100\n",
      "6287/6287 [==============================] - 6s 980us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 58/100\n",
      "6287/6287 [==============================] - 6s 948us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 59/100\n",
      "6287/6287 [==============================] - 6s 961us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 60/100\n",
      "6287/6287 [==============================] - 6s 961us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 61/100\n",
      "6287/6287 [==============================] - 6s 984us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 62/100\n",
      "6287/6287 [==============================] - 6s 971us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 63/100\n",
      "6287/6287 [==============================] - 6s 947us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 64/100\n",
      "6287/6287 [==============================] - 6s 972us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 65/100\n",
      "6287/6287 [==============================] - 6s 941us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 66/100\n",
      "6287/6287 [==============================] - 6s 966us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 67/100\n",
      "6287/6287 [==============================] - 6s 977us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 68/100\n",
      "6287/6287 [==============================] - 6s 958us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 69/100\n",
      "6287/6287 [==============================] - 6s 952us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 70/100\n",
      "6287/6287 [==============================] - 6s 940us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 71/100\n",
      "6287/6287 [==============================] - 6s 909us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 72/100\n",
      "6287/6287 [==============================] - 6s 948us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 73/100\n",
      "6287/6287 [==============================] - 6s 948us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 74/100\n",
      "6287/6287 [==============================] - 6s 976us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 75/100\n",
      "6287/6287 [==============================] - 6s 933us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 76/100\n",
      "6287/6287 [==============================] - 6s 934us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1847 - val_accuracy: 0.4917\n",
      "Epoch 77/100\n",
      "6287/6287 [==============================] - 6s 974us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 78/100\n",
      "6287/6287 [==============================] - 6s 971us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 79/100\n",
      "6287/6287 [==============================] - 6s 947us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1848 - val_accuracy: 0.4917\n",
      "Epoch 80/100\n",
      "6287/6287 [==============================] - 6s 1ms/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 81/100\n",
      "6287/6287 [==============================] - 6s 980us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 82/100\n",
      "6287/6287 [==============================] - 6s 1ms/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 83/100\n",
      "6287/6287 [==============================] - 6s 974us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 84/100\n",
      "6287/6287 [==============================] - 6s 954us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 85/100\n",
      "6287/6287 [==============================] - 6s 935us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 86/100\n",
      "6287/6287 [==============================] - 6s 898us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 87/100\n",
      "6287/6287 [==============================] - 6s 976us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 88/100\n",
      "6287/6287 [==============================] - 6s 1ms/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 89/100\n",
      "6287/6287 [==============================] - 6s 950us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 90/100\n",
      "6287/6287 [==============================] - 6s 982us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 91/100\n",
      "6287/6287 [==============================] - 6s 1ms/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 92/100\n",
      "6287/6287 [==============================] - 6s 986us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 93/100\n",
      "6287/6287 [==============================] - 6s 976us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 94/100\n",
      "6287/6287 [==============================] - 6s 975us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1844 - val_accuracy: 0.4917\n",
      "Epoch 95/100\n",
      "6287/6287 [==============================] - 6s 940us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 96/100\n",
      "6287/6287 [==============================] - 6s 970us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 97/100\n",
      "6287/6287 [==============================] - 6s 991us/step - loss: 1.1814 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 98/100\n",
      "6287/6287 [==============================] - 6s 945us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "Epoch 99/100\n",
      "6287/6287 [==============================] - 6s 941us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1846 - val_accuracy: 0.4917\n",
      "Epoch 100/100\n",
      "6287/6287 [==============================] - 6s 934us/step - loss: 1.1813 - accuracy: 0.4918 - val_loss: 1.1845 - val_accuracy: 0.4917\n",
      "==================================================\n",
      "End Model:23\n",
      "==================================================\n",
      "Excection Time:\n",
      "9856.32\n",
      "Number of fitting:\n",
      "24\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "results = build_model(\n",
    "    X_train,y_train,\n",
    "    X_test,y_test,\n",
    "\n",
    "    base_on='val_loss',\n",
    "\n",
    "    layers_nums=[3,4,5],\n",
    "    units_nums=[6,7,8,9],\n",
    "    activations=['relu','softmax'],\n",
    "    optimizers=['adam'],\n",
    "    epochs=100,\n",
    "    batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = best_model(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'units': 9,\n",
       " 'layers': 5,\n",
       " 'activation': 'relu',\n",
       " 'optimizer': 'adam',\n",
       " 'epochs': 100,\n",
       " 'batch_size': 32,\n",
       " 'model_history': <keras.callbacks.History at 0x1bd682cefa0>}"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6660420298576355"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** \n",
    "# Tests\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>CarBrand</th>\n",
       "      <th>CarModel</th>\n",
       "      <th>ManufactureYear</th>\n",
       "      <th>TotalCost</th>\n",
       "      <th>PaymentType</th>\n",
       "      <th>CarMade</th>\n",
       "      <th>CarType</th>\n",
       "      <th>PartsNumber</th>\n",
       "      <th>PartOfDay</th>\n",
       "      <th>part_Bridge</th>\n",
       "      <th>part_Bumper</th>\n",
       "      <th>part_Coilover</th>\n",
       "      <th>part_Control Arms</th>\n",
       "      <th>part_Dash insulator</th>\n",
       "      <th>part_Decoration</th>\n",
       "      <th>part_Door</th>\n",
       "      <th>part_Fender</th>\n",
       "      <th>part_Fiber</th>\n",
       "      <th>part_Grill</th>\n",
       "      <th>part_Handle</th>\n",
       "      <th>part_Headlight</th>\n",
       "      <th>part_Hinges</th>\n",
       "      <th>part_Hood</th>\n",
       "      <th>part_Injection</th>\n",
       "      <th>part_Mirror</th>\n",
       "      <th>part_Mudguard</th>\n",
       "      <th>part_Muffler</th>\n",
       "      <th>part_Other</th>\n",
       "      <th>part_Power Window</th>\n",
       "      <th>part_Radiator</th>\n",
       "      <th>part_Rims</th>\n",
       "      <th>part_Rotor</th>\n",
       "      <th>part_Sensor</th>\n",
       "      <th>part_Shock absorber</th>\n",
       "      <th>part_Splash shield</th>\n",
       "      <th>part_Stabilizer link</th>\n",
       "      <th>part_Taillight</th>\n",
       "      <th>part_Tie rod</th>\n",
       "      <th>part_Tire</th>\n",
       "      <th>part_Windshild</th>\n",
       "      <th>pos_front</th>\n",
       "      <th>pos_front left</th>\n",
       "      <th>pos_front right</th>\n",
       "      <th>pos_left</th>\n",
       "      <th>pos_rear</th>\n",
       "      <th>pos_rear left</th>\n",
       "      <th>pos_rear right</th>\n",
       "      <th>pos_right</th>\n",
       "      <th>pos_undefined</th>\n",
       "      <th>state_New</th>\n",
       "      <th>state_Used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>96</td>\n",
       "      <td>815</td>\n",
       "      <td>2002</td>\n",
       "      <td>3710</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>96</td>\n",
       "      <td>815</td>\n",
       "      <td>2008</td>\n",
       "      <td>11820</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>655</td>\n",
       "      <td>2012</td>\n",
       "      <td>10556</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>362</td>\n",
       "      <td>2011</td>\n",
       "      <td>1386</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>412</td>\n",
       "      <td>2007</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251468</th>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>740</td>\n",
       "      <td>2016</td>\n",
       "      <td>3580</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251469</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>278</td>\n",
       "      <td>2016</td>\n",
       "      <td>12011</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251470</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>505</td>\n",
       "      <td>2011</td>\n",
       "      <td>3200</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251471</th>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>278</td>\n",
       "      <td>2016</td>\n",
       "      <td>1947</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251472</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>674</td>\n",
       "      <td>2014</td>\n",
       "      <td>8182</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>251473 rows Ã— 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Area  CarBrand  CarModel  ManufactureYear  TotalCost  PaymentType  \\\n",
       "0          4        96       815             2002       3710            1   \n",
       "1          4        96       815             2008      11820            1   \n",
       "2          2         5       655             2012      10556            0   \n",
       "3          2        37       362             2011       1386            1   \n",
       "4          1        50       412             2007       2019            0   \n",
       "...      ...       ...       ...              ...        ...          ...   \n",
       "251468     1        40       740             2016       3580            0   \n",
       "251469     0        37       278             2016      12011            0   \n",
       "251470     3        12       505             2011       3200            0   \n",
       "251471     1        37       278             2016       1947            1   \n",
       "251472     0        37       674             2014       8182            0   \n",
       "\n",
       "        CarMade  CarType  PartsNumber  PartOfDay  part_Bridge  part_Bumper  \\\n",
       "0            13        1            4          2            0            0   \n",
       "1            13        1            4          2            0            1   \n",
       "2             5        0            1          2            0            1   \n",
       "3             9        1            1          2            0            0   \n",
       "4             8        0            2          2            0            1   \n",
       "...         ...      ...          ...        ...          ...          ...   \n",
       "251468        8        1            2          0            0            0   \n",
       "251469        9        1            5          0            0            1   \n",
       "251470       16        1            1          1            0            0   \n",
       "251471        9        1            2          0            0            0   \n",
       "251472        9        1            1          0            0            0   \n",
       "\n",
       "        part_Coilover  part_Control Arms  part_Dash insulator  \\\n",
       "0                   0                  0                    0   \n",
       "1                   0                  0                    0   \n",
       "2                   0                  0                    0   \n",
       "3                   0                  0                    0   \n",
       "4                   0                  0                    0   \n",
       "...               ...                ...                  ...   \n",
       "251468              0                  0                    0   \n",
       "251469              0                  0                    0   \n",
       "251470              0                  0                    1   \n",
       "251471              0                  0                    0   \n",
       "251472              0                  0                    0   \n",
       "\n",
       "        part_Decoration  part_Door  part_Fender  part_Fiber  part_Grill  \\\n",
       "0                     1          0            1           0           0   \n",
       "1                     1          0            0           0           0   \n",
       "2                     0          0            0           0           0   \n",
       "3                     0          0            0           0           0   \n",
       "4                     0          0            0           0           0   \n",
       "...                 ...        ...          ...         ...         ...   \n",
       "251468                0          0            0           0           0   \n",
       "251469                1          0            1           0           0   \n",
       "251470                0          0            0           0           0   \n",
       "251471                0          0            0           0           0   \n",
       "251472                0          1            0           0           0   \n",
       "\n",
       "        part_Handle  part_Headlight  part_Hinges  part_Hood  part_Injection  \\\n",
       "0                 0               0            0          0               0   \n",
       "1                 0               0            0          0               0   \n",
       "2                 0               0            0          0               0   \n",
       "3                 0               0            0          0               0   \n",
       "4                 0               0            0          0               0   \n",
       "...             ...             ...          ...        ...             ...   \n",
       "251468            0               0            0          0               0   \n",
       "251469            0               1            0          0               0   \n",
       "251470            0               0            0          0               0   \n",
       "251471            0               0            0          0               0   \n",
       "251472            0               0            0          0               0   \n",
       "\n",
       "        part_Mirror  part_Mudguard  part_Muffler  part_Other  \\\n",
       "0                 0              0             0           1   \n",
       "1                 0              0             0           1   \n",
       "2                 0              0             0           0   \n",
       "3                 0              0             0           0   \n",
       "4                 0              0             0           0   \n",
       "...             ...            ...           ...         ...   \n",
       "251468            0              0             0           1   \n",
       "251469            0              0             0           0   \n",
       "251470            0              0             0           0   \n",
       "251471            0              1             0           0   \n",
       "251472            0              0             0           0   \n",
       "\n",
       "        part_Power Window  part_Radiator  part_Rims  part_Rotor  part_Sensor  \\\n",
       "0                       0              0          0           0            0   \n",
       "1                       0              0          0           0            0   \n",
       "2                       0              0          0           0            0   \n",
       "3                       0              0          0           0            1   \n",
       "4                       0              0          0           0            1   \n",
       "...                   ...            ...        ...         ...          ...   \n",
       "251468                  0              0          1           0            0   \n",
       "251469                  0              0          0           0            0   \n",
       "251470                  0              0          0           0            0   \n",
       "251471                  0              0          0           0            0   \n",
       "251472                  0              0          0           0            0   \n",
       "\n",
       "        part_Shock absorber  part_Splash shield  part_Stabilizer link  \\\n",
       "0                         0                   0                     0   \n",
       "1                         0                   0                     0   \n",
       "2                         0                   0                     0   \n",
       "3                         0                   0                     0   \n",
       "4                         0                   0                     0   \n",
       "...                     ...                 ...                   ...   \n",
       "251468                    0                   0                     0   \n",
       "251469                    0                   1                     0   \n",
       "251470                    0                   0                     0   \n",
       "251471                    0                   1                     0   \n",
       "251472                    0                   0                     0   \n",
       "\n",
       "        part_Taillight  part_Tie rod  part_Tire  part_Windshild   pos_front  \\\n",
       "0                    1             0          0                0          0   \n",
       "1                    1             0          0                0          0   \n",
       "2                    0             0          0                0          0   \n",
       "3                    0             0          0                0          0   \n",
       "4                    0             0          0                0          1   \n",
       "...                ...           ...        ...              ...        ...   \n",
       "251468               0             0          0                0          0   \n",
       "251469               0             0          0                0          1   \n",
       "251470               0             0          0                0          0   \n",
       "251471               0             0          0                0          0   \n",
       "251472               0             0          0                0          0   \n",
       "\n",
       "        pos_front left  pos_front right  pos_left  pos_rear  pos_rear left  \\\n",
       "0                    1                0         1         0              1   \n",
       "1                    0                1         0         0              0   \n",
       "2                    0                0         0         1              0   \n",
       "3                    0                0         0         0              0   \n",
       "4                    0                1         0         0              0   \n",
       "...                ...              ...       ...       ...            ...   \n",
       "251468               0                0         0         0              0   \n",
       "251469               0                1         0         0              0   \n",
       "251470               1                0         0         0              1   \n",
       "251471               0                0         0         0              1   \n",
       "251472               1                0         0         0              0   \n",
       "\n",
       "        pos_rear right  pos_right  pos_undefined  state_New  state_Used  \n",
       "0                    0          0              0          1           0  \n",
       "1                    0          1              0          1           0  \n",
       "2                    0          0              0          1           0  \n",
       "3                    0          0              1          1           0  \n",
       "4                    0          0              0          1           0  \n",
       "...                ...        ...            ...        ...         ...  \n",
       "251468               1          0              0          1           0  \n",
       "251469               0          1              1          1           0  \n",
       "251470               0          0              0          1           0  \n",
       "251471               0          0              0          1           0  \n",
       "251472               0          0              0          1           0  \n",
       "\n",
       "[251473 rows x 52 columns]"
      ]
     },
     "execution_count": 640,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take copy from original dataframe to apply the regression model\n",
    "reg_df = df.copy()\n",
    "\n",
    "# Get dummies for parts regression dataframe \n",
    "reg_df = reg_df.join(reg_df['PartsList'].str.join('|').str.get_dummies().add_prefix('part_'))\n",
    "reg_df = reg_df.join(reg_df['PositionList'].str.join('|').str.get_dummies().add_prefix('pos_'))\n",
    "reg_df = reg_df.join(reg_df['PartStateList'].str.join('|').str.get_dummies().add_prefix('state_'))\n",
    "\n",
    "\n",
    "# Remove unwanted columns from Regression Training\n",
    "unwanted_cols = ['c_id','RegistrationTime', 'CloseTime', 'Hour','Month', 'Day', 'WeekDay', 'PartsList', 'PositionList', 'PartStateList']\n",
    "unwanted_cols.append('AssessmentCost')\n",
    "unwanted_cols.append('SparePartCost')\n",
    "unwanted_cols.append('SparePart_Differace%')\n",
    "unwanted_cols.append('AssessmentEvaluation')\n",
    "unwanted_cols.append('TotalCostEvaluation')\n",
    "\n",
    "unwanted_cols.append('TimeEvaluation')\n",
    "unwanted_cols.append('DurationTime')\n",
    "\n",
    "unwanted_cols.append('CarColor')\n",
    "unwanted_cols.append('CarClass')\n",
    "# Than drop the columns\n",
    "reg_df.drop(unwanted_cols, axis=1, inplace=True)\n",
    "\n",
    "target = 'TotalCost'\n",
    "\n",
    "cat_cols = reg_df.describe(exclude='number').columns\n",
    "num_cols = reg_df.describe().columns\n",
    "\n",
    "\n",
    "\n",
    "reg_df[cat_cols]=reg_df[cat_cols].apply(LabelEncoder().fit_transform)\n",
    "reg_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "uniqueKyes = {}\n",
    "for x in cat_cols:\n",
    "    uniqueKyes[x] = dict(zip(df[x].unique(),(reg_df[x].unique())))\n",
    "\n",
    "for k,v in uniqueKyes.items():\n",
    "    for k2,v2 in v.items():\n",
    "        uniqueKyes[k][k2] = int(v2)\n",
    "\n",
    "uniqueKyes\n",
    "\n",
    "with open('UniqueKyes', 'w') as f:\n",
    "    f.write(json.dumps(uniqueKyes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>CarBrand</th>\n",
       "      <th>CarModel</th>\n",
       "      <th>ManufactureYear</th>\n",
       "      <th>PaymentType</th>\n",
       "      <th>CarMade</th>\n",
       "      <th>CarType</th>\n",
       "      <th>PartsNumber</th>\n",
       "      <th>PartOfDay</th>\n",
       "      <th>part_Bridge</th>\n",
       "      <th>part_Bumper</th>\n",
       "      <th>part_Coilover</th>\n",
       "      <th>part_Control Arms</th>\n",
       "      <th>part_Dash insulator</th>\n",
       "      <th>part_Decoration</th>\n",
       "      <th>part_Door</th>\n",
       "      <th>part_Fender</th>\n",
       "      <th>part_Fiber</th>\n",
       "      <th>part_Grill</th>\n",
       "      <th>part_Handle</th>\n",
       "      <th>part_Headlight</th>\n",
       "      <th>part_Hinges</th>\n",
       "      <th>part_Hood</th>\n",
       "      <th>part_Injection</th>\n",
       "      <th>part_Mirror</th>\n",
       "      <th>part_Mudguard</th>\n",
       "      <th>part_Muffler</th>\n",
       "      <th>part_Other</th>\n",
       "      <th>part_Power Window</th>\n",
       "      <th>part_Radiator</th>\n",
       "      <th>part_Rims</th>\n",
       "      <th>part_Rotor</th>\n",
       "      <th>part_Sensor</th>\n",
       "      <th>part_Shock absorber</th>\n",
       "      <th>part_Splash shield</th>\n",
       "      <th>part_Stabilizer link</th>\n",
       "      <th>part_Taillight</th>\n",
       "      <th>part_Tie rod</th>\n",
       "      <th>part_Tire</th>\n",
       "      <th>part_Windshild</th>\n",
       "      <th>pos_front</th>\n",
       "      <th>pos_front left</th>\n",
       "      <th>pos_front right</th>\n",
       "      <th>pos_left</th>\n",
       "      <th>pos_rear</th>\n",
       "      <th>pos_rear left</th>\n",
       "      <th>pos_rear right</th>\n",
       "      <th>pos_right</th>\n",
       "      <th>pos_undefined</th>\n",
       "      <th>state_New</th>\n",
       "      <th>state_Used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>92</td>\n",
       "      <td>201</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Area  CarBrand  CarModel  ManufactureYear  PaymentType  CarMade  CarType  \\\n",
       "0     2        92       201             2016            0        8        1   \n",
       "\n",
       "   PartsNumber  PartOfDay  part_Bridge  part_Bumper  part_Coilover  \\\n",
       "0            3          0            1            1              0   \n",
       "\n",
       "   part_Control Arms  part_Dash insulator  part_Decoration  part_Door  \\\n",
       "0                  0                    0                0          0   \n",
       "\n",
       "   part_Fender  part_Fiber  part_Grill  part_Handle  part_Headlight  \\\n",
       "0            0           0           0            0               0   \n",
       "\n",
       "   part_Hinges  part_Hood  part_Injection  part_Mirror  part_Mudguard  \\\n",
       "0            0          0               0            0              0   \n",
       "\n",
       "   part_Muffler  part_Other  part_Power Window  part_Radiator  part_Rims  \\\n",
       "0             0           0                  0              0          0   \n",
       "\n",
       "   part_Rotor  part_Sensor  part_Shock absorber  part_Splash shield  \\\n",
       "0           0            1                    0                   0   \n",
       "\n",
       "   part_Stabilizer link  part_Taillight  part_Tie rod  part_Tire  \\\n",
       "0                     0               0             0          0   \n",
       "\n",
       "   part_Windshild   pos_front  pos_front left  pos_front right  pos_left  \\\n",
       "0                0          0               0                0         0   \n",
       "\n",
       "   pos_rear  pos_rear left  pos_rear right  pos_right  pos_undefined  \\\n",
       "0         1              1               0          0              0   \n",
       "\n",
       "   state_New  state_Used  \n",
       "0          1           0  "
      ]
     },
     "execution_count": 642,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dict = {'Area': 2,\n",
    " 'CarBrand': 92,\n",
    " 'CarModel': 201,\n",
    " 'ManufactureYear': 2016,\n",
    " 'PaymentType': 0,\n",
    " 'CarMade': 8,\n",
    " 'CarType': 1,\n",
    " 'PartsNumber': 3,\n",
    " 'PartOfDay': 0,\n",
    " 'part_Bridge': 1,\n",
    " 'part_Bumper': 1,\n",
    " 'part_Coilover': 0,\n",
    " 'part_Control Arms': 0,\n",
    " 'part_Dash insulator': 0,\n",
    " 'part_Decoration': 0,\n",
    " 'part_Door': 0,\n",
    " 'part_Fender': 0,\n",
    " 'part_Fiber': 0,\n",
    " 'part_Grill': 0,\n",
    " 'part_Handle': 0,\n",
    " 'part_Headlight': 0,\n",
    " 'part_Hinges': 0,\n",
    " 'part_Hood': 0,\n",
    " 'part_Injection': 0,\n",
    " 'part_Mirror': 0,\n",
    " 'part_Mudguard': 0,\n",
    " 'part_Muffler': 0,\n",
    " 'part_Other': 0,\n",
    " 'part_Power Window': 0,\n",
    " 'part_Radiator': 0,\n",
    " 'part_Rims': 0,\n",
    " 'part_Rotor': 0,\n",
    " 'part_Sensor': 1,\n",
    " 'part_Shock absorber': 0,\n",
    " 'part_Splash shield': 0,\n",
    " 'part_Stabilizer link': 0,\n",
    " 'part_Taillight': 0,\n",
    " 'part_Tie rod': 0,\n",
    " 'part_Tire': 0,\n",
    " 'part_Windshild ': 0,\n",
    " 'pos_front': 0,\n",
    " 'pos_front left': 0,\n",
    " 'pos_front right': 0,\n",
    " 'pos_left': 0,\n",
    " 'pos_rear': 1,\n",
    " 'pos_rear left': 1,\n",
    " 'pos_rear right': 0,\n",
    " 'pos_right': 0,\n",
    " 'pos_undefined': 0,\n",
    " 'state_New': 1,\n",
    " 'state_Used': 0}\n",
    "\n",
    "test_df = pd.DataFrame(input_dict, index=[0])\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_R = joblib.load(f\"models/XGBR_Model_19_23-21\")\n",
    "XGB_C = joblib.load(f\"models/XGBC_Model_19_23-21\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4544.4595], dtype=float32)"
      ]
     },
     "execution_count": 644,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB_R.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3318"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_id</th>\n",
       "      <th>Area</th>\n",
       "      <th>RegistrationTime</th>\n",
       "      <th>CloseTime</th>\n",
       "      <th>CarBrand</th>\n",
       "      <th>CarModel</th>\n",
       "      <th>ManufactureYear</th>\n",
       "      <th>CarColor</th>\n",
       "      <th>AssessmentCost</th>\n",
       "      <th>SparePartCost</th>\n",
       "      <th>TotalCost</th>\n",
       "      <th>PaymentType</th>\n",
       "      <th>DurationTime</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>WeekDay</th>\n",
       "      <th>PartsList</th>\n",
       "      <th>PositionList</th>\n",
       "      <th>PartStateList</th>\n",
       "      <th>CarMade</th>\n",
       "      <th>CarClass</th>\n",
       "      <th>CarType</th>\n",
       "      <th>SparePart_Differace%</th>\n",
       "      <th>AssessmentEvaluation</th>\n",
       "      <th>PartsNumber</th>\n",
       "      <th>TimeEvaluation</th>\n",
       "      <th>PartOfDay</th>\n",
       "      <th>TotalCostEvaluation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94</td>\n",
       "      <td>Orouba</td>\n",
       "      <td>2018-01-01 10:17:57.727000</td>\n",
       "      <td>2018-01-01 10:25:00</td>\n",
       "      <td>BMW</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>2012</td>\n",
       "      <td>white</td>\n",
       "      <td>5778</td>\n",
       "      <td>4778</td>\n",
       "      <td>10556</td>\n",
       "      <td>Insurance Company</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Monday</td>\n",
       "      <td>[Bumper]</td>\n",
       "      <td>[rear]</td>\n",
       "      <td>[New]</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Luxury</td>\n",
       "      <td>Car</td>\n",
       "      <td>20.929259</td>\n",
       "      <td>Acceptable</td>\n",
       "      <td>1</td>\n",
       "      <td>Fast</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Acceptable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99</td>\n",
       "      <td>Orouba</td>\n",
       "      <td>2018-01-01 10:25:36.453000</td>\n",
       "      <td>2018-01-01 10:52:00</td>\n",
       "      <td>Hyundai</td>\n",
       "      <td>Genesis</td>\n",
       "      <td>2011</td>\n",
       "      <td>silver</td>\n",
       "      <td>1043</td>\n",
       "      <td>343</td>\n",
       "      <td>1386</td>\n",
       "      <td>POS</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Monday</td>\n",
       "      <td>[Sensor]</td>\n",
       "      <td>[undefined]</td>\n",
       "      <td>[New]</td>\n",
       "      <td>Korea</td>\n",
       "      <td>Luxury</td>\n",
       "      <td>Multi</td>\n",
       "      <td>204.081633</td>\n",
       "      <td>unacceptable</td>\n",
       "      <td>1</td>\n",
       "      <td>Delay</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>120</td>\n",
       "      <td>Orouba</td>\n",
       "      <td>2018-01-01 08:58:11.430000</td>\n",
       "      <td>2018-01-01 09:05:00</td>\n",
       "      <td>Lexus</td>\n",
       "      <td>GS 460</td>\n",
       "      <td>2011</td>\n",
       "      <td>white</td>\n",
       "      <td>2019</td>\n",
       "      <td>1019</td>\n",
       "      <td>3038</td>\n",
       "      <td>Insurance Company</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Monday</td>\n",
       "      <td>[Bumper]</td>\n",
       "      <td>[rear]</td>\n",
       "      <td>[New]</td>\n",
       "      <td>Japan</td>\n",
       "      <td>Luxury</td>\n",
       "      <td>Car</td>\n",
       "      <td>98.135427</td>\n",
       "      <td>unacceptable</td>\n",
       "      <td>1</td>\n",
       "      <td>Fast</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>295</td>\n",
       "      <td>Capital Industrial</td>\n",
       "      <td>2018-01-01 09:44:24.113000</td>\n",
       "      <td>2018-01-01 09:52:00</td>\n",
       "      <td>Mercedes</td>\n",
       "      <td>320</td>\n",
       "      <td>2003</td>\n",
       "      <td>silver</td>\n",
       "      <td>2300</td>\n",
       "      <td>800</td>\n",
       "      <td>3100</td>\n",
       "      <td>Insurance Company</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Monday</td>\n",
       "      <td>[Bumper]</td>\n",
       "      <td>[front]</td>\n",
       "      <td>[Used]</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Luxury</td>\n",
       "      <td>Multi</td>\n",
       "      <td>187.500000</td>\n",
       "      <td>unacceptable</td>\n",
       "      <td>1</td>\n",
       "      <td>Fast</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>408</td>\n",
       "      <td>New Industrial</td>\n",
       "      <td>2018-01-01 11:03:56.103000</td>\n",
       "      <td>2018-01-01 11:20:00</td>\n",
       "      <td>Lexus</td>\n",
       "      <td>IS 350</td>\n",
       "      <td>2016</td>\n",
       "      <td>grey</td>\n",
       "      <td>3500</td>\n",
       "      <td>1500</td>\n",
       "      <td>5000</td>\n",
       "      <td>Insurance Company</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Monday</td>\n",
       "      <td>[Dash insulator]</td>\n",
       "      <td>[rear right]</td>\n",
       "      <td>[New]</td>\n",
       "      <td>Japan</td>\n",
       "      <td>Luxury</td>\n",
       "      <td>Car</td>\n",
       "      <td>133.333333</td>\n",
       "      <td>unacceptable</td>\n",
       "      <td>1</td>\n",
       "      <td>Acceptable</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251461</th>\n",
       "      <td>253382</td>\n",
       "      <td>Remmal Industrial</td>\n",
       "      <td>2018-12-19 10:51:52.593000</td>\n",
       "      <td>2018-12-19 11:21:00</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>Prado</td>\n",
       "      <td>2014</td>\n",
       "      <td>white</td>\n",
       "      <td>1620</td>\n",
       "      <td>820</td>\n",
       "      <td>2441</td>\n",
       "      <td>Insurance Company</td>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>[Bumper]</td>\n",
       "      <td>[rear, rear right]</td>\n",
       "      <td>[New]</td>\n",
       "      <td>Japan</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Multi</td>\n",
       "      <td>97.560976</td>\n",
       "      <td>unacceptable</td>\n",
       "      <td>1</td>\n",
       "      <td>Delay</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251464</th>\n",
       "      <td>253386</td>\n",
       "      <td>Remmal Industrial</td>\n",
       "      <td>2018-12-19 13:12:38.333000</td>\n",
       "      <td>2018-12-19 13:35:00</td>\n",
       "      <td>Kia</td>\n",
       "      <td>Cerato</td>\n",
       "      <td>2014</td>\n",
       "      <td>black</td>\n",
       "      <td>1372</td>\n",
       "      <td>572</td>\n",
       "      <td>1945</td>\n",
       "      <td>Insurance Company</td>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>[Mirror]</td>\n",
       "      <td>[right]</td>\n",
       "      <td>[New]</td>\n",
       "      <td>Korea</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Multi</td>\n",
       "      <td>139.860140</td>\n",
       "      <td>unacceptable</td>\n",
       "      <td>1</td>\n",
       "      <td>Acceptable</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251467</th>\n",
       "      <td>253389</td>\n",
       "      <td>Orouba</td>\n",
       "      <td>2018-12-19 12:51:14.513000</td>\n",
       "      <td>2018-12-19 13:02:00</td>\n",
       "      <td>Kia</td>\n",
       "      <td>Carnival</td>\n",
       "      <td>2015</td>\n",
       "      <td>silver</td>\n",
       "      <td>1702</td>\n",
       "      <td>902</td>\n",
       "      <td>2605</td>\n",
       "      <td>Insurance Company</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>[Bumper]</td>\n",
       "      <td>[front]</td>\n",
       "      <td>[New]</td>\n",
       "      <td>Korea</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Multi</td>\n",
       "      <td>88.691796</td>\n",
       "      <td>Very High</td>\n",
       "      <td>1</td>\n",
       "      <td>Fast</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251470</th>\n",
       "      <td>253392</td>\n",
       "      <td>Remmal Industrial</td>\n",
       "      <td>2018-12-19 17:22:22.537000</td>\n",
       "      <td>2018-12-19 17:36:00</td>\n",
       "      <td>Chevrolet</td>\n",
       "      <td>Malibu</td>\n",
       "      <td>2011</td>\n",
       "      <td>silver</td>\n",
       "      <td>2600</td>\n",
       "      <td>600</td>\n",
       "      <td>3200</td>\n",
       "      <td>Insurance Company</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>[Dash insulator]</td>\n",
       "      <td>[front left, rear left]</td>\n",
       "      <td>[New]</td>\n",
       "      <td>US</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Multi</td>\n",
       "      <td>333.333333</td>\n",
       "      <td>unacceptable</td>\n",
       "      <td>1</td>\n",
       "      <td>Acceptable</td>\n",
       "      <td>Evening</td>\n",
       "      <td>Acceptable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251472</th>\n",
       "      <td>253395</td>\n",
       "      <td>Capital Industrial</td>\n",
       "      <td>2018-12-19 15:32:21.193000</td>\n",
       "      <td>2018-12-19 15:54:00</td>\n",
       "      <td>Hyundai</td>\n",
       "      <td>Sonata</td>\n",
       "      <td>2014</td>\n",
       "      <td>silver</td>\n",
       "      <td>5191</td>\n",
       "      <td>2991</td>\n",
       "      <td>8182</td>\n",
       "      <td>Insurance Company</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>[Door]</td>\n",
       "      <td>[front left]</td>\n",
       "      <td>[New]</td>\n",
       "      <td>Korea</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Multi</td>\n",
       "      <td>73.553995</td>\n",
       "      <td>Very High</td>\n",
       "      <td>1</td>\n",
       "      <td>Acceptable</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>Acceptable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65405 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          c_id                Area            RegistrationTime  \\\n",
       "2           94              Orouba  2018-01-01 10:17:57.727000   \n",
       "3           99              Orouba  2018-01-01 10:25:36.453000   \n",
       "7          120              Orouba  2018-01-01 08:58:11.430000   \n",
       "12         295  Capital Industrial  2018-01-01 09:44:24.113000   \n",
       "15         408      New Industrial  2018-01-01 11:03:56.103000   \n",
       "...        ...                 ...                         ...   \n",
       "251461  253382   Remmal Industrial  2018-12-19 10:51:52.593000   \n",
       "251464  253386   Remmal Industrial  2018-12-19 13:12:38.333000   \n",
       "251467  253389              Orouba  2018-12-19 12:51:14.513000   \n",
       "251470  253392   Remmal Industrial  2018-12-19 17:22:22.537000   \n",
       "251472  253395  Capital Industrial  2018-12-19 15:32:21.193000   \n",
       "\n",
       "                  CloseTime   CarBrand  CarModel  ManufactureYear CarColor  \\\n",
       "2       2018-01-01 10:25:00        BMW     Sedan             2012    white   \n",
       "3       2018-01-01 10:52:00    Hyundai   Genesis             2011   silver   \n",
       "7       2018-01-01 09:05:00      Lexus    GS 460             2011    white   \n",
       "12      2018-01-01 09:52:00   Mercedes       320             2003   silver   \n",
       "15      2018-01-01 11:20:00      Lexus    IS 350             2016     grey   \n",
       "...                     ...        ...       ...              ...      ...   \n",
       "251461  2018-12-19 11:21:00     Toyota     Prado             2014    white   \n",
       "251464  2018-12-19 13:35:00        Kia    Cerato             2014    black   \n",
       "251467  2018-12-19 13:02:00        Kia  Carnival             2015   silver   \n",
       "251470  2018-12-19 17:36:00  Chevrolet    Malibu             2011   silver   \n",
       "251472  2018-12-19 15:54:00    Hyundai    Sonata             2014   silver   \n",
       "\n",
       "        AssessmentCost  SparePartCost  TotalCost        PaymentType  \\\n",
       "2                 5778           4778      10556  Insurance Company   \n",
       "3                 1043            343       1386                POS   \n",
       "7                 2019           1019       3038  Insurance Company   \n",
       "12                2300            800       3100  Insurance Company   \n",
       "15                3500           1500       5000  Insurance Company   \n",
       "...                ...            ...        ...                ...   \n",
       "251461            1620            820       2441  Insurance Company   \n",
       "251464            1372            572       1945  Insurance Company   \n",
       "251467            1702            902       2605  Insurance Company   \n",
       "251470            2600            600       3200  Insurance Company   \n",
       "251472            5191           2991       8182  Insurance Company   \n",
       "\n",
       "        DurationTime  Hour  Month  Day    WeekDay         PartsList  \\\n",
       "2                  7    10      1    1     Monday          [Bumper]   \n",
       "3                 26    10      1    1     Monday          [Sensor]   \n",
       "7                  6     8      1    1     Monday          [Bumper]   \n",
       "12                 7     9      1    1     Monday          [Bumper]   \n",
       "15                16    11      1    1     Monday  [Dash insulator]   \n",
       "...              ...   ...    ...  ...        ...               ...   \n",
       "251461            29    10     12   19  Wednesday          [Bumper]   \n",
       "251464            22    13     12   19  Wednesday          [Mirror]   \n",
       "251467            10    12     12   19  Wednesday          [Bumper]   \n",
       "251470            13    17     12   19  Wednesday  [Dash insulator]   \n",
       "251472            21    15     12   19  Wednesday            [Door]   \n",
       "\n",
       "                   PositionList PartStateList  CarMade CarClass CarType  \\\n",
       "2                        [rear]         [New]  Germany   Luxury     Car   \n",
       "3                   [undefined]         [New]    Korea   Luxury   Multi   \n",
       "7                        [rear]         [New]    Japan   Luxury     Car   \n",
       "12                      [front]        [Used]  Germany   Luxury   Multi   \n",
       "15                 [rear right]         [New]    Japan   Luxury     Car   \n",
       "...                         ...           ...      ...      ...     ...   \n",
       "251461       [rear, rear right]         [New]    Japan   Normal   Multi   \n",
       "251464                  [right]         [New]    Korea   Normal   Multi   \n",
       "251467                  [front]         [New]    Korea   Normal   Multi   \n",
       "251470  [front left, rear left]         [New]       US   Normal   Multi   \n",
       "251472             [front left]         [New]    Korea   Normal   Multi   \n",
       "\n",
       "        SparePart_Differace% AssessmentEvaluation  PartsNumber TimeEvaluation  \\\n",
       "2                  20.929259           Acceptable            1           Fast   \n",
       "3                 204.081633         unacceptable            1          Delay   \n",
       "7                  98.135427         unacceptable            1           Fast   \n",
       "12                187.500000         unacceptable            1           Fast   \n",
       "15                133.333333         unacceptable            1     Acceptable   \n",
       "...                      ...                  ...          ...            ...   \n",
       "251461             97.560976         unacceptable            1          Delay   \n",
       "251464            139.860140         unacceptable            1     Acceptable   \n",
       "251467             88.691796            Very High            1           Fast   \n",
       "251470            333.333333         unacceptable            1     Acceptable   \n",
       "251472             73.553995            Very High            1     Acceptable   \n",
       "\n",
       "        PartOfDay TotalCostEvaluation  \n",
       "2         Morning          Acceptable  \n",
       "3         Morning                 Low  \n",
       "7         Morning                 Low  \n",
       "12        Morning                 Low  \n",
       "15        Morning                 Low  \n",
       "...           ...                 ...  \n",
       "251461    Morning                 Low  \n",
       "251464  Afternoon                 Low  \n",
       "251467  Afternoon                 Low  \n",
       "251470    Evening          Acceptable  \n",
       "251472  Afternoon          Acceptable  \n",
       "\n",
       "[65405 rows x 29 columns]"
      ]
     },
     "execution_count": 648,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['PartsNumber']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_id</th>\n",
       "      <th>Area</th>\n",
       "      <th>RegistrationTime</th>\n",
       "      <th>CloseTime</th>\n",
       "      <th>CarBrand</th>\n",
       "      <th>CarModel</th>\n",
       "      <th>ManufactureYear</th>\n",
       "      <th>CarColor</th>\n",
       "      <th>AssessmentCost</th>\n",
       "      <th>SparePartCost</th>\n",
       "      <th>TotalCost</th>\n",
       "      <th>PaymentType</th>\n",
       "      <th>DurationTime</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>WeekDay</th>\n",
       "      <th>PartsList</th>\n",
       "      <th>PositionList</th>\n",
       "      <th>PartStateList</th>\n",
       "      <th>CarMade</th>\n",
       "      <th>CarClass</th>\n",
       "      <th>CarType</th>\n",
       "      <th>SparePart_Differace%</th>\n",
       "      <th>AssessmentEvaluation</th>\n",
       "      <th>PartsNumber</th>\n",
       "      <th>TimeEvaluation</th>\n",
       "      <th>PartOfDay</th>\n",
       "      <th>TotalCostEvaluation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>251461</th>\n",
       "      <td>253382</td>\n",
       "      <td>Remmal Industrial</td>\n",
       "      <td>2018-12-19 10:51:52.593000</td>\n",
       "      <td>2018-12-19 11:21:00</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>Prado</td>\n",
       "      <td>2014</td>\n",
       "      <td>white</td>\n",
       "      <td>1620</td>\n",
       "      <td>820</td>\n",
       "      <td>2441</td>\n",
       "      <td>Insurance Company</td>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>[Bumper]</td>\n",
       "      <td>[rear, rear right]</td>\n",
       "      <td>[New]</td>\n",
       "      <td>Japan</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Multi</td>\n",
       "      <td>97.560976</td>\n",
       "      <td>unacceptable</td>\n",
       "      <td>1</td>\n",
       "      <td>Delay</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          c_id               Area            RegistrationTime  \\\n",
       "251461  253382  Remmal Industrial  2018-12-19 10:51:52.593000   \n",
       "\n",
       "                  CloseTime CarBrand CarModel  ManufactureYear CarColor  \\\n",
       "251461  2018-12-19 11:21:00   Toyota    Prado             2014    white   \n",
       "\n",
       "        AssessmentCost  SparePartCost  TotalCost        PaymentType  \\\n",
       "251461            1620            820       2441  Insurance Company   \n",
       "\n",
       "        DurationTime  Hour  Month  Day    WeekDay PartsList  \\\n",
       "251461            29    10     12   19  Wednesday  [Bumper]   \n",
       "\n",
       "              PositionList PartStateList CarMade CarClass CarType  \\\n",
       "251461  [rear, rear right]         [New]   Japan   Normal   Multi   \n",
       "\n",
       "        SparePart_Differace% AssessmentEvaluation  PartsNumber TimeEvaluation  \\\n",
       "251461             97.560976         unacceptable            1          Delay   \n",
       "\n",
       "       PartOfDay TotalCostEvaluation  \n",
       "251461   Morning                 Low  "
      ]
     },
     "execution_count": 650,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['c_id']==253382]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_id</th>\n",
       "      <th>Area</th>\n",
       "      <th>RegistrationTime</th>\n",
       "      <th>CloseTime</th>\n",
       "      <th>CarBrand</th>\n",
       "      <th>CarModel</th>\n",
       "      <th>ManufactureYear</th>\n",
       "      <th>CarColor</th>\n",
       "      <th>AssessmentCost</th>\n",
       "      <th>SparePartCost</th>\n",
       "      <th>TotalCost</th>\n",
       "      <th>PaymentType</th>\n",
       "      <th>DurationTime</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>WeekDay</th>\n",
       "      <th>PartsList</th>\n",
       "      <th>PositionList</th>\n",
       "      <th>PartStateList</th>\n",
       "      <th>CarMade</th>\n",
       "      <th>CarClass</th>\n",
       "      <th>CarType</th>\n",
       "      <th>SparePart_Differace%</th>\n",
       "      <th>AssessmentEvaluation</th>\n",
       "      <th>PartsNumber</th>\n",
       "      <th>TimeEvaluation</th>\n",
       "      <th>PartOfDay</th>\n",
       "      <th>TotalCostEvaluation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>408</td>\n",
       "      <td>New Industrial</td>\n",
       "      <td>2018-01-01 11:03:56.103000</td>\n",
       "      <td>2018-01-01 11:20:00</td>\n",
       "      <td>Lexus</td>\n",
       "      <td>IS 350</td>\n",
       "      <td>2016</td>\n",
       "      <td>grey</td>\n",
       "      <td>3500</td>\n",
       "      <td>1500</td>\n",
       "      <td>5000</td>\n",
       "      <td>Insurance Company</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Monday</td>\n",
       "      <td>[Dash insulator]</td>\n",
       "      <td>[rear right]</td>\n",
       "      <td>[New]</td>\n",
       "      <td>Japan</td>\n",
       "      <td>Luxury</td>\n",
       "      <td>Car</td>\n",
       "      <td>133.333333</td>\n",
       "      <td>unacceptable</td>\n",
       "      <td>1</td>\n",
       "      <td>Acceptable</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    c_id            Area            RegistrationTime            CloseTime  \\\n",
       "15   408  New Industrial  2018-01-01 11:03:56.103000  2018-01-01 11:20:00   \n",
       "\n",
       "   CarBrand CarModel  ManufactureYear CarColor  AssessmentCost  SparePartCost  \\\n",
       "15    Lexus   IS 350             2016     grey            3500           1500   \n",
       "\n",
       "    TotalCost        PaymentType  DurationTime  Hour  Month  Day WeekDay  \\\n",
       "15       5000  Insurance Company            16    11      1    1  Monday   \n",
       "\n",
       "           PartsList  PositionList PartStateList CarMade CarClass CarType  \\\n",
       "15  [Dash insulator]  [rear right]         [New]   Japan   Luxury     Car   \n",
       "\n",
       "    SparePart_Differace% AssessmentEvaluation  PartsNumber TimeEvaluation  \\\n",
       "15            133.333333         unacceptable            1     Acceptable   \n",
       "\n",
       "   PartOfDay TotalCostEvaluation  \n",
       "15   Morning                 Low  "
      ]
     },
     "execution_count": 649,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['c_id']==408]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a077222d77dfe082b8f1dd562ad70e458ac2ab76993a0b248ab0476e32e9e8dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
